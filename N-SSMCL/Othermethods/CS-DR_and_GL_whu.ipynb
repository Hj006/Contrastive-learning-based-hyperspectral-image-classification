{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "库的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.exposure\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from scipy.sparse import coo_array\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 如果你显示中文，改为你系统支持的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whu_longkou(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 WHU-Hi-LongKou 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 num_train_per_class 个作为训练样本\n",
    "    - 所有 ground truth 标签 > 0 的像素作为测试集\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 读取 hyperspectral 数据\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou.tif\") as src:\n",
    "        hyperspectral = src.read()  # shape: (bands, height, width)\n",
    "    c, h, w = hyperspectral.shape\n",
    "\n",
    "    # 读取 ground truth 标签\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou_gt.tif\") as src:\n",
    "        gt = src.read(1)  # shape: (height, width)\n",
    "\n",
    "    label_dict = {\n",
    "        1: '玉米', 2: '棉花', 3: '芝麻',\n",
    "        4: '圆叶大豆', 5: '长叶大豆', 6: '水稻',\n",
    "        7: '水体', 8: '房屋和道路', 9: '混合杂草',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\"类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    # 所有标签 > 0 的都作为测试样本\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return hyperspectral, train_truth, candidate_truth, test_truth, info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_train_test(train_truth, test_truth, shape):\n",
    "    \"\"\"\n",
    "    合并训练集和测试集稀疏矩阵为一个新的训练集矩阵。\n",
    "    \n",
    "    参数:\n",
    "        train_truth: coo_matrix, 原始训练集稀疏矩阵\n",
    "        test_truth: coo_matrix, 原始测试集稀疏矩阵\n",
    "        shape: tuple, 数据的形状 (height, width)\n",
    "        \n",
    "    返回:\n",
    "        merged_truth: coo_matrix, 合并后的训练集稀疏矩阵\n",
    "    \"\"\"\n",
    "    # 合并行、列和数据\n",
    "    merged_rows = np.concatenate([train_truth.row, test_truth.row])\n",
    "    merged_cols = np.concatenate([train_truth.col, test_truth.col])\n",
    "    merged_data = np.concatenate([train_truth.data, test_truth.data])\n",
    "    \n",
    "    # 创建新的稀疏矩阵\n",
    "    merged_truth = coo_matrix((merged_data, (merged_rows, merged_cols)), shape=shape)\n",
    "    return merged_truth\n",
    "\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=40):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 高光谱图像数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: int, 保留的主成分数量\n",
    "        \n",
    "    返回:\n",
    "        pca_data: numpy.ndarray, PCA 降维后的数据，形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape  # 高光谱数据的形状\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "    \n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "    \n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "    \n",
    "    # 转换整个数据集 [C, H, W] -> [H×W, C]\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "    \n",
    "    # 恢复为原始图像的形状 [num_components, H, W]\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "def superpixel_segmentation(hsi_data, num_superpixels=100):\n",
    "    \"\"\"\n",
    "    使用 SLIC 超像素分割对 HSI 进行分割。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        num_superpixels: 生成的超像素数量\n",
    "        \n",
    "    返回:\n",
    "        labels: 超像素标签矩阵，形状为 (H, W)\n",
    "    \"\"\"\n",
    "    # 先用 PCA 提取第一主成分\n",
    "    first_pc = PCA(n_components=1).fit_transform(hsi_data.reshape(hsi_data.shape[0], -1).T)\n",
    "    first_pc = first_pc.reshape(hsi_data.shape[1:])  # 变成 (H, W)\n",
    "\n",
    "    # 修正错误：复制 3 通道，使其符合 SLIC 需 \n",
    "    first_pc_rgb = np.stack([first_pc] * 3, axis=-1)  # 变成 (H, W, 3)\n",
    "\n",
    "    # 正确调用 skimage.segmentation.sli \n",
    "    labels = skimage.segmentation.slic(first_pc_rgb, n_segments=num_superpixels, compactness=10, start_label=0, channel_axis=-1)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_superpiixel_pca(hsi_data, superpixel_labels, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算每个超像素的局部 PCA，并返回降维后的特征。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        superpixel_labels: numpy.ndarray, 形状为 (H, W)\n",
    "        merged_train_truth: coo_matrix, 训练区域掩码\n",
    "        num_components: int, PCA 维度\n",
    "        \n",
    "    返回:\n",
    "        superpixel_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "        superpixel_pca_dict: dict, 每个超像素的局部PCA结果\n",
    "    \"\"\"\n",
    "    h, w = superpixel_labels.shape\n",
    "    c = hsi_data.shape[0]\n",
    "    superpixel_pca_map = np.zeros((num_components, h, w))\n",
    "    superpixel_pca_dict = {}\n",
    "\n",
    "    # 获取训练区域坐标\n",
    "    mask_train = merged_train_truth.toarray() > 0\n",
    "\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "\n",
    "        # 当前超像素区域内的训练区域\n",
    "        train_mask = np.logical_and(mask, mask_train)\n",
    "        if np.sum(train_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        pixels = hsi_data[:, train_mask].T  # shape: (num_samples, num_channels)\n",
    "\n",
    "        # 如果样本数不足，跳过\n",
    "        if pixels.shape[0] <= num_components:\n",
    "            continue\n",
    "\n",
    "        # 执行局部 PCA\n",
    "        pca = PCA(n_components=num_components, svd_solver='auto')\n",
    "        reduced_pixels = pca.fit_transform(pixels)\n",
    "        superpixel_pca_dict[label] = reduced_pixels.T  # shape: (num_components, N)\n",
    "\n",
    "        # 计算均值写入整块区域\n",
    "        for i in range(num_components):\n",
    "            superpixel_pca_map[i, mask] = np.mean(reduced_pixels[:, i])\n",
    "\n",
    "    return superpixel_pca_map, superpixel_pca_dict\n",
    "\n",
    "\n",
    "\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    c1 = c // 2  # 每个子块保留一半的通道\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱数据中提取局部立方块，并在边界不足时进行填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy.ndarray, 形状为 [C, H, W]\n",
    "        x, y: int, 立方块的中心像素坐标\n",
    "        size: tuple, 立方块的大小 (s, s)，要求 s 必须是奇数\n",
    "    \n",
    "    返回:\n",
    "        cube: numpy.ndarray, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    assert size[0] % 2 == 1, \"立方块大小必须是奇数，以确保中心点对齐。\"\n",
    "    \n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2  # 计算半径\n",
    "\n",
    "    # 计算提取区域的坐标范围\n",
    "    x_min, x_max = max(0, x - half_size), min(h, x + half_size + 1)\n",
    "    y_min, y_max = max(0, y - half_size), min(w, y + half_size + 1)\n",
    "\n",
    "    # 提取局部数据\n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 计算需要填充的大小\n",
    "    pad_x_min, pad_x_max = max(0, half_size - x), max(0, x + half_size + 1 - h)\n",
    "    pad_y_min, pad_y_max = max(0, half_size - y), max(0, y + half_size + 1 - w)\n",
    "\n",
    "    # 使用边缘填充，确保输出形状为 (C, size, size)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (pad_x_min, pad_x_max),  # 高度填充\n",
    "        (pad_y_min, pad_y_max),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"edge\")  # 填充值是边界像素，而不是反射\n",
    "    #cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=40):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n",
    "    \n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n",
    "\n",
    "def extract_precise_superpixel_pca(superpixel_pca_dict, superpixel_labels, x, y):\n",
    "    \"\"\"\n",
    "    获取像素 (x, y) 所属超像素的 SuperPCA 特征。\n",
    "    \n",
    "    参数:\n",
    "        superpixel_pca_dict: 字典，存储每个超像素的 PCA 结果\n",
    "        superpixel_labels: 超像素标签矩阵\n",
    "        x, y: 目标像素坐标\n",
    "        \n",
    "    返回:\n",
    "        superpixel_features: numpy.ndarray, 形状为 (20,)\n",
    "    \"\"\"\n",
    "    superpixel_label = superpixel_labels[x, y]  # 获取该像素的超像素标签\n",
    "    \n",
    "    # 获取该超像素块的所有 PCA 结果\n",
    "    superpixel_features = superpixel_pca_dict[superpixel_label]  # 形状为 (20, N)，N 是该超像素块内像素数\n",
    "\n",
    "    # 取所有像素的平均值，确保返回 20 维的特征向量\n",
    "    superpixel_features = np.mean(superpixel_features, axis=1)  # 形状变为 (20,)\n",
    "\n",
    "    return superpixel_features\n",
    "\n",
    "\n",
    "\n",
    "class S3PCADataset(Dataset):\n",
    "    def __init__(self, pca_data, superpixel_pca_map, superpixel_pca_dict, superpixel_labels, global_pca, patch_size=11, num_samples=1000):\n",
    "        self.pca_data = pca_data\n",
    "        self.superpixel_pca_map = superpixel_pca_map\n",
    "        self.superpixel_pca_dict = superpixel_pca_dict\n",
    "        self.superpixel_labels = superpixel_labels\n",
    "        self.global_pca = global_pca\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.h, self.w = pca_data.shape[1], pca_data.shape[2]\n",
    "\n",
    "        #  构造 valid_coords 列表\n",
    "        self.valid_coords = []\n",
    "        for x in range(patch_size // 2, self.h - patch_size // 2):\n",
    "            for y in range(patch_size // 2, self.w - patch_size // 2):\n",
    "                label = superpixel_labels[x, y]\n",
    "                if label in superpixel_pca_dict:\n",
    "                    self.valid_coords.append((x, y))\n",
    "\n",
    "        if len(self.valid_coords) == 0:\n",
    "            raise ValueError(\"没有找到任何有效的 superpixel 区域坐标！\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.num_samples, len(self.valid_coords))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #  从 valid_coords 中采样\n",
    "        x, y = self.valid_coords[idx % len(self.valid_coords)]  # 防止超出索引\n",
    "\n",
    "        # 提取 PCA patch\n",
    "        pca_patch = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "        pca_patch = torch.tensor(pca_patch, dtype=torch.float32)\n",
    "\n",
    "        # 拆分成两半\n",
    "        pca_channels = pca_patch.shape[0]\n",
    "        half_channels = pca_channels // 2\n",
    "        pca_patch_a, pca_patch_b = torch.split(pca_patch, [half_channels, pca_channels - half_channels], dim=0)\n",
    "\n",
    "        # 提取 Superpixel PCA\n",
    "        superpixel_patch = extract_precise_superpixel_pca(self.superpixel_pca_dict, self.superpixel_labels, x, y)\n",
    "        superpixel_patch = torch.tensor(superpixel_patch[:, None, None], dtype=torch.float32)\n",
    "        superpixel_patch = superpixel_patch.expand(-1, self.patch_size, self.patch_size)\n",
    "\n",
    "        # 提取 Global PCA\n",
    "        global_patch = extract_cube(self.global_pca, x, y, (self.patch_size, self.patch_size))\n",
    "        global_patch = torch.tensor(global_patch, dtype=torch.float32)\n",
    "\n",
    "        # 拼接形成 cube_a 和 cube_b\n",
    "        cube_a = torch.cat([pca_patch_a, superpixel_patch], dim=0)\n",
    "        cube_b = torch.cat([pca_patch_b, global_patch], dim=0)\n",
    "\n",
    "        return cube_a, cube_b\n",
    "\n",
    "    \n",
    "def compute_global_pca(hsi_data, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算全局 PCA，并应用到整个 HSI。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (B, H, W)\n",
    "        merged_train_truth: coo_matrix, 标注的训练区域\n",
    "        num_components: int, PCA 降维维度\n",
    "        \n",
    "    返回:\n",
    "        global_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = merged_train_truth.row, merged_train_truth.col  # 获取训练样本的位置\n",
    "\n",
    "    # 取出训练区域的数据\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # (num_samples, num_channels)\n",
    "\n",
    "    # 在训练数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 只在训练数据上拟合\n",
    "\n",
    "    # 对整个 HSI 应用 PCA 变换\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # (H*W, C)\n",
    "    reduced_data = pca.transform(reshaped_data)  # (H*W, num_components)\n",
    "\n",
    "    global_pca_map = reduced_data.T.reshape(num_components, h, w)  # 还原形状\n",
    "    return global_pca_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "class S3PCADataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 pca_data, \n",
    "                 superpixel_pca_map, \n",
    "                 superpixel_pca_dict, \n",
    "                 superpixel_labels, \n",
    "                 global_pca, \n",
    "                 patch_size=11, \n",
    "                 num_samples=1000,\n",
    "                 mode=\"original\"  #  加一个模式选择参数\n",
    "                ):\n",
    "        self.pca_data = pca_data\n",
    "        self.superpixel_pca_map = superpixel_pca_map\n",
    "        self.superpixel_pca_dict = superpixel_pca_dict\n",
    "        self.superpixel_labels = superpixel_labels\n",
    "        self.global_pca = global_pca\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.mode = mode  #  保存模式\n",
    "        self.h, self.w = pca_data.shape[1], pca_data.shape[2]\n",
    "\n",
    "        #  构造 valid_coords 列表\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(patch_size // 2, self.h - patch_size // 2)\n",
    "            for y in range(patch_size // 2, self.w - patch_size // 2)\n",
    "            if superpixel_labels[x, y] in superpixel_pca_dict\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.num_samples, len(self.valid_coords))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx % len(self.valid_coords)]\n",
    "\n",
    "        if self.mode == \"raw_only\":\n",
    "            raw_patch = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "            raw_patch = torch.tensor(raw_patch, dtype=torch.float32)\n",
    "            half = raw_patch.shape[0] // 2\n",
    "            cube_a, cube_b = torch.split(raw_patch[:2*half], [half, half], dim=0)\n",
    "            return cube_a, cube_b\n",
    "\n",
    "        elif self.mode == \"local_global\":\n",
    "            superpixel_feat = self.superpixel_pca_dict[self.superpixel_labels[x, y]]  # shape (103,)\n",
    "            superpixel_patch = torch.tensor(superpixel_feat[:, None, None], dtype=torch.float32)\n",
    "            superpixel_patch = superpixel_patch.expand(-1, self.patch_size, self.patch_size)\n",
    "\n",
    "            global_patch = extract_cube(self.global_pca, x, y, (self.patch_size, self.patch_size)).astype(np.float32)\n",
    "            global_patch = torch.tensor(global_patch, dtype=torch.float32)\n",
    "\n",
    "            return superpixel_patch, global_patch\n",
    "\n",
    "\n",
    "        elif self.mode == \"pca_super_rawglobal\":\n",
    "            raw_patch = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "            raw_patch = torch.tensor(raw_patch, dtype=torch.float32)\n",
    "            total_channels = raw_patch.shape[0]\n",
    "            half = total_channels // 2\n",
    "            raw_a, raw_b = torch.split(raw_patch[:2*half], [half, half], dim=0)\n",
    "\n",
    "            superpixel_patch = extract_precise_superpixel_pca(self.superpixel_pca_dict, self.superpixel_labels, x, y)\n",
    "            superpixel_patch = torch.tensor(superpixel_patch[:, None, None], dtype=torch.float32)\n",
    "            superpixel_patch = superpixel_patch.expand(-1, self.patch_size, self.patch_size)\n",
    "\n",
    "            global_patch = extract_cube(self.global_pca, x, y, (self.patch_size, self.patch_size))\n",
    "            global_patch = torch.tensor(global_patch, dtype=torch.float32)\n",
    "\n",
    "            cube_a = torch.cat([raw_a, superpixel_patch], dim=0)\n",
    "            cube_b = torch.cat([raw_b, global_patch], dim=0)\n",
    "            return cube_a, cube_b\n",
    "\n",
    "        else:  # 默认原始方式\n",
    "            pca_patch = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "            pca_patch = torch.tensor(pca_patch, dtype=torch.float32)\n",
    "            pca_channels = pca_patch.shape[0]\n",
    "            half_channels = pca_channels // 2\n",
    "            pca_patch_a, pca_patch_b = torch.split(pca_patch, [half_channels, pca_channels - half_channels], dim=0)\n",
    "\n",
    "            superpixel_patch = extract_precise_superpixel_pca(self.superpixel_pca_dict, self.superpixel_labels, x, y)\n",
    "            superpixel_patch = torch.tensor(superpixel_patch[:, None, None], dtype=torch.float32)\n",
    "            superpixel_patch = superpixel_patch.expand(-1, self.patch_size, self.patch_size)\n",
    "\n",
    "            global_patch = extract_cube(self.global_pca, x, y, (self.patch_size, self.patch_size))\n",
    "            global_patch = torch.tensor(global_patch, dtype=torch.float32)\n",
    "\n",
    "            cube_a = torch.cat([pca_patch_a, superpixel_patch], dim=0)\n",
    "            cube_b = torch.cat([pca_patch_b, global_patch], dim=0)\n",
    "            return cube_a, cube_b\n",
    "\n",
    "\n",
    "def compute_superpixel_feature_map(hsi_data, superpixel_labels):\n",
    "    \"\"\"\n",
    "    对每个超像素提取均值特征（不降维），并生成特征图。\n",
    "    \"\"\"\n",
    "    h, w = superpixel_labels.shape\n",
    "    c = hsi_data.shape[0]\n",
    "    superpixel_feature_map = np.zeros((c, h, w), dtype=np.float32)\n",
    "    superpixel_feature_dict = {}\n",
    "\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        pixels = hsi_data[:, mask].T  # (N, C)\n",
    "        mean_feat = np.mean(pixels, axis=0)  # (C,)\n",
    "        superpixel_feature_dict[label] = mean_feat\n",
    "        for i in range(c):\n",
    "            superpixel_feature_map[i][mask] = mean_feat[i]\n",
    "\n",
    "    return superpixel_feature_map, superpixel_feature_dict\n",
    "\n",
    "\n",
    "\n",
    "def compute_superpixel_pca(hsi_data, superpixel_labels, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算每个超像素的局部 PCA，并返回降维后的特征。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        superpixel_labels: numpy.ndarray, 形状为 (H, W)\n",
    "        merged_train_truth: coo_matrix, 训练区域掩码\n",
    "        num_components: int, PCA 维度\n",
    "        \n",
    "    返回:\n",
    "        superpixel_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "        superpixel_pca_dict: dict, 每个超像素的局部PCA结果\n",
    "    \"\"\"\n",
    "    h, w = superpixel_labels.shape\n",
    "    c = hsi_data.shape[0]\n",
    "    superpixel_pca_map = np.zeros((num_components, h, w))\n",
    "    superpixel_pca_dict = {}\n",
    "\n",
    "    # 获取训练区域坐标\n",
    "    mask_train = merged_train_truth.toarray() > 0\n",
    "\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "\n",
    "        # 当前超像素区域内的训练区域\n",
    "        train_mask = np.logical_and(mask, mask_train)\n",
    "        if np.sum(train_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        pixels = hsi_data[:, train_mask].T  # shape: (num_samples, num_channels)\n",
    "\n",
    "        # 如果样本数不足，跳过\n",
    "        if pixels.shape[0] <= num_components:\n",
    "            continue\n",
    "\n",
    "        # 执行局部 PCA\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced_pixels = pca.fit_transform(pixels)\n",
    "        superpixel_pca_dict[label] = reduced_pixels.T  # shape: (num_components, N)\n",
    "\n",
    "        # 计算均值写入整块区域\n",
    "        for i in range(num_components):\n",
    "            superpixel_pca_map[i, mask] = np.mean(reduced_pixels[:, i])\n",
    "\n",
    "    return superpixel_pca_map, superpixel_pca_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_global_pca(hsi_data, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算全局 PCA，并应用到整个 HSI。\n",
    "    如果训练样本数少于目标维度，则跳过 PCA，直接返回原始数据。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (B, H, W)\n",
    "        merged_train_truth: coo_matrix, 标注的训练区域\n",
    "        num_components: int, PCA 降维维度\n",
    "        \n",
    "    返回:\n",
    "        global_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = merged_train_truth.row, merged_train_truth.col\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "    num_samples = train_spectra.shape[0]\n",
    "\n",
    "    if num_samples < num_components:\n",
    "        print(f\"样本数 {num_samples} 小于 PCA 维度 {num_components}，跳过 PCA，返回原始数据\")\n",
    "        return hsi_data  # 不降维\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)\n",
    "\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # shape: (H*W, C)\n",
    "    reduced_data = pca.transform(reshaped_data)  # shape: (H*W, num_components)\n",
    "    global_pca_map = reduced_data.T.reshape(num_components, h, w)\n",
    "\n",
    "    return global_pca_map\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def apply_pca_on_candidate(hsi_data, candidate_truth, num_components=40, use_pca=True):\n",
    "    \"\"\"\n",
    "    在 candidate_truth 区域进行 PCA 或保留原始光谱，返回结果格式统一。\n",
    "    \n",
    "    返回：\n",
    "    - candidate_data: shape [C, H, W]，只在候选区域填值，其余为 0\n",
    "    - samples: shape [N, C]，候选像素的特征\n",
    "    - coords: List of (row, col)\n",
    "    - explained_variance_ratio 或 None\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = candidate_truth.row, candidate_truth.col\n",
    "    spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "    coords = list(zip(rows, cols))\n",
    "\n",
    "    if use_pca:\n",
    "        if num_components > c:\n",
    "            raise ValueError(f\"PCA 维度 {num_components} 不能大于原始通道数 {c}\")\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced = pca.fit_transform(spectra)  # shape: (N, num_components)\n",
    "        result_c = num_components\n",
    "        final_data = reduced\n",
    "        var_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        reduced = spectra\n",
    "        result_c = c\n",
    "        final_data = reduced\n",
    "        var_ratio = None\n",
    "\n",
    "    # 构建 [C, H, W] 格式，只填候选区域\n",
    "    candidate_data = np.zeros((result_c, h, w), dtype=np.float32)\n",
    "    for i, (r, c_) in enumerate(coords):\n",
    "        candidate_data[:, r, c_] = final_data[i]\n",
    "\n",
    "    return candidate_data, reduced, coords, var_ratio\n",
    "\n",
    "def prepare_data_from_loaded(mode, hsi_data, candidate_truth, train_truth, test_truth, info):\n",
    "    \"\"\"\n",
    "    使用你已加载的 pavia、truth 等数据，按模式准备训练用的数据。\n",
    "    根据模式控制是否对主数据、superpixel 和 global 特征降维。\n",
    "    \"\"\"\n",
    "    merged_truth = merge_train_test(train_truth, test_truth, (info[\"height\"], info[\"width\"]))\n",
    "\n",
    "    # === 模式配置 ===\n",
    "    use_pca = mode == \"original\"\n",
    "    use_raw = mode == \"local_global\"\n",
    "    main_channels = 40 if use_pca else hsi_data.shape[0]\n",
    "    side_channels = 20 if use_pca else hsi_data.shape[0]\n",
    "\n",
    "    # === 1. 主数据 ===\n",
    "    if use_raw:\n",
    "        main_data = hsi_data  # 不降维\n",
    "    else:\n",
    "        main_data, _, _, _ = apply_pca_on_candidate(\n",
    "            hsi_data, candidate_truth,\n",
    "            num_components=main_channels,\n",
    "            use_pca=use_pca\n",
    "        )\n",
    "\n",
    "    # === 2. 超像素标签 ===\n",
    "    superpixel_labels = superpixel_segmentation(hsi_data)\n",
    "\n",
    "    # === 3. Superpixel 特征 ===\n",
    "    if use_raw:\n",
    "        # 不做 PCA，直接用均值光谱\n",
    "        superpixel_pca_map, superpixel_pca_dict = compute_superpixel_feature_map(\n",
    "            hsi_data, superpixel_labels\n",
    "        )\n",
    "    else:\n",
    "        superpixel_pca_map, superpixel_pca_dict = compute_superpixel_pca(\n",
    "            hsi_data, superpixel_labels, candidate_truth, num_components=side_channels\n",
    "        )\n",
    "\n",
    "    # === 4. Global 特征 ===\n",
    "    if use_raw:\n",
    "        global_pca_map = hsi_data  # 不做 PCA\n",
    "    else:\n",
    "        global_pca_map = compute_global_pca(\n",
    "            hsi_data, candidate_truth, num_components=side_channels\n",
    "        )\n",
    "\n",
    "    return main_data, superpixel_pca_map, superpixel_pca_dict, superpixel_labels, global_pca_map\n",
    "\n",
    "def run_experiment(mode, dataset):\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "    input_channels = dataset[0][0].shape[0]  # 获取 cube_a 的通道数\n",
    "    feature_extractor = FeatureExtractor(input_channels=input_channels).cuda()\n",
    "    projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "    optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "    os.makedirs('./pth', exist_ok=True)\n",
    "    num_epochs = 50\n",
    "    temperature = 1.0\n",
    "    loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        feature_extractor.train()\n",
    "        projection_head.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for cube_a, cube_b in dataloader:\n",
    "            cube_a, cube_b = cube_a.cuda(), cube_b.cuda()\n",
    "            features_a = feature_extractor(cube_a)\n",
    "            features_b = feature_extractor(cube_b)\n",
    "            proj_a = projection_head(features_a)\n",
    "            proj_b = projection_head(features_b)\n",
    "\n",
    "            loss = contrastive_loss_ce_hard_negatives(proj_a,proj_b,temperature=1,num_negatives=10)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        loss_values.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Mode: {mode} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 保存模型\n",
    "    model_path = f'final/model_{mode}.pth'\n",
    "    print(\"model:\", model_path)\n",
    "    torch.save({\n",
    "        'epoch': num_epochs,\n",
    "        'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "        'projection_head_state_dict': projection_head.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss_values[-1],\n",
    "    }, model_path)\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "    # 可选：画损失图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_values, marker='o')\n",
    "    plt.title(f\"Loss Curve ({mode})\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'final/loss_curve_{mode}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模式名\t                  是否降维\t数据组合方式\n",
    "\n",
    "\"original\"\t             ✅\t     20pca + 20super vs 20pca + 20global\n",
    "\n",
    "\"local_global\"\t         ❌\t     super103 vs global103\n",
    "\n",
    "\"pca_super_rawglobal\"\t ❌\t     raw51 + super103 vs raw51 + global103\n",
    "\n",
    "\"raw_only\"\t             ❌\t     raw51 vs raw51（切半）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\rasterio\\__init__.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Mode: local_global | Loss: 1.3378\n",
      "Epoch [2/50] | Mode: local_global | Loss: 0.9571\n",
      "Epoch [3/50] | Mode: local_global | Loss: 0.8566\n",
      "Epoch [4/50] | Mode: local_global | Loss: 0.8298\n",
      "Epoch [5/50] | Mode: local_global | Loss: 0.8205\n",
      "Epoch [6/50] | Mode: local_global | Loss: 0.8164\n",
      "Epoch [7/50] | Mode: local_global | Loss: 0.8147\n",
      "Epoch [8/50] | Mode: local_global | Loss: 0.8123\n",
      "Epoch [9/50] | Mode: local_global | Loss: 0.8103\n",
      "Epoch [10/50] | Mode: local_global | Loss: 0.8095\n",
      "Epoch [11/50] | Mode: local_global | Loss: 0.8084\n",
      "Epoch [12/50] | Mode: local_global | Loss: 0.8064\n",
      "Epoch [13/50] | Mode: local_global | Loss: 0.8057\n",
      "Epoch [14/50] | Mode: local_global | Loss: 0.8048\n",
      "Epoch [15/50] | Mode: local_global | Loss: 0.8041\n",
      "Epoch [16/50] | Mode: local_global | Loss: 0.8035\n",
      "Epoch [17/50] | Mode: local_global | Loss: 0.8025\n",
      "Epoch [18/50] | Mode: local_global | Loss: 0.8023\n",
      "Epoch [19/50] | Mode: local_global | Loss: 0.8015\n",
      "Epoch [20/50] | Mode: local_global | Loss: 0.8013\n",
      "Epoch [21/50] | Mode: local_global | Loss: 0.8010\n",
      "Epoch [22/50] | Mode: local_global | Loss: 0.8004\n",
      "Epoch [23/50] | Mode: local_global | Loss: 0.8001\n",
      "Epoch [24/50] | Mode: local_global | Loss: 0.8001\n",
      "Epoch [25/50] | Mode: local_global | Loss: 0.7991\n",
      "Epoch [26/50] | Mode: local_global | Loss: 0.7989\n",
      "Epoch [27/50] | Mode: local_global | Loss: 0.7985\n",
      "Epoch [28/50] | Mode: local_global | Loss: 0.7984\n",
      "Epoch [29/50] | Mode: local_global | Loss: 0.7983\n",
      "Epoch [30/50] | Mode: local_global | Loss: 0.7982\n",
      "Epoch [31/50] | Mode: local_global | Loss: 0.7981\n",
      "Epoch [32/50] | Mode: local_global | Loss: 0.7980\n",
      "Epoch [33/50] | Mode: local_global | Loss: 0.7977\n",
      "Epoch [34/50] | Mode: local_global | Loss: 0.7977\n",
      "Epoch [35/50] | Mode: local_global | Loss: 0.7975\n",
      "Epoch [36/50] | Mode: local_global | Loss: 0.7975\n",
      "Epoch [37/50] | Mode: local_global | Loss: 0.7974\n",
      "Epoch [38/50] | Mode: local_global | Loss: 0.7975\n",
      "Epoch [39/50] | Mode: local_global | Loss: 0.7973\n",
      "Epoch [40/50] | Mode: local_global | Loss: 0.7973\n",
      "Epoch [41/50] | Mode: local_global | Loss: 0.7973\n",
      "Epoch [42/50] | Mode: local_global | Loss: 0.7973\n",
      "Epoch [43/50] | Mode: local_global | Loss: 0.7972\n",
      "Epoch [44/50] | Mode: local_global | Loss: 0.7972\n",
      "Epoch [45/50] | Mode: local_global | Loss: 0.7973\n",
      "Epoch [46/50] | Mode: local_global | Loss: 0.7973\n",
      "Epoch [47/50] | Mode: local_global | Loss: 0.7972\n",
      "Epoch [48/50] | Mode: local_global | Loss: 0.7974\n",
      "Epoch [49/50] | Mode: local_global | Loss: 0.7971\n",
      "Epoch [50/50] | Mode: local_global | Loss: 0.7971\n",
      "model: final/model_local_global.pth\n",
      "Model saved to: final/model_local_global.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\WHU\\Tiff_format\\WHU-Hi-LongKou\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 300, 2: 300, 3: 300,\n",
    "    4: 300, 5: 300, 6: 300,\n",
    "    7: 300, 8: 300, 9: 300\n",
    "}\n",
    "\n",
    "whu, train_truth, candidate_truth, test_truth, info = load_whu_longkou(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=10\n",
    ")\n",
    "\n",
    "\n",
    "# 调用 prepare\n",
    "mode = \"local_global\"  # 你想跑的模式\n",
    "main_data, superpixel_pca_map, superpixel_pca_dict, superpixel_labels, global_pca_map = prepare_data_from_loaded(\n",
    "    mode, whu, candidate_truth, train_truth, test_truth, info\n",
    ")\n",
    "\n",
    "# 用于 S3PCADataset 构建数据集\n",
    "dataset = S3PCADataset(\n",
    "    main_data,\n",
    "    superpixel_pca_map,\n",
    "    superpixel_pca_dict,\n",
    "    superpixel_labels,\n",
    "    global_pca_map,\n",
    "    mode=mode\n",
    ")\n",
    "\n",
    "run_experiment(mode, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "# === 模式选择 ===\n",
    "mode = \"local_global\"  # original, local_global, pca_super_rawglobal, raw_only\n",
    "\n",
    "# === 输入通道定义（匹配对比训练）===\n",
    "\n",
    "def get_input_channels_for_classification(mode):\n",
    "    if mode == \"original\":\n",
    "        return 20\n",
    "    elif mode == \"local_global\":\n",
    "        return 270\n",
    "    elif mode == \"pca_super_rawglobal\":\n",
    "        return 135 + 270\n",
    "    elif mode == \"raw_only\":\n",
    "        return 135\n",
    "    else:\n",
    "        raise ValueError(f\"未知模式: {mode}\")\n",
    "# === 从稀疏矩阵提取 label ===\n",
    "def extract_labels(truth, label_dict):\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "# === 分类数据集 ===\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))\n",
    "        return torch.tensor(cube).float(), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# === 特征提取器 ===\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# === 分类头 ===\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# === 分类训练函数 ===\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()\n",
    "    classification_head.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        if epoch < 10:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# === 分类评估函数 ===\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = torch.zeros(num_classes).cuda()\n",
    "    class_total = torch.zeros(num_classes).cuda()\n",
    "    prediction_counts = torch.zeros(num_classes).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                class_total[labels[i]] += 1\n",
    "                if predicted[i] == labels[i]:\n",
    "                    class_correct[labels[i]] += 1\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    oa = correct / total\n",
    "    class_accuracy = class_correct / class_total  # 每个类别的准确率\n",
    "    aa = class_accuracy.mean().item()\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "    \n",
    "    print(f\"\\nOverall Accuracy: {oa:.4f}\")\n",
    "    print(f\"Average Accuracy: {aa:.4f}\")\n",
    "    print(f\"Kappa: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for i, acc in enumerate(class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "\n",
    "    return oa, aa, kappa, class_accuracy.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def prepare_data_by_mode(mode, hsi_data, train_truth=None, test_truth=None, num_superpixel_components=51):\n",
    "    \"\"\"\n",
    "    根据 mode 返回 main_data:\n",
    "    - \"local_global\": 使用原始高光谱数据，不做降维\n",
    "    - \"raw_only\": 使用 PCA 全图降维\n",
    "    - \"pca_super_rawglobal\": 原始数据 + 局部 PCA（仅用有标签区域拟合）拼接\n",
    "    \"\"\"\n",
    "    print(f\"[prepare_data_by_mode] 当前模式: {mode}\")\n",
    "    C_raw, H, W = hsi_data.shape\n",
    "\n",
    "    if mode == \"local_global\":\n",
    "        print(\"使用原始高光谱数据，不做 PCA\")\n",
    "        return hsi_data\n",
    "\n",
    "    elif mode == \"raw_only\":\n",
    "        num_components = 135\n",
    "        reshaped = hsi_data.reshape(C_raw, -1).T  # shape: (H*W, C)\n",
    "        print(f\"对全图做 PCA 降维到 {num_components} 维...\")\n",
    "        pca = PCA(n_components=num_components, svd_solver='auto')\n",
    "        reduced = pca.fit_transform(reshaped).T  # shape: (num_components, H*W)\n",
    "        reduced_data = reduced.reshape(num_components, H, W)\n",
    "        print(f\"PCA 完成，降维后形状: {reduced_data.shape}\")\n",
    "        return reduced_data\n",
    "\n",
    "    elif mode == \"pca_super_rawglobal\":\n",
    "        if train_truth is None or test_truth is None:\n",
    "            raise ValueError(\"必须提供 train_truth 和 test_truth 用于构造局部 PCA 区域\")\n",
    "\n",
    "        # 1. 构建全图上的标签区域（合并 train 和 test）\n",
    "        merged_truth = merge_train_test(train_truth, test_truth, shape=(H, W))\n",
    "\n",
    "        # 2. 超像素分割（对整个图做）\n",
    "        superpixel_labels = superpixel_segmentation(hsi_data)\n",
    "\n",
    "        # 3. 在 merged truth 区域执行每个超像素的 PCA 拟合，输出整个图的特征图\n",
    "        superpixel_pca_map, _ = compute_superpixel_pca(\n",
    "            hsi_data, superpixel_labels, merged_truth,\n",
    "            num_components=num_superpixel_components\n",
    "        )\n",
    "\n",
    "        # 4. 拼接原始数据和 superpixel PCA 特征图\n",
    "        combined = np.concatenate([hsi_data, superpixel_pca_map], axis=0)\n",
    "        print(f\"[组合特征] 原始: {hsi_data.shape} + SuperPCA: {superpixel_pca_map.shape} → 总: {combined.shape}\")\n",
    "        return combined\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"暂未支持的 mode: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prepare_data_by_mode] 当前模式: local_global\n",
      "使用原始高光谱数据，不做 PCA\n",
      "\n",
      "[调试] 当前模式: local_global\n",
      "[调试] 输入数据 main_data.shape: (270, 550, 400) (channels, height, width)\n",
      "[调试] Number of training samples: 90\n",
      "[调试] Number of testing samples: 204542\n",
      "[调试] 实际输入通道数: 270\n",
      "[调试] 模式期望通道数: 270\n",
      "模型： final/model_local_global.pth\n",
      "[调试] 可加载层数: 21 / 21\n",
      " 成功加载部分预训练参数（自动适配输入通道）\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: 准备分类输入数据 ===\n",
    "main_data = prepare_data_by_mode(\n",
    "    mode=mode,\n",
    "    hsi_data=whu,\n",
    "    train_truth=train_truth,\n",
    "    test_truth=test_truth,\n",
    "    num_superpixel_components=135  # 你可以调这个\n",
    ")\n",
    "\n",
    "print(f\"\\n[调试] 当前模式: {mode}\")\n",
    "print(f\"[调试] 输入数据 main_data.shape: {main_data.shape} (channels, height, width)\")\n",
    "\n",
    "train_labels = extract_labels(train_truth, info[\"label_dict\"])\n",
    "test_labels = extract_labels(test_truth, info[\"label_dict\"])\n",
    "# === STEP 1.5: 构建训练与测试 DataLoader ===\n",
    "patch_size = 11  # 可自定义\n",
    "\n",
    "train_dataset = ClassificationDataset(main_data, train_labels, patch_size=patch_size)\n",
    "test_dataset = ClassificationDataset(main_data, test_labels, patch_size=patch_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"[调试] Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"[调试] Number of testing samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "# === STEP 2: 模型准备 ===\n",
    "# 自动从 main_data 获取输入通道数\n",
    "actual_input_channels = main_data.shape[0]\n",
    "expected_input_channels = get_input_channels_for_classification(mode)\n",
    "\n",
    "print(f\"[调试] 实际输入通道数: {actual_input_channels}\")\n",
    "print(f\"[调试] 模式期望通道数: {expected_input_channels}\")\n",
    "if actual_input_channels != expected_input_channels:\n",
    "    print(\" 通道数不一致！已使用实际输入通道数进行初始化\")\n",
    "\n",
    "feature_extractor = FeatureExtractor(input_channels=actual_input_channels).cuda()\n",
    "\n",
    "checkpoint_path = f\"final/model_{mode}.pth\"\n",
    "print(\"模型：\",checkpoint_path)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "pretrained_state = checkpoint['feature_extractor_state_dict']\n",
    "current_state = feature_extractor.state_dict()\n",
    "\n",
    "# 只加载 shape 一致的层\n",
    "filtered_state = {\n",
    "    k: v for k, v in pretrained_state.items()\n",
    "    if k in current_state and v.shape == current_state[k].shape\n",
    "}\n",
    "\n",
    "print(f\"[调试] 可加载层数: {len(filtered_state)} / {len(pretrained_state)}\")\n",
    "\n",
    "# 更新模型参数并加载\n",
    "current_state.update(filtered_state)\n",
    "feature_extractor.load_state_dict(current_state)\n",
    "print(f\" 成功加载部分预训练参数（自动适配输入通道）\")\n",
    "\n",
    "# === 后续流程保持不变 ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 | Loss: 2.3759\n",
      "Epoch 2/200 | Loss: 2.0049\n",
      "Epoch 3/200 | Loss: 1.6745\n",
      "Epoch 4/200 | Loss: 1.5476\n",
      "Epoch 5/200 | Loss: 1.3964\n",
      "Epoch 6/200 | Loss: 1.3090\n",
      "Epoch 7/200 | Loss: 1.2313\n",
      "Epoch 8/200 | Loss: 1.1133\n",
      "Epoch 9/200 | Loss: 0.9987\n",
      "Epoch 10/200 | Loss: 0.9621\n",
      "\n",
      "Overall Accuracy: 0.8920\n",
      "Average Accuracy: 0.8026\n",
      "Kappa: 0.8587\n",
      "\n",
      "Per-class Accuracy:\n",
      "0.9969\n",
      "0.9686\n",
      "0.5058\n",
      "0.8246\n",
      "0.9138\n",
      "0.4654\n",
      "0.9995\n",
      "0.9739\n",
      "0.5754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8919928425457853,\n",
       " 0.8026485443115234,\n",
       " 0.8586681803154417,\n",
       " array([0.99689955, 0.96859324, 0.50577366, 0.8245586 , 0.9137557 ,\n",
       "        0.46541253, 0.99950784, 0.9738911 , 0.57544464], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "classification_head = ClassificationHead(128, num_classes=len(info[\"label_dict\"])).cuda()\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# === STEP 3: 训练 ===\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n",
    "\n",
    "# === STEP 4: 评估 ===\n",
    "evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes=len(info[\"label_dict\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始模型 新loss\n",
    "Epoch 1/200 | Loss: 2.2799\n",
    "Epoch 2/200 | Loss: 1.9049\n",
    "Epoch 3/200 | Loss: 1.7027\n",
    "Epoch 4/200 | Loss: 1.5020\n",
    "Epoch 5/200 | Loss: 1.3715\n",
    "Epoch 6/200 | Loss: 1.2738\n",
    "Epoch 7/200 | Loss: 1.1259\n",
    "Epoch 8/200 | Loss: 1.0522\n",
    "Epoch 9/200 | Loss: 0.9816\n",
    "Epoch 10/200 | Loss: 0.8938\n",
    "\n",
    " Overall Accuracy: 0.9390\n",
    " Average Accuracy: 0.9286\n",
    " Kappa: 0.9211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "原始模型不降维 新loss\n",
    "Epoch 1/200 | Loss: 2.2799\n",
    "Epoch 2/200 | Loss: 1.9048\n",
    "Epoch 3/200 | Loss: 1.7028\n",
    "Epoch 4/200 | Loss: 1.5015\n",
    "Epoch 5/200 | Loss: 1.3710\n",
    "Epoch 6/200 | Loss: 1.2725\n",
    "Epoch 7/200 | Loss: 1.1294\n",
    "Epoch 8/200 | Loss: 1.0534\n",
    "Epoch 9/200 | Loss: 0.9805\n",
    "Epoch 10/200 | Loss: 0.8941\n",
    "\n",
    " Overall Accuracy: 0.9402\n",
    " Average Accuracy: 0.9251\n",
    " Kappa: 0.9225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "新的loss ， 局部与全局\n",
    "0.9422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "不降维新的loss ， pca_super_rawglobal\n",
    " Overall Accuracy: 0.9416\n",
    " Average Accuracy: 0.9273\n",
    " Kappa: 0.9243"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/200 | Loss: 2.3429\n",
    "Epoch 2/200 | Loss: 1.9264\n",
    "Epoch 3/200 | Loss: 1.7961\n",
    "Epoch 4/200 | Loss: 1.6046\n",
    "Epoch 5/200 | Loss: 1.4309\n",
    "Epoch 6/200 | Loss: 1.2866\n",
    "Epoch 7/200 | Loss: 1.1881\n",
    "Epoch 8/200 | Loss: 1.1271\n",
    "Epoch 9/200 | Loss: 1.0084\n",
    "Epoch 10/200 | Loss: 0.9382\n",
    "\n",
    " Overall Accuracy: 0.9399\n",
    " Average Accuracy: 0.9255\n",
    " Kappa: 0.9221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " local global 不降维\n",
    " Overall Accuracy: 0.9387\n",
    " Average Accuracy: 0.9219\n",
    " Kappa: 0.9204"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
