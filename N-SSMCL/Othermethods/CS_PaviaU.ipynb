{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个类别的真实像素数：\n",
      "类别 1: 6631 个像素\n",
      "类别 2: 18649 个像素\n",
      "类别 3: 2099 个像素\n",
      "类别 4: 3064 个像素\n",
      "类别 5: 1345 个像素\n",
      "类别 6: 5029 个像素\n",
      "类别 7: 1330 个像素\n",
      "类别 8: 3682 个像素\n",
      "类别 9: 947 个像素\n",
      "总标注像素数: 42776\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def count_pixels_per_class(data_path: Path):\n",
    "    gt = loadmat(data_path / 'PaviaU_gt.mat')['paviaU_gt']\n",
    "    unique_labels = np.unique(gt)\n",
    "    unique_labels = unique_labels[unique_labels != 0]\n",
    "\n",
    "    print(\"每个类别的真实像素数：\")\n",
    "    total = 0\n",
    "    for label in unique_labels:\n",
    "        count = np.sum(gt == label)\n",
    "        print(f\"类别 {label}: {count} 个像素\")\n",
    "        total += count\n",
    "    print(f\"总标注像素数: {total}\")\n",
    "\n",
    "# 示例路径\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\otherdataset\")\n",
    "count_pixels_per_class(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.exposure\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation\n",
    "import random\n",
    "from scipy.sparse import coo_array\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pavia University shape: (103, 610, 340)\n",
      "Train samples: 90\n",
      "Candidate samples: 3921\n",
      "Test samples: 42776\n"
     ]
    }
   ],
   "source": [
    "def load_pavia_university_with_full_test(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 Pavia University 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 10 个作为训练样本\n",
    "    - 所有 ground truth 像素都作为测试样本（包括候选/训练区域）\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    pavia_data = loadmat(data_path / 'PaviaU.mat')['paviaU']\n",
    "    gt = loadmat(data_path / 'PaviaU_gt.mat')['paviaU_gt']\n",
    "    h, w, c = pavia_data.shape\n",
    "\n",
    "    label_dict = {\n",
    "        1: 'Asphalt road', 2: 'Meadows', 3: 'Gravel',\n",
    "        4: 'Trees', 5: 'Painted metal sheets', 6: 'Bare Soil',\n",
    "        7: 'Bitumen', 8: 'Self-Blocking Bricks', 9: 'Shadows',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\" 类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    #  测试集直接包含所有 ground truth\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return pavia_data.transpose(2, 0, 1), train_truth, candidate_truth, test_truth, info\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\otherdataset\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 548, 2: 540, 3: 392,\n",
    "    4: 524, 5: 265, 6: 532,\n",
    "    7: 375, 8: 514, 9: 231\n",
    "}\n",
    "\n",
    "pavia, train_truth, candidate_truth, test_truth, info = load_pavia_university_with_full_test(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=10\n",
    ")\n",
    "\n",
    "print(f\"Pavia University shape: {pavia.shape}\")\n",
    "print(f\"Train samples: {train_truth.count_nonzero()}\")         #  90\n",
    "print(f\"Candidate samples: {candidate_truth.count_nonzero()}\") #  3921\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           #  42776\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计 train_truth 中的类别数量（非零值的唯一值数量）\n",
    "num_classes = len(set(train_truth.data))\n",
    "num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选区降维结果 shape: (40, 610, 340)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def apply_pca_on_candidate(hsi_data, candidate_truth, num_components=40, use_pca=True):\n",
    "    \"\"\"\n",
    "    在 candidate_truth 区域进行 PCA 或保留原始光谱，返回结果格式统一。\n",
    "\n",
    "    返回：\n",
    "    - data: shape [C, H, W]，只在候选区域填值，其余为 0\n",
    "    - samples: shape [N, C]，候选像素的特征\n",
    "    - coords: List of (row, col)\n",
    "    - explained_variance_ratio 或 None\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = candidate_truth.row, candidate_truth.col\n",
    "    spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "\n",
    "    coords = list(zip(rows, cols))\n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced = pca.fit_transform(spectra)  # shape: (N, num_components)\n",
    "        result_c = num_components\n",
    "        final_data = reduced\n",
    "        var_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        reduced = spectra  # shape: (N, C)\n",
    "        result_c = c\n",
    "        final_data = reduced\n",
    "        var_ratio = None\n",
    "\n",
    "    # 构建 [C, H, W] 格式，只填候选区域\n",
    "    candidate_data = np.zeros((result_c, h, w), dtype=np.float32)\n",
    "    for i, (r, c_) in enumerate(coords):\n",
    "        candidate_data[:, r, c_] = final_data[i]\n",
    "\n",
    "    return candidate_data, reduced, coords, var_ratio\n",
    "\n",
    "\n",
    "\n",
    "# 应用 PCA 降维\n",
    "pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(pavia, candidate_truth, num_components=40)\n",
    "#不用pca降维\n",
    "#original_candidate_data, raw_samples, coords, _\n",
    "#pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(pavia, candidate_truth, use_pca=False)\n",
    "\n",
    "print(f\"候选区降维结果 shape: {pca_candidate_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的立方块形状: (40, 11, 11)\n",
      "子立方块 A 形状: torch.Size([11, 11, 20])\n",
      "子立方块 B 形状: torch.Size([11, 11, 20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    通道维度为奇数时，丢弃最后一个通道，保持对称划分。\n",
    "\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    if c % 2 != 0:\n",
    "        hsi_cube = hsi_cube[:, :, :c - 1]  # 丢掉最后一个通道\n",
    "    c1 = hsi_cube.shape[2] // 2\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "# 提取 11x11 的立方块\n",
    "s = 11  # 立方块的宽和高\n",
    "patch_size = (s, s)\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 进行对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "# 提取某像素点周围的立方块\n",
    "x, y = 100, 100  # 中心像素位置\n",
    "cube = extract_cube(pca_candidate_data, x, y, patch_size)\n",
    "print(\"提取的立方块形状:\", cube.shape)  # (40, 11, 11)\n",
    "# 切分通道\n",
    "cube_tensor = torch.tensor(cube).permute(1, 2, 0)  # 转换为 [H, W, C]\n",
    "cube_a, cube_b = split_cube(cube_tensor)\n",
    "\n",
    "print(\"子立方块 A 形状:\", cube_a.shape)  # (11, 11, 20)\n",
    "print(\"子立方块 B 形状:\", cube_b.shape)  # (11, 11, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # 如果为 False，CUDA 不可用\n",
    "print(torch.cuda.current_device())  # 当前设备编号\n",
    "print(torch.cuda.get_device_name(0))  # 查看设备名称\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=20):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cpu\n",
      "torch.float32 cpu\n"
     ]
    }
   ],
   "source": [
    "print(cube_a.dtype, cube_a.device)\n",
    "print(cube_b.dtype, cube_b.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features A Shape: torch.Size([1, 128])\n",
      "Features B Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取网络\n",
    "feature_extractor = FeatureExtractor(input_channels=20).cuda()\n",
    "\n",
    "# 输入子立方块\n",
    "cube_a = cube_a.permute(2, 0, 1).unsqueeze(0).float().cuda()  # 转换为 [batch_size, channels, height, width]\n",
    "cube_b = cube_b.permute(2, 0, 1).unsqueeze(0).float().cuda()\n",
    "\n",
    "# 提取特征\n",
    "features_a = feature_extractor(cube_a)  # 子块 A 的特征\n",
    "features_b = feature_extractor(cube_b)  # 子块 B 的特征\n",
    "\n",
    "print(f\"Features A Shape: {features_a.shape}\")  # 输出特征形状，例如 [batch_size, feature_dim]\n",
    "print(f\"Features B Shape: {features_b.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrastive Loss: 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# 初始化网络\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "\n",
    "# 投影特征\n",
    "proj_a = projection_head(features_a)  # 子块 A 的投影特征\n",
    "proj_b = projection_head(features_b)  # 子块 B 的投影特征\n",
    "\n",
    "# 计算对比损失\n",
    "temperature = 1.0\n",
    "loss = contrastive_loss_ce_hard_negatives(proj_a, proj_b, temperature,num_negatives=2)\n",
    "\n",
    "print(f\"Contrastive Loss: {loss.item()}\")  # 打印损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选 patch 样本数量: 3921\n",
      "Epoch [1/100], Loss: 0.2756\n",
      "Epoch [2/100], Loss: 0.2056\n",
      "Epoch [3/100], Loss: 0.1806\n",
      "Epoch [4/100], Loss: 0.1708\n",
      "Epoch [5/100], Loss: 0.1645\n",
      "Epoch [6/100], Loss: 0.1622\n",
      "Epoch [7/100], Loss: 0.1572\n",
      "Epoch [8/100], Loss: 0.1593\n",
      "Epoch [9/100], Loss: 0.1532\n",
      "Epoch [10/100], Loss: 0.1563\n",
      "Epoch [11/100], Loss: 0.1496\n",
      "Epoch [12/100], Loss: 0.1599\n",
      "Epoch [13/100], Loss: 0.1465\n",
      "Epoch [14/100], Loss: 0.1459\n",
      "Epoch [15/100], Loss: 0.1431\n",
      "Epoch [16/100], Loss: 0.1415\n",
      "Epoch [17/100], Loss: 0.1416\n",
      "Epoch [18/100], Loss: 0.1420\n",
      "Epoch [19/100], Loss: 0.1408\n",
      "Epoch [20/100], Loss: 0.1378\n",
      "Epoch [21/100], Loss: 0.1419\n",
      "Epoch [22/100], Loss: 0.1396\n",
      "Epoch [23/100], Loss: 0.1380\n",
      "Epoch [24/100], Loss: 0.1383\n",
      "Epoch [25/100], Loss: 0.1363\n",
      "Epoch [26/100], Loss: 0.1385\n",
      "Epoch [27/100], Loss: 0.1414\n",
      "Epoch [28/100], Loss: 0.1392\n",
      "Epoch [29/100], Loss: 0.1374\n",
      "Epoch [30/100], Loss: 0.1353\n",
      "Epoch [31/100], Loss: 0.1378\n",
      "Epoch [32/100], Loss: 0.1362\n",
      "Epoch [33/100], Loss: 0.1360\n",
      "Epoch [34/100], Loss: 0.1342\n",
      "Epoch [35/100], Loss: 0.1403\n",
      "Epoch [36/100], Loss: 0.1344\n",
      "Epoch [37/100], Loss: 0.1372\n",
      "Epoch [38/100], Loss: 0.1389\n",
      "Epoch [39/100], Loss: 0.1378\n",
      "Epoch [40/100], Loss: 0.1346\n",
      "Epoch [41/100], Loss: 0.1337\n",
      "Epoch [42/100], Loss: 0.1329\n",
      "Epoch [43/100], Loss: 0.1323\n",
      "Epoch [44/100], Loss: 0.1323\n",
      "Epoch [45/100], Loss: 0.1320\n",
      "Epoch [46/100], Loss: 0.1316\n",
      "Epoch [47/100], Loss: 0.1317\n",
      "Epoch [48/100], Loss: 0.1313\n",
      "Epoch [49/100], Loss: 0.1313\n",
      "Epoch [50/100], Loss: 0.1313\n",
      "Epoch [51/100], Loss: 0.1308\n",
      "Epoch [52/100], Loss: 0.1307\n",
      "Epoch [53/100], Loss: 0.1311\n",
      "Epoch [54/100], Loss: 0.1306\n",
      "Epoch [55/100], Loss: 0.1307\n",
      "Epoch [56/100], Loss: 0.1301\n",
      "Epoch [57/100], Loss: 0.1336\n",
      "Epoch [58/100], Loss: 0.1324\n",
      "Epoch [59/100], Loss: 0.1320\n",
      "Epoch [60/100], Loss: 0.1308\n",
      "Epoch [61/100], Loss: 0.1304\n",
      "Epoch [62/100], Loss: 0.1301\n",
      "Epoch [63/100], Loss: 0.1308\n",
      "Epoch [64/100], Loss: 0.1303\n",
      "Epoch [65/100], Loss: 0.1296\n",
      "Epoch [66/100], Loss: 0.1302\n",
      "Epoch [67/100], Loss: 0.1302\n",
      "Epoch [68/100], Loss: 0.1311\n",
      "Epoch [69/100], Loss: 0.1303\n",
      "Epoch [70/100], Loss: 0.1301\n",
      "Epoch [71/100], Loss: 0.1295\n",
      "Epoch [72/100], Loss: 0.1294\n",
      "Epoch [73/100], Loss: 0.1294\n",
      "Epoch [74/100], Loss: 0.1295\n",
      "Epoch [75/100], Loss: 0.1294\n",
      "Epoch [76/100], Loss: 0.1294\n",
      "Epoch [77/100], Loss: 0.1292\n",
      "Epoch [78/100], Loss: 0.1290\n",
      "Epoch [79/100], Loss: 0.1290\n",
      "Epoch [80/100], Loss: 0.1288\n",
      "Epoch [81/100], Loss: 0.1287\n",
      "Epoch [82/100], Loss: 0.1287\n",
      "Epoch [83/100], Loss: 0.1353\n",
      "Epoch [84/100], Loss: 0.1626\n",
      "Epoch [85/100], Loss: 0.1632\n",
      "Epoch [86/100], Loss: 0.1427\n",
      "Epoch [87/100], Loss: 0.1374\n",
      "Epoch [88/100], Loss: 0.1344\n",
      "Epoch [89/100], Loss: 0.1332\n",
      "Epoch [90/100], Loss: 0.1326\n",
      "Epoch [91/100], Loss: 0.1323\n",
      "Epoch [92/100], Loss: 0.1308\n",
      "Epoch [93/100], Loss: 0.1307\n",
      "Epoch [94/100], Loss: 0.1308\n",
      "Epoch [95/100], Loss: 0.1305\n",
      "Epoch [96/100], Loss: 0.1298\n",
      "Epoch [97/100], Loss: 0.1300\n",
      "Epoch [98/100], Loss: 0.1297\n",
      "Epoch [99/100], Loss: 0.1297\n",
      "Epoch [100/100], Loss: 0.1294\n",
      "Final model saved to final/Pavia_20_100ep.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CandidatePatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.coords[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # [C, H, W]\n",
    "        cube = torch.tensor(cube).permute(1, 2, 0)  # [H, W, C]\n",
    "        cube_a, cube_b = split_cube(cube)\n",
    "        cube_a = cube_a.permute(2, 0, 1)\n",
    "        cube_b = cube_b.permute(2, 0, 1)\n",
    "        return cube_a, cube_b\n",
    "\n",
    "\n",
    "# 初始化数据集和数据加载器\n",
    "pca_data_tensor = torch.tensor(pca_candidate_data).float()\n",
    "dataset = CandidatePatchDataset(pca_data_tensor, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "print(f\"候选 patch 样本数量: {len(dataset)}\") \n",
    "# 初始化网络和优化器\n",
    "feature_extractor = FeatureExtractor(input_channels=20).cuda()\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "# 创建保存模型的文件夹\n",
    "os.makedirs('./final', exist_ok=True)\n",
    "\n",
    "# 初始化变量用于保存损失值\n",
    "loss_values = []\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 100\n",
    "temperature = 1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        cube_a, cube_b = batch\n",
    "        cube_a, cube_b = cube_a.cuda(), cube_b.cuda()\n",
    "        \n",
    "        features_a = feature_extractor(cube_a)\n",
    "        features_b = feature_extractor(cube_b)\n",
    "        \n",
    "        proj_a = projection_head(features_a)\n",
    "        proj_b = projection_head(features_b)\n",
    "        \n",
    "        loss = contrastive_loss_ce_hard_negatives(proj_a, proj_b, temperature,num_negatives=2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 仅保存最后一个模型\n",
    "model_path = 'final/Pavia_20_100ep.pth'\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': num_epochs,\n",
    "        'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "        'projection_head_state_dict': projection_head.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss_values[-1],\n",
    "    },\n",
    "    model_path\n",
    ")\n",
    "print(f\"Final model saved to {model_path}\")\n",
    "\n",
    "# 绘制损失值曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/Pavia_original_fulld_100ep.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 42776\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "test_labels = extract_labels(test_truth, info['label_dict'])\n",
    "\n",
    "\n",
    "print(f\"Number of testing samples: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(70, 0, 0), (71, 0, 0), (72, 0, 0), (87, 0, 1), (88, 0, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing label distribution: Counter({1: 18649, 0: 6631, 5: 5029, 7: 3682, 3: 3064, 2: 2099, 4: 1345, 6: 1330, 8: 947})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "test_label_counts = Counter([label for _, _, label in test_labels])\n",
    "\n",
    "\n",
    "print(\"Testing label distribution:\", test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (20, 610, 340)\n",
      "Number of training samples: 90\n",
      "Number of testing samples: 42776\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 提取立方块函数\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "# PCA 降维函数\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    参数:\n",
    "        hsi_data: 高光谱数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: 保留的主成分数量\n",
    "    返回:\n",
    "        pca_data: 降维后的数据, 形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "\n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "\n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "\n",
    "    # 转换整个数据集\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "\n",
    "    # 恢复为原始图像的形状\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, torch.tensor(label - 1, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(train_truth.row, train_truth.col, train_truth.data)\n",
    "]\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "pca_data, explained_variance_ratio = apply_pca_train_only(pavia, train_truth, num_components=20)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "\n",
    "test_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(test_truth.row, test_truth.col, test_truth.data)\n",
    "]\n",
    "test_dataset = ClassificationDataset(pca_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印样本信息\n",
    "print(f\"PCA 降维后的数据形状: {pca_data.shape}\")\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载对比学习训练的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "#checkpoint_path = \"./pth/model_epoch_160.pth\"  # 修改为对比学习模型的路径\n",
    "checkpoint_path = \"final/Pavia_20_100ep.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n",
      "Epoch [1/200], Loss: 2.9801\n",
      "Epoch [2/200], Loss: 2.6209\n",
      "Epoch [3/200], Loss: 2.3445\n",
      "Epoch [4/200], Loss: 2.1556\n",
      "Epoch [5/200], Loss: 1.9707\n",
      "Epoch [6/200], Loss: 1.7975\n",
      "Epoch [7/200], Loss: 1.7081\n",
      "Epoch [8/200], Loss: 1.5971\n",
      "Epoch [9/200], Loss: 1.4980\n",
      "Epoch [10/200], Loss: 1.3861\n",
      "Epoch [11/200], Loss: 1.3271\n",
      "Epoch [12/200], Loss: 1.2895\n",
      "Epoch [13/200], Loss: 1.2202\n",
      "Epoch [14/200], Loss: 1.1230\n",
      "Epoch [15/200], Loss: 1.0471\n",
      "Epoch [16/200], Loss: 1.0042\n",
      "Epoch [17/200], Loss: 0.9385\n",
      "Epoch [18/200], Loss: 0.9659\n",
      "Epoch [19/200], Loss: 0.8608\n",
      "Epoch [20/200], Loss: 0.8097\n",
      "Epoch [21/200], Loss: 0.7606\n",
      "Epoch [22/200], Loss: 0.7829\n",
      "Epoch [23/200], Loss: 0.7377\n",
      "Epoch [24/200], Loss: 0.6803\n",
      "Epoch [25/200], Loss: 0.6513\n",
      "Epoch [26/200], Loss: 0.5930\n",
      "Epoch [27/200], Loss: 0.5498\n",
      "Epoch [28/200], Loss: 0.5863\n",
      "Epoch [29/200], Loss: 0.5242\n",
      "Epoch [30/200], Loss: 0.5168\n",
      "Epoch [31/200], Loss: 0.5156\n",
      "Epoch [32/200], Loss: 0.4800\n",
      "Epoch [33/200], Loss: 0.4574\n",
      "Epoch [34/200], Loss: 0.4436\n",
      "Epoch [35/200], Loss: 0.4112\n",
      "Epoch [36/200], Loss: 0.4299\n",
      "Epoch [37/200], Loss: 0.3740\n",
      "Epoch [38/200], Loss: 0.3821\n",
      "Epoch [39/200], Loss: 0.3229\n",
      "Epoch [40/200], Loss: 0.3309\n",
      "Epoch [41/200], Loss: 0.3480\n",
      "Epoch [42/200], Loss: 0.2997\n",
      "Epoch [43/200], Loss: 0.3115\n",
      "Epoch [44/200], Loss: 0.3006\n",
      "Epoch [45/200], Loss: 0.3175\n",
      "Epoch [46/200], Loss: 0.2364\n",
      "Epoch [47/200], Loss: 0.2660\n",
      "Epoch [48/200], Loss: 0.2328\n",
      "Epoch [49/200], Loss: 0.2661\n",
      "Epoch [50/200], Loss: 0.2130\n",
      "Epoch [51/200], Loss: 0.2291\n",
      "Epoch [52/200], Loss: 0.1847\n",
      "Epoch [53/200], Loss: 0.1989\n",
      "Epoch [54/200], Loss: 0.1914\n",
      "Epoch [55/200], Loss: 0.2191\n",
      "Epoch [56/200], Loss: 0.1750\n",
      "Epoch [57/200], Loss: 0.1986\n",
      "Epoch [58/200], Loss: 0.1598\n",
      "Epoch [59/200], Loss: 0.1779\n",
      "Epoch [60/200], Loss: 0.1302\n",
      "Epoch [61/200], Loss: 0.1540\n",
      "Epoch [62/200], Loss: 0.1450\n",
      "Epoch [63/200], Loss: 0.1304\n",
      "Epoch [64/200], Loss: 0.1348\n",
      "Epoch [65/200], Loss: 0.1217\n",
      "Epoch [66/200], Loss: 0.1067\n",
      "Epoch [67/200], Loss: 0.1289\n",
      "Epoch [68/200], Loss: 0.1003\n",
      "Epoch [69/200], Loss: 0.0969\n",
      "Epoch [70/200], Loss: 0.1583\n",
      "Epoch [71/200], Loss: 0.1274\n",
      "Epoch [72/200], Loss: 0.0823\n",
      "Epoch [73/200], Loss: 0.0852\n",
      "Epoch [74/200], Loss: 0.0849\n",
      "Epoch [75/200], Loss: 0.0828\n",
      "Epoch [76/200], Loss: 0.0813\n",
      "Epoch [77/200], Loss: 0.0756\n",
      "Epoch [78/200], Loss: 0.0958\n",
      "Epoch [79/200], Loss: 0.0866\n",
      "Epoch [80/200], Loss: 0.0803\n",
      "Epoch [81/200], Loss: 0.0644\n",
      "Epoch [82/200], Loss: 0.0735\n",
      "Epoch [83/200], Loss: 0.0822\n",
      "Epoch [84/200], Loss: 0.0601\n",
      "Epoch [85/200], Loss: 0.0714\n",
      "Epoch [86/200], Loss: 0.0475\n",
      "Epoch [87/200], Loss: 0.0468\n",
      "Epoch [88/200], Loss: 0.0515\n",
      "Epoch [89/200], Loss: 0.0522\n",
      "Epoch [90/200], Loss: 0.0461\n",
      "Epoch [91/200], Loss: 0.0429\n",
      "Epoch [92/200], Loss: 0.0758\n",
      "Epoch [93/200], Loss: 0.0438\n",
      "Epoch [94/200], Loss: 0.0466\n",
      "Epoch [95/200], Loss: 0.0440\n",
      "Epoch [96/200], Loss: 0.0405\n",
      "Epoch [97/200], Loss: 0.0873\n",
      "Epoch [98/200], Loss: 0.0449\n",
      "Epoch [99/200], Loss: 0.0339\n",
      "Epoch [100/200], Loss: 0.0404\n",
      "Epoch [101/200], Loss: 0.0474\n",
      "Epoch [102/200], Loss: 0.0325\n",
      "Epoch [103/200], Loss: 0.0353\n",
      "Epoch [104/200], Loss: 0.0334\n",
      "Epoch [105/200], Loss: 0.0280\n",
      "Epoch [106/200], Loss: 0.0352\n",
      "Epoch [107/200], Loss: 0.0254\n",
      "Epoch [108/200], Loss: 0.0281\n",
      "Epoch [109/200], Loss: 0.0378\n",
      "Epoch [110/200], Loss: 0.0287\n",
      "Epoch [111/200], Loss: 0.0244\n",
      "Epoch [112/200], Loss: 0.0226\n",
      "Epoch [113/200], Loss: 0.0276\n",
      "Epoch [114/200], Loss: 0.0273\n",
      "Epoch [115/200], Loss: 0.0246\n",
      "Epoch [116/200], Loss: 0.0260\n",
      "Epoch [117/200], Loss: 0.0311\n",
      "Epoch [118/200], Loss: 0.0221\n",
      "Epoch [119/200], Loss: 0.0226\n",
      "Epoch [120/200], Loss: 0.0204\n",
      "Epoch [121/200], Loss: 0.0255\n",
      "Epoch [122/200], Loss: 0.0176\n",
      "Epoch [123/200], Loss: 0.0176\n",
      "Epoch [124/200], Loss: 0.0246\n",
      "Epoch [125/200], Loss: 0.0247\n",
      "Epoch [126/200], Loss: 0.0170\n",
      "Epoch [127/200], Loss: 0.0201\n",
      "Epoch [128/200], Loss: 0.0181\n",
      "Epoch [129/200], Loss: 0.0153\n",
      "Epoch [130/200], Loss: 0.0154\n",
      "Epoch [131/200], Loss: 0.0145\n",
      "Epoch [132/200], Loss: 0.0221\n",
      "Epoch [133/200], Loss: 0.0151\n",
      "Epoch [134/200], Loss: 0.0474\n",
      "Epoch [135/200], Loss: 0.0184\n",
      "Epoch [136/200], Loss: 0.0176\n",
      "Epoch [137/200], Loss: 0.0352\n",
      "Epoch [138/200], Loss: 0.0487\n",
      "Epoch [139/200], Loss: 0.0172\n",
      "Epoch [140/200], Loss: 0.0303\n",
      "Epoch [141/200], Loss: 0.0221\n",
      "Epoch [142/200], Loss: 0.0156\n",
      "Epoch [143/200], Loss: 0.0124\n",
      "Epoch [144/200], Loss: 0.0116\n",
      "Epoch [145/200], Loss: 0.0114\n",
      "Epoch [146/200], Loss: 0.0151\n",
      "Epoch [147/200], Loss: 0.0104\n",
      "Epoch [148/200], Loss: 0.0223\n",
      "Epoch [149/200], Loss: 0.0141\n",
      "Epoch [150/200], Loss: 0.0098\n",
      "Epoch [151/200], Loss: 0.0169\n",
      "Epoch [152/200], Loss: 0.0095\n",
      "Epoch [153/200], Loss: 0.0176\n",
      "Epoch [154/200], Loss: 0.0140\n",
      "Epoch [155/200], Loss: 0.0162\n",
      "Epoch [156/200], Loss: 0.0136\n",
      "Epoch [157/200], Loss: 0.0102\n",
      "Epoch [158/200], Loss: 0.0096\n",
      "Epoch [159/200], Loss: 0.0074\n",
      "Epoch [160/200], Loss: 0.0134\n",
      "Epoch [161/200], Loss: 0.0118\n",
      "Epoch [162/200], Loss: 0.0125\n",
      "Epoch [163/200], Loss: 0.0086\n",
      "Epoch [164/200], Loss: 0.0087\n",
      "Epoch [165/200], Loss: 0.0145\n",
      "Epoch [166/200], Loss: 0.0079\n",
      "Epoch [167/200], Loss: 0.0066\n",
      "Epoch [168/200], Loss: 0.0108\n",
      "Epoch [169/200], Loss: 0.0071\n",
      "Epoch [170/200], Loss: 0.0078\n",
      "Epoch [171/200], Loss: 0.0101\n",
      "Epoch [172/200], Loss: 0.0080\n",
      "Epoch [173/200], Loss: 0.0211\n",
      "Epoch [174/200], Loss: 0.0063\n",
      "Epoch [175/200], Loss: 0.0132\n",
      "Epoch [176/200], Loss: 0.0068\n",
      "Epoch [177/200], Loss: 0.0066\n",
      "Epoch [178/200], Loss: 0.0070\n",
      "Epoch [179/200], Loss: 0.0118\n",
      "Epoch [180/200], Loss: 0.0059\n",
      "Epoch [181/200], Loss: 0.0139\n",
      "Epoch [182/200], Loss: 0.0058\n",
      "Epoch [183/200], Loss: 0.0056\n",
      "Epoch [184/200], Loss: 0.0077\n",
      "Epoch [185/200], Loss: 0.0075\n",
      "Epoch [186/200], Loss: 0.0100\n",
      "Epoch [187/200], Loss: 0.0065\n",
      "Epoch [188/200], Loss: 0.0129\n",
      "Epoch [189/200], Loss: 0.0052\n",
      "Epoch [190/200], Loss: 0.0068\n",
      "Epoch [191/200], Loss: 0.0075\n",
      "Epoch [192/200], Loss: 0.0061\n",
      "Epoch [193/200], Loss: 0.0091\n",
      "Epoch [194/200], Loss: 0.0053\n",
      "Epoch [195/200], Loss: 0.0084\n",
      "Epoch [196/200], Loss: 0.0075\n",
      "Epoch [197/200], Loss: 0.0060\n",
      "Epoch [198/200], Loss: 0.0128\n",
      "Epoch [199/200], Loss: 0.0051\n",
      "Epoch [200/200], Loss: 0.0069\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 20）\n",
    "feature_extractor = FeatureExtractor(input_channels=20).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 定义分类头\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=15).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练分类头和特征提取器\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()  # 微调特征提取器\n",
    "    classification_head.train()  # 训练分类头\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征\n",
    "            features = feature_extractor(cubes)\n",
    "\n",
    "            # 分类头进行训练\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7734\n",
      "Average Accuracy: 0.8329\n",
      "Kappa Coefficient: 0.7148\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 5582 predictions\n",
      "Class 1: 13864 predictions\n",
      "Class 2: 3447 predictions\n",
      "Class 3: 3183 predictions\n",
      "Class 4: 1417 predictions\n",
      "Class 5: 9025 predictions\n",
      "Class 6: 2059 predictions\n",
      "Class 7: 3248 predictions\n",
      "Class 8: 951 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.7352\n",
      "Class 1: 0.7354\n",
      "Class 2: 0.7627\n",
      "Class 3: 0.9664\n",
      "Class 4: 0.9955\n",
      "Class 5: 0.8616\n",
      "Class 6: 0.8699\n",
      "Class 7: 0.5902\n",
      "Class 8: 0.9789\n",
      "0.7352\n",
      "0.7354\n",
      "0.7627\n",
      "0.9664\n",
      "0.9955\n",
      "0.8616\n",
      "0.8699\n",
      "0.5902\n",
      "0.9789\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
