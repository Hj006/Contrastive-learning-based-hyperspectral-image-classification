{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_array\n",
    "import skimage.exposure\n",
    "from scipy.sparse import coo_matrix\n",
    "import warnings\n",
    "from io import StringIO\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\rasterio\\__init__.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHU shape: (270, 550, 400)\n",
      "Train samples: 90\n",
      "Candidate samples: 2700\n",
      "Test samples: 204542\n",
      "Test samples: 204542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_whu_longkou(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 WHU-Hi-LongKou 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 num_train_per_class 个作为训练样本\n",
    "    - 所有 ground truth 标签 > 0 的像素作为测试集\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 读取 hyperspectral 数据\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou.tif\") as src:\n",
    "        hyperspectral = src.read()  # shape: (bands, height, width)\n",
    "    c, h, w = hyperspectral.shape\n",
    "\n",
    "    # 读取 ground truth 标签\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou_gt.tif\") as src:\n",
    "        gt = src.read(1)  # shape: (height, width)\n",
    "\n",
    "    label_dict = {\n",
    "        1: '玉米', 2: '棉花', 3: '芝麻',\n",
    "        4: '圆叶大豆', 5: '长叶大豆', 6: '水稻',\n",
    "        7: '水体', 8: '房屋和道路', 9: '混合杂草',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\"类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    # 所有标签 > 0 的都作为测试样本\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return hyperspectral, train_truth, candidate_truth, test_truth, info\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\WHU\\Tiff_format\\WHU-Hi-LongKou\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 300, 2: 300, 3: 300,\n",
    "    4: 300, 5: 300, 6: 300,\n",
    "    7: 300, 8: 300, 9: 300\n",
    "}\n",
    "\n",
    "whu, train_truth, candidate_truth, test_truth, info = load_whu_longkou(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=10\n",
    ")\n",
    "\n",
    "print(f\"WHU shape: {whu.shape}\")  # 应该是 (270, 400, 550)\n",
    "print(f\"Train samples: {train_truth.count_nonzero()}\")         # 90\n",
    "print(f\"Candidate samples: {candidate_truth.count_nonzero()}\") # 2700\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           # 应该接近你截图里的 201842\n",
    "\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           # 应该接近你截图里的 201842\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计 train_truth 中的类别数量（非零值的唯一值数量）\n",
    "num_classes = len(set(train_truth.data))\n",
    "num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选区降维结果 shape: (180, 550, 400)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def apply_pca_on_candidate(hsi_data, candidate_truth, num_components=40, use_pca=True):\n",
    "    \"\"\"\n",
    "    在 candidate_truth 区域进行 PCA 或保留原始光谱，返回结果格式统一。\n",
    "\n",
    "    返回：\n",
    "    - data: shape [C, H, W]，只在候选区域填值，其余为 0\n",
    "    - samples: shape [N, C]，候选像素的特征\n",
    "    - coords: List of (row, col)\n",
    "    - explained_variance_ratio 或 None\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = candidate_truth.row, candidate_truth.col\n",
    "    spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "\n",
    "    coords = list(zip(rows, cols))\n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced = pca.fit_transform(spectra)  # shape: (N, num_components)\n",
    "        result_c = num_components\n",
    "        final_data = reduced\n",
    "        var_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        reduced = spectra  # shape: (N, C)\n",
    "        result_c = c\n",
    "        final_data = reduced\n",
    "        var_ratio = None\n",
    "\n",
    "    # 构建 [C, H, W] 格式，只填候选区域\n",
    "    candidate_data = np.zeros((result_c, h, w), dtype=np.float32)\n",
    "    for i, (r, c_) in enumerate(coords):\n",
    "        candidate_data[:, r, c_] = final_data[i]\n",
    "\n",
    "    return candidate_data, reduced, coords, var_ratio\n",
    "\n",
    "\n",
    "\n",
    "# 应用 PCA 降维\n",
    "pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(whu, candidate_truth, num_components=180)\n",
    "#不用pca降维\n",
    "#original_candidate_data, raw_samples, coords, _\n",
    "#pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(whu, candidate_truth, use_pca=False)\n",
    "\n",
    "print(f\"候选区降维结果 shape: {pca_candidate_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的立方块形状: (180, 11, 11)\n",
      "子立方块 A 形状: torch.Size([11, 11, 90])\n",
      "子立方块 B 形状: torch.Size([11, 11, 90])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    通道维度为奇数时，丢弃最后一个通道，保持对称划分。\n",
    "\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    if c % 2 != 0:\n",
    "        hsi_cube = hsi_cube[:, :, :c - 1]  # 丢掉最后一个通道\n",
    "    c1 = hsi_cube.shape[2] // 2\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "# 提取 11x11 的立方块\n",
    "s = 11  # 立方块的宽和高\n",
    "patch_size = (s, s)\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 进行对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "# 提取某像素点周围的立方块\n",
    "x, y = 100, 100  # 中心像素位置\n",
    "cube = extract_cube(pca_candidate_data, x, y, patch_size)\n",
    "print(\"提取的立方块形状:\", cube.shape)  # (40, 11, 11)\n",
    "# 切分通道\n",
    "cube_tensor = torch.tensor(cube).permute(1, 2, 0)  # 转换为 [H, W, C]\n",
    "cube_a, cube_b = split_cube(cube_tensor)\n",
    "\n",
    "print(\"子立方块 A 形状:\", cube_a.shape)  # (11, 11, 20)\n",
    "print(\"子立方块 B 形状:\", cube_b.shape)  # (11, 11, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=20):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features A Shape: torch.Size([1, 128])\n",
      "Features B Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取网络\n",
    "feature_extractor = FeatureExtractor(input_channels=90).cuda()\n",
    "\n",
    "# 输入子立方块\n",
    "cube_a = cube_a.permute(2, 0, 1).unsqueeze(0).float().cuda()  # 转换为 [batch_size, channels, height, width]\n",
    "cube_b = cube_b.permute(2, 0, 1).unsqueeze(0).float().cuda()\n",
    "\n",
    "# 提取特征\n",
    "features_a = feature_extractor(cube_a)  # 子块 A 的特征\n",
    "features_b = feature_extractor(cube_b)  # 子块 B 的特征\n",
    "\n",
    "print(f\"Features A Shape: {features_a.shape}\")  # 输出特征形状，例如 [batch_size, feature_dim]\n",
    "print(f\"Features B Shape: {features_b.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrastive Loss: 0.6936745643615723\n"
     ]
    }
   ],
   "source": [
    "# 初始化网络\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "\n",
    "# 投影特征\n",
    "proj_a = projection_head(features_a)  # 子块 A 的投影特征\n",
    "proj_b = projection_head(features_b)  # 子块 B 的投影特征\n",
    "\n",
    "# 计算对比损失\n",
    "temperature = 1.0\n",
    "loss = contrastive_loss(proj_a, proj_b, temperature)\n",
    "\n",
    "print(f\"Contrastive Loss: {loss.item()}\")  # 打印损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选 patch 样本数量: 2700\n",
      "Epoch [1/100], Loss: 5.8660\n",
      "Epoch [2/100], Loss: 5.6021\n",
      "Epoch [3/100], Loss: 5.4892\n",
      "Epoch [4/100], Loss: 5.4512\n",
      "Epoch [5/100], Loss: 5.4214\n",
      "Epoch [6/100], Loss: 5.4026\n",
      "Epoch [7/100], Loss: 5.3884\n",
      "Epoch [8/100], Loss: 5.3790\n",
      "Epoch [9/100], Loss: 5.3663\n",
      "Epoch [10/100], Loss: 5.3579\n",
      "Epoch [11/100], Loss: 5.3480\n",
      "Epoch [12/100], Loss: 5.3427\n",
      "Epoch [13/100], Loss: 5.3362\n",
      "Epoch [14/100], Loss: 5.3309\n",
      "Epoch [15/100], Loss: 5.3259\n",
      "Epoch [16/100], Loss: 5.3209\n",
      "Epoch [17/100], Loss: 5.3167\n",
      "Epoch [18/100], Loss: 5.3129\n",
      "Epoch [19/100], Loss: 5.3102\n",
      "Epoch [20/100], Loss: 5.3077\n",
      "Epoch [21/100], Loss: 5.3058\n",
      "Epoch [22/100], Loss: 5.3046\n",
      "Epoch [23/100], Loss: 5.3019\n",
      "Epoch [24/100], Loss: 5.2993\n",
      "Epoch [25/100], Loss: 5.2980\n",
      "Epoch [26/100], Loss: 5.2963\n",
      "Epoch [27/100], Loss: 5.2930\n",
      "Epoch [28/100], Loss: 5.2918\n",
      "Epoch [29/100], Loss: 5.2905\n",
      "Epoch [30/100], Loss: 5.2897\n",
      "Epoch [31/100], Loss: 5.2878\n",
      "Epoch [32/100], Loss: 5.2861\n",
      "Epoch [33/100], Loss: 5.2874\n",
      "Epoch [34/100], Loss: 5.2853\n",
      "Epoch [35/100], Loss: 5.2839\n",
      "Epoch [36/100], Loss: 5.2818\n",
      "Epoch [37/100], Loss: 5.2820\n",
      "Epoch [38/100], Loss: 5.2802\n",
      "Epoch [39/100], Loss: 5.2798\n",
      "Epoch [40/100], Loss: 5.2787\n",
      "Epoch [41/100], Loss: 5.2779\n",
      "Epoch [42/100], Loss: 5.2775\n",
      "Epoch [43/100], Loss: 5.2769\n",
      "Epoch [44/100], Loss: 5.2764\n",
      "Epoch [45/100], Loss: 5.2759\n",
      "Epoch [46/100], Loss: 5.2744\n",
      "Epoch [47/100], Loss: 5.2748\n",
      "Epoch [48/100], Loss: 5.2735\n",
      "Epoch [49/100], Loss: 5.2734\n",
      "Epoch [50/100], Loss: 5.2725\n",
      "Epoch [51/100], Loss: 5.2714\n",
      "Epoch [52/100], Loss: 5.2717\n",
      "Epoch [53/100], Loss: 5.2708\n",
      "Epoch [54/100], Loss: 5.2710\n",
      "Epoch [55/100], Loss: 5.2705\n",
      "Epoch [56/100], Loss: 5.2686\n",
      "Epoch [57/100], Loss: 5.2690\n",
      "Epoch [58/100], Loss: 5.2690\n",
      "Epoch [59/100], Loss: 5.2679\n",
      "Epoch [60/100], Loss: 5.2676\n",
      "Epoch [61/100], Loss: 5.2671\n",
      "Epoch [62/100], Loss: 5.2660\n",
      "Epoch [63/100], Loss: 5.2660\n",
      "Epoch [64/100], Loss: 5.2657\n",
      "Epoch [65/100], Loss: 5.2657\n",
      "Epoch [66/100], Loss: 5.2645\n",
      "Epoch [67/100], Loss: 5.2651\n",
      "Epoch [68/100], Loss: 5.2650\n",
      "Epoch [69/100], Loss: 5.2643\n",
      "Epoch [70/100], Loss: 5.2643\n",
      "Epoch [71/100], Loss: 5.2641\n",
      "Epoch [72/100], Loss: 5.2633\n",
      "Epoch [73/100], Loss: 5.2628\n",
      "Epoch [74/100], Loss: 5.2630\n",
      "Epoch [75/100], Loss: 5.2626\n",
      "Epoch [76/100], Loss: 5.2619\n",
      "Epoch [77/100], Loss: 5.2615\n",
      "Epoch [78/100], Loss: 5.2615\n",
      "Epoch [79/100], Loss: 5.2615\n",
      "Epoch [80/100], Loss: 5.2611\n",
      "Epoch [81/100], Loss: 5.2614\n",
      "Epoch [82/100], Loss: 5.2604\n",
      "Epoch [83/100], Loss: 5.2614\n",
      "Epoch [84/100], Loss: 5.2616\n",
      "Epoch [85/100], Loss: 5.2603\n",
      "Epoch [86/100], Loss: 5.2606\n",
      "Epoch [87/100], Loss: 5.2598\n",
      "Epoch [88/100], Loss: 5.2591\n",
      "Epoch [89/100], Loss: 5.2607\n",
      "Epoch [90/100], Loss: 5.2591\n",
      "Epoch [91/100], Loss: 5.2595\n",
      "Epoch [92/100], Loss: 5.2589\n",
      "Epoch [93/100], Loss: 5.2584\n",
      "Epoch [94/100], Loss: 5.2592\n",
      "Epoch [95/100], Loss: 5.2584\n",
      "Epoch [96/100], Loss: 5.2579\n",
      "Epoch [97/100], Loss: 5.2581\n",
      "Epoch [98/100], Loss: 5.2586\n",
      "Epoch [99/100], Loss: 5.2583\n",
      "Epoch [100/100], Loss: 5.2582\n",
      "Final model saved to final/Whu_original_fulld_1.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CandidatePatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.coords[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # [C, H, W]\n",
    "        cube = torch.tensor(cube).permute(1, 2, 0)  # [H, W, C]\n",
    "        cube_a, cube_b = split_cube(cube)\n",
    "        cube_a = cube_a.permute(2, 0, 1)\n",
    "        cube_b = cube_b.permute(2, 0, 1)\n",
    "        return cube_a, cube_b\n",
    "\n",
    "\n",
    "# 初始化数据集和数据加载器\n",
    "pca_data_tensor = torch.tensor(pca_candidate_data).float()\n",
    "dataset = CandidatePatchDataset(pca_data_tensor, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "print(f\"候选 patch 样本数量: {len(dataset)}\") \n",
    "# 初始化网络和优化器\n",
    "feature_extractor = FeatureExtractor(input_channels=90).cuda()\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "# 创建保存模型的文件夹\n",
    "os.makedirs('./pth', exist_ok=True)\n",
    "\n",
    "# 初始化变量用于保存损失值\n",
    "loss_values = []\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 100\n",
    "temperature = 1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        cube_a, cube_b = batch\n",
    "        cube_a, cube_b = cube_a.cuda(), cube_b.cuda()\n",
    "        \n",
    "        features_a = feature_extractor(cube_a)\n",
    "        features_b = feature_extractor(cube_b)\n",
    "        \n",
    "        proj_a = projection_head(features_a)\n",
    "        proj_b = projection_head(features_b)\n",
    "        \n",
    "        loss = contrastive_loss(proj_a, proj_b, temperature)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 仅保存最后一个模型\n",
    "model_path = 'final/Whu_original_fulld_1.pth'\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': num_epochs,\n",
    "        'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "        'projection_head_state_dict': projection_head.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss_values[-1],\n",
    "    },\n",
    "    model_path\n",
    ")\n",
    "print(f\"Final model saved to {model_path}\")\n",
    "\n",
    "# 绘制损失值曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/Whu_original_fulld_1.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 204542\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "test_labels = extract_labels(test_truth, info['label_dict'])\n",
    "\n",
    "\n",
    "print(f\"Number of testing samples: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0), (5, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing label distribution: Counter({6: 67056, 3: 63212, 0: 34511, 5: 11854, 1: 8374, 7: 7124, 8: 5229, 4: 4151, 2: 3031})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "test_label_counts = Counter([label for _, _, label in test_labels])\n",
    "\n",
    "\n",
    "print(\"Testing label distribution:\", test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (90, 550, 400)\n",
      "Number of training samples: 90\n",
      "Number of testing samples: 204542\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 提取立方块函数\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "# PCA 降维函数\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    参数:\n",
    "        hsi_data: 高光谱数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: 保留的主成分数量\n",
    "    返回:\n",
    "        pca_data: 降维后的数据, 形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "\n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "\n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components, svd_solver='auto')\n",
    "\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "\n",
    "    # 转换整个数据集\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "\n",
    "    # 恢复为原始图像的形状\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, torch.tensor(label - 1, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(train_truth.row, train_truth.col, train_truth.data)\n",
    "]\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "pca_data, explained_variance_ratio = apply_pca_train_only(whu, train_truth, num_components=90)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "\n",
    "test_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(test_truth.row, test_truth.col, test_truth.data)\n",
    "]\n",
    "test_dataset = ClassificationDataset(pca_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 打印样本信息\n",
    "print(f\"PCA 降维后的数据形状: {pca_data.shape}\")\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载对比学习训练的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "checkpoint_path = \"./final/Whu_original_fulld_1.pth\"  # 修改为对比学习模型的路径\n",
    "#checkpoint_path = \"final/Whu_original_20d_1.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n",
      "Epoch [1/200], Loss: 3.0668\n",
      "Epoch [2/200], Loss: 2.7918\n",
      "Epoch [3/200], Loss: 2.5406\n",
      "Epoch [4/200], Loss: 2.3147\n",
      "Epoch [5/200], Loss: 2.1135\n",
      "Epoch [6/200], Loss: 1.9380\n",
      "Epoch [7/200], Loss: 1.7856\n",
      "Epoch [8/200], Loss: 1.6543\n",
      "Epoch [9/200], Loss: 1.5407\n",
      "Epoch [10/200], Loss: 1.4411\n",
      "Epoch [11/200], Loss: 1.3528\n",
      "Epoch [12/200], Loss: 1.2741\n",
      "Epoch [13/200], Loss: 1.2026\n",
      "Epoch [14/200], Loss: 1.1375\n",
      "Epoch [15/200], Loss: 1.0776\n",
      "Epoch [16/200], Loss: 1.0221\n",
      "Epoch [17/200], Loss: 0.9699\n",
      "Epoch [18/200], Loss: 0.9200\n",
      "Epoch [19/200], Loss: 0.8723\n",
      "Epoch [20/200], Loss: 0.8264\n",
      "Epoch [21/200], Loss: 0.7828\n",
      "Epoch [22/200], Loss: 0.7412\n",
      "Epoch [23/200], Loss: 0.7018\n",
      "Epoch [24/200], Loss: 0.6645\n",
      "Epoch [25/200], Loss: 0.6292\n",
      "Epoch [26/200], Loss: 0.5957\n",
      "Epoch [27/200], Loss: 0.5637\n",
      "Epoch [28/200], Loss: 0.5333\n",
      "Epoch [29/200], Loss: 0.5043\n",
      "Epoch [30/200], Loss: 0.4768\n",
      "Epoch [31/200], Loss: 0.4505\n",
      "Epoch [32/200], Loss: 0.4255\n",
      "Epoch [33/200], Loss: 0.4018\n",
      "Epoch [34/200], Loss: 0.3792\n",
      "Epoch [35/200], Loss: 0.3578\n",
      "Epoch [36/200], Loss: 0.3375\n",
      "Epoch [37/200], Loss: 0.3183\n",
      "Epoch [38/200], Loss: 0.3001\n",
      "Epoch [39/200], Loss: 0.2828\n",
      "Epoch [40/200], Loss: 0.2664\n",
      "Epoch [41/200], Loss: 0.2509\n",
      "Epoch [42/200], Loss: 0.2361\n",
      "Epoch [43/200], Loss: 0.2223\n",
      "Epoch [44/200], Loss: 0.2092\n",
      "Epoch [45/200], Loss: 0.1970\n",
      "Epoch [46/200], Loss: 0.1855\n",
      "Epoch [47/200], Loss: 0.1747\n",
      "Epoch [48/200], Loss: 0.1646\n",
      "Epoch [49/200], Loss: 0.1551\n",
      "Epoch [50/200], Loss: 0.1462\n",
      "Epoch [51/200], Loss: 0.1379\n",
      "Epoch [52/200], Loss: 0.1302\n",
      "Epoch [53/200], Loss: 0.1230\n",
      "Epoch [54/200], Loss: 0.1163\n",
      "Epoch [55/200], Loss: 0.1100\n",
      "Epoch [56/200], Loss: 0.1041\n",
      "Epoch [57/200], Loss: 0.0986\n",
      "Epoch [58/200], Loss: 0.0935\n",
      "Epoch [59/200], Loss: 0.0887\n",
      "Epoch [60/200], Loss: 0.0842\n",
      "Epoch [61/200], Loss: 0.0800\n",
      "Epoch [62/200], Loss: 0.0761\n",
      "Epoch [63/200], Loss: 0.0724\n",
      "Epoch [64/200], Loss: 0.0690\n",
      "Epoch [65/200], Loss: 0.0659\n",
      "Epoch [66/200], Loss: 0.0629\n",
      "Epoch [67/200], Loss: 0.0601\n",
      "Epoch [68/200], Loss: 0.0575\n",
      "Epoch [69/200], Loss: 0.0551\n",
      "Epoch [70/200], Loss: 0.0528\n",
      "Epoch [71/200], Loss: 0.0507\n",
      "Epoch [72/200], Loss: 0.0487\n",
      "Epoch [73/200], Loss: 0.0468\n",
      "Epoch [74/200], Loss: 0.0450\n",
      "Epoch [75/200], Loss: 0.0434\n",
      "Epoch [76/200], Loss: 0.0418\n",
      "Epoch [77/200], Loss: 0.0404\n",
      "Epoch [78/200], Loss: 0.0390\n",
      "Epoch [79/200], Loss: 0.0376\n",
      "Epoch [80/200], Loss: 0.0364\n",
      "Epoch [81/200], Loss: 0.0352\n",
      "Epoch [82/200], Loss: 0.0341\n",
      "Epoch [83/200], Loss: 0.0330\n",
      "Epoch [84/200], Loss: 0.0321\n",
      "Epoch [85/200], Loss: 0.0311\n",
      "Epoch [86/200], Loss: 0.0302\n",
      "Epoch [87/200], Loss: 0.0293\n",
      "Epoch [88/200], Loss: 0.0285\n",
      "Epoch [89/200], Loss: 0.0277\n",
      "Epoch [90/200], Loss: 0.0270\n",
      "Epoch [91/200], Loss: 0.0263\n",
      "Epoch [92/200], Loss: 0.0256\n",
      "Epoch [93/200], Loss: 0.0250\n",
      "Epoch [94/200], Loss: 0.0243\n",
      "Epoch [95/200], Loss: 0.0237\n",
      "Epoch [96/200], Loss: 0.0232\n",
      "Epoch [97/200], Loss: 0.0226\n",
      "Epoch [98/200], Loss: 0.0221\n",
      "Epoch [99/200], Loss: 0.0216\n",
      "Epoch [100/200], Loss: 0.0211\n",
      "Epoch [101/200], Loss: 0.0207\n",
      "Epoch [102/200], Loss: 0.0202\n",
      "Epoch [103/200], Loss: 0.0198\n",
      "Epoch [104/200], Loss: 0.0194\n",
      "Epoch [105/200], Loss: 0.0190\n",
      "Epoch [106/200], Loss: 0.0186\n",
      "Epoch [107/200], Loss: 0.0182\n",
      "Epoch [108/200], Loss: 0.0179\n",
      "Epoch [109/200], Loss: 0.0175\n",
      "Epoch [110/200], Loss: 0.0172\n",
      "Epoch [111/200], Loss: 0.0169\n",
      "Epoch [112/200], Loss: 0.0166\n",
      "Epoch [113/200], Loss: 0.0163\n",
      "Epoch [114/200], Loss: 0.0160\n",
      "Epoch [115/200], Loss: 0.0157\n",
      "Epoch [116/200], Loss: 0.0154\n",
      "Epoch [117/200], Loss: 0.0152\n",
      "Epoch [118/200], Loss: 0.0149\n",
      "Epoch [119/200], Loss: 0.0146\n",
      "Epoch [120/200], Loss: 0.0144\n",
      "Epoch [121/200], Loss: 0.0142\n",
      "Epoch [122/200], Loss: 0.0139\n",
      "Epoch [123/200], Loss: 0.0137\n",
      "Epoch [124/200], Loss: 0.0135\n",
      "Epoch [125/200], Loss: 0.0133\n",
      "Epoch [126/200], Loss: 0.0131\n",
      "Epoch [127/200], Loss: 0.0129\n",
      "Epoch [128/200], Loss: 0.0127\n",
      "Epoch [129/200], Loss: 0.0125\n",
      "Epoch [130/200], Loss: 0.0123\n",
      "Epoch [131/200], Loss: 0.0121\n",
      "Epoch [132/200], Loss: 0.0119\n",
      "Epoch [133/200], Loss: 0.0118\n",
      "Epoch [134/200], Loss: 0.0116\n",
      "Epoch [135/200], Loss: 0.0114\n",
      "Epoch [136/200], Loss: 0.0113\n",
      "Epoch [137/200], Loss: 0.0111\n",
      "Epoch [138/200], Loss: 0.0110\n",
      "Epoch [139/200], Loss: 0.0108\n",
      "Epoch [140/200], Loss: 0.0107\n",
      "Epoch [141/200], Loss: 0.0105\n",
      "Epoch [142/200], Loss: 0.0104\n",
      "Epoch [143/200], Loss: 0.0103\n",
      "Epoch [144/200], Loss: 0.0101\n",
      "Epoch [145/200], Loss: 0.0100\n",
      "Epoch [146/200], Loss: 0.0099\n",
      "Epoch [147/200], Loss: 0.0097\n",
      "Epoch [148/200], Loss: 0.0096\n",
      "Epoch [149/200], Loss: 0.0095\n",
      "Epoch [150/200], Loss: 0.0094\n",
      "Epoch [151/200], Loss: 0.0093\n",
      "Epoch [152/200], Loss: 0.0092\n",
      "Epoch [153/200], Loss: 0.0090\n",
      "Epoch [154/200], Loss: 0.0089\n",
      "Epoch [155/200], Loss: 0.0088\n",
      "Epoch [156/200], Loss: 0.0087\n",
      "Epoch [157/200], Loss: 0.0086\n",
      "Epoch [158/200], Loss: 0.0085\n",
      "Epoch [159/200], Loss: 0.0084\n",
      "Epoch [160/200], Loss: 0.0083\n",
      "Epoch [161/200], Loss: 0.0082\n",
      "Epoch [162/200], Loss: 0.0081\n",
      "Epoch [163/200], Loss: 0.0080\n",
      "Epoch [164/200], Loss: 0.0080\n",
      "Epoch [165/200], Loss: 0.0079\n",
      "Epoch [166/200], Loss: 0.0078\n",
      "Epoch [167/200], Loss: 0.0077\n",
      "Epoch [168/200], Loss: 0.0076\n",
      "Epoch [169/200], Loss: 0.0075\n",
      "Epoch [170/200], Loss: 0.0074\n",
      "Epoch [171/200], Loss: 0.0074\n",
      "Epoch [172/200], Loss: 0.0073\n",
      "Epoch [173/200], Loss: 0.0072\n",
      "Epoch [174/200], Loss: 0.0071\n",
      "Epoch [175/200], Loss: 0.0071\n",
      "Epoch [176/200], Loss: 0.0070\n",
      "Epoch [177/200], Loss: 0.0069\n",
      "Epoch [178/200], Loss: 0.0068\n",
      "Epoch [179/200], Loss: 0.0068\n",
      "Epoch [180/200], Loss: 0.0067\n",
      "Epoch [181/200], Loss: 0.0066\n",
      "Epoch [182/200], Loss: 0.0066\n",
      "Epoch [183/200], Loss: 0.0065\n",
      "Epoch [184/200], Loss: 0.0065\n",
      "Epoch [185/200], Loss: 0.0064\n",
      "Epoch [186/200], Loss: 0.0063\n",
      "Epoch [187/200], Loss: 0.0063\n",
      "Epoch [188/200], Loss: 0.0062\n",
      "Epoch [189/200], Loss: 0.0061\n",
      "Epoch [190/200], Loss: 0.0061\n",
      "Epoch [191/200], Loss: 0.0060\n",
      "Epoch [192/200], Loss: 0.0060\n",
      "Epoch [193/200], Loss: 0.0059\n",
      "Epoch [194/200], Loss: 0.0059\n",
      "Epoch [195/200], Loss: 0.0058\n",
      "Epoch [196/200], Loss: 0.0058\n",
      "Epoch [197/200], Loss: 0.0057\n",
      "Epoch [198/200], Loss: 0.0057\n",
      "Epoch [199/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0056\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 20）\n",
    "feature_extractor = FeatureExtractor(input_channels=90).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 定义分类头\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=15).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练分类头和特征提取器\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()  # 微调特征提取器\n",
    "    classification_head.train()  # 训练分类头\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征\n",
    "            features = feature_extractor(cubes)\n",
    "\n",
    "            # 分类头进行训练\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9474\n",
      "Average Accuracy: 0.9313\n",
      "Kappa Coefficient: 0.9317\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 35297 predictions\n",
      "Class 1: 9349 predictions\n",
      "Class 2: 4742 predictions\n",
      "Class 3: 56468 predictions\n",
      "Class 4: 6789 predictions\n",
      "Class 5: 11225 predictions\n",
      "Class 6: 66888 predictions\n",
      "Class 7: 9509 predictions\n",
      "Class 8: 4275 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.9946\n",
      "Class 1: 0.9331\n",
      "Class 2: 0.9957\n",
      "Class 3: 0.8869\n",
      "Class 4: 0.9475\n",
      "Class 5: 0.9432\n",
      "Class 6: 0.9964\n",
      "Class 7: 0.9672\n",
      "Class 8: 0.7168\n",
      "0.9946\n",
      "0.9331\n",
      "0.9957\n",
      "0.8869\n",
      "0.9475\n",
      "0.9432\n",
      "0.9964\n",
      "0.9672\n",
      "0.7168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
