{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffPage 0 @2949772> parsing GDAL_NODATA tag raised ValueError('-3.4028234663852886e+38 is not castable to float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASI shape: (144, 349, 1905)\n",
      "LiDAR shape: (1, 349, 1905)\n",
      "Train truth non-zero: 225\n",
      "Test truth non-zero: 12197\n",
      "Label dictionary: {1: 'Healthy grass', 2: 'Stressed grass', 3: 'Synthetic grass', 4: 'Trees', 5: 'Soil', 6: 'Water', 7: 'Residential', 8: 'Commercial', 9: 'Road', 10: 'Highway', 11: 'Railway', 12: 'Parking Lot 1', 13: 'Parking Lot 2', 14: 'Tennis Court', 15: 'Running Track'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_array\n",
    "import skimage.exposure\n",
    "from scipy.sparse import coo_matrix\n",
    "import warnings\n",
    "from io import StringIO\n",
    "\n",
    "def _read_roi(path: Path, shape) -> coo_matrix:\n",
    "    \"\"\"\n",
    "    读取 ENVI 软件导出 ROI 文件的 txt 文件，生成一个稀疏矩阵，表示每个像素点的类别标签。\n",
    "    \n",
    "    :param path: 文件路径，ENVI ROI 文件的路径\n",
    "    :param shape: 图像的形状（height, width）\n",
    "    :return: 一个稀疏矩阵，非零值表示像素点的类别标签\n",
    "    \"\"\"\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)  # 忽略 loadtxt 的警告\n",
    "    data = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "    current_label = 0\n",
    "    buffer = \"\"\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            # 判断是否为新 ROI 的分割点\n",
    "            if line.strip() == \"\" or line.startswith(\";\") or \"ROI\" in line:\n",
    "                if buffer:  # 如果缓冲区有内容，解析为坐标数据\n",
    "                    roi_data = np.loadtxt(StringIO(buffer), usecols=(2, 1), dtype=int)\n",
    "                    if roi_data.size > 0:\n",
    "                        r, c = roi_data.T\n",
    "                        rows.extend(r)\n",
    "                        cols.extend(c)\n",
    "                        data.extend([current_label] * len(r))\n",
    "                    buffer = \"\"  # 清空缓冲区\n",
    "                # 如果遇到 ROI name 行，增加类别标签\n",
    "                if \"ROI name\" in line:\n",
    "                    current_label += 1\n",
    "            else:\n",
    "                buffer += line  # 将数据加入缓冲区\n",
    "\n",
    "        # 处理最后一个 ROI\n",
    "        if buffer:\n",
    "            roi_data = np.loadtxt(StringIO(buffer), usecols=(2, 1), dtype=int)\n",
    "            if roi_data.size > 0:\n",
    "                r, c = roi_data.T\n",
    "                rows.extend(r)\n",
    "                cols.extend(c)\n",
    "                data.extend([current_label] * len(r))\n",
    "\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "    # 创建稀疏矩阵\n",
    "    img = coo_matrix((data, (rows, cols)), shape=shape, dtype=int)\n",
    "    return img\n",
    "\n",
    "\n",
    "def sample_train_from_candidate(candidate_truth, num_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    从 candidate_truth 中每个类别随机抽取固定数量作为新的训练样本。\n",
    "    \n",
    "    参数:\n",
    "        candidate_truth: coo_matrix, 原始训练稀疏标签\n",
    "        num_per_class: int, 每类抽取数量\n",
    "        seed: int, 随机种子\n",
    "\n",
    "    返回:\n",
    "        train_truth: coo_matrix, 新的训练样本矩阵\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    rows, cols, labels = candidate_truth.row, candidate_truth.col, candidate_truth.data\n",
    "    new_rows, new_cols, new_labels = [], [], []\n",
    "\n",
    "    unique_classes = np.unique(labels)\n",
    "    for cls in unique_classes:\n",
    "        indices = np.where(labels == cls)[0]\n",
    "        if len(indices) < num_per_class:\n",
    "            raise ValueError(f\"类 {cls} 样本不足，只有 {len(indices)} 个，无法抽取 {num_per_class} 个\")\n",
    "        chosen = np.random.choice(indices, num_per_class, replace=False)\n",
    "        new_rows.extend(rows[chosen])\n",
    "        new_cols.extend(cols[chosen])\n",
    "        new_labels.extend(labels[chosen])\n",
    "\n",
    "    shape = candidate_truth.shape\n",
    "    train_truth = coo_matrix((new_labels, (new_rows, new_cols)), shape=shape, dtype=int)\n",
    "    return train_truth\n",
    "def load_houston2013(data_path: Path):\n",
    "    \"\"\"\n",
    "    从本地路径加载 Houston2013 数据集。\n",
    "\n",
    "    :param data_path: 数据集的根目录路径。\n",
    "    :return: (casi, lidar, train_truth, test_truth, info)\n",
    "    \"\"\"\n",
    "    FILES_PATH = data_path\n",
    "    assert FILES_PATH.exists(), f\"{FILES_PATH} does not exist. Please check the path.\"\n",
    "\n",
    "    # 加载图像数据\n",
    "    lidar = skimage.io.imread(FILES_PATH / '2013_IEEE_GRSS_DF_Contest_LiDAR.tif')[np.newaxis, :, :]  # (1, 349, 1905)\n",
    "    casi = skimage.io.imread(FILES_PATH / '2013_IEEE_GRSS_DF_Contest_CASI.tif').transpose(2, 0, 1)   # (144, 349, 1905)\n",
    "\n",
    "    # 加载训练集和测试集的真值\n",
    "    train_truth = _read_roi(FILES_PATH / '2013_IEEE_GRSS_DF_Contest_Samples_TR.txt', (349, 1905))\n",
    "    test_truth = _read_roi(FILES_PATH / '2013_IEEE_GRSS_DF_Contest_Samples_VA.txt', (349, 1905))\n",
    "\n",
    "    # 数据集元信息\n",
    "    info = {\n",
    "        'n_band_casi': 144,\n",
    "        'n_band_lidar': 1,\n",
    "        'width': 1905,\n",
    "        'height': 349,\n",
    "        'label_dict': {\n",
    "            1: 'Healthy grass',\n",
    "            2: 'Stressed grass',\n",
    "            3: 'Synthetic grass',\n",
    "            4: 'Trees',\n",
    "            5: 'Soil',\n",
    "            6: 'Water',\n",
    "            7: 'Residential',\n",
    "            8: 'Commercial',\n",
    "            9: 'Road',\n",
    "            10: 'Highway',\n",
    "            11: 'Railway',\n",
    "            12: 'Parking Lot 1',\n",
    "            13: 'Parking Lot 2',\n",
    "            14: 'Tennis Court',\n",
    "            15: 'Running Track',\n",
    "        }\n",
    "    }\n",
    "    # 原始 train_truth 作为候选样本\n",
    "    candidate_truth = train_truth\n",
    "\n",
    "    # 从候选中随机抽样为正式训练集\n",
    "    train_truth = sample_train_from_candidate(candidate_truth, num_per_class=15)\n",
    "\n",
    "    return casi, lidar, train_truth, candidate_truth, test_truth, info\n",
    "\n",
    "\n",
    "# 指定数据集路径\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\Houston2013\\2013_DFTC\")\n",
    "\n",
    "# 加载数据集\n",
    "casi, lidar, train_truth, candidate_truth, test_truth, info = load_houston2013(data_path)\n",
    "\n",
    "# 打印数据集基本信息\n",
    "print(f\"CASI shape: {casi.shape}\")   # 高光谱图像 (144, 349, 1905)\n",
    "print(f\"LiDAR shape: {lidar.shape}\")  # LiDAR 数据 (1, 349, 1905)\n",
    "print(f\"Train truth non-zero: {train_truth.count_nonzero()}\")  # 训练集非零样本数\n",
    "print(f\"Test truth non-zero: {test_truth.count_nonzero()}\")    # 测试集非零样本数\n",
    "print(f\"Label dictionary: {info['label_dict']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计 train_truth 中的类别数量（非零值的唯一值数量）\n",
    "num_classes = len(set(train_truth.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<349x1905 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 12422 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def merge_train_test(train_truth, test_truth, shape):\n",
    "    \"\"\"\n",
    "    合并训练集和测试集稀疏矩阵为一个新的训练集矩阵。\n",
    "    \n",
    "    参数:\n",
    "        train_truth: coo_matrix, 原始训练集稀疏矩阵\n",
    "        test_truth: coo_matrix, 原始测试集稀疏矩阵\n",
    "        shape: tuple, 数据的形状 (height, width)\n",
    "        \n",
    "    返回:\n",
    "        merged_truth: coo_matrix, 合并后的训练集稀疏矩阵\n",
    "    \"\"\"\n",
    "    # 合并行、列和数据\n",
    "    merged_rows = np.concatenate([train_truth.row, test_truth.row])\n",
    "    merged_cols = np.concatenate([train_truth.col, test_truth.col])\n",
    "    merged_data = np.concatenate([train_truth.data, test_truth.data])\n",
    "    \n",
    "    # 创建新的稀疏矩阵\n",
    "    merged_truth = coo_matrix((merged_data, (merged_rows, merged_cols)), shape=shape)\n",
    "    return merged_truth\n",
    "\n",
    "# 合并训练集和测试集为新的训练集\n",
    "merged_train_truth = merge_train_test(train_truth, test_truth, (349, 1905))\n",
    "merged_train_truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (60, 349, 1905)\n",
      "PCA 累计解释方差比: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def apply_pca_on_candidate(hsi_data, candidate_truth, num_components=40, use_pca=True):\n",
    "    \"\"\"\n",
    "    在 candidate_truth 区域进行 PCA 或保留原始光谱，返回结果格式统一。\n",
    "\n",
    "    返回：\n",
    "    - data: shape [C, H, W]，只在候选区域填值，其余为 0\n",
    "    - samples: shape [N, C]，候选像素的特征\n",
    "    - coords: List of (row, col)\n",
    "    - explained_variance_ratio 或 None\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = candidate_truth.row, candidate_truth.col\n",
    "    spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "\n",
    "    coords = list(zip(rows, cols))\n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced = pca.fit_transform(spectra)  # shape: (N, num_components)\n",
    "        result_c = num_components\n",
    "        final_data = reduced\n",
    "        var_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        reduced = spectra  # shape: (N, C)\n",
    "        result_c = c\n",
    "        final_data = reduced\n",
    "        var_ratio = None\n",
    "\n",
    "    # 构建 [C, H, W] 格式，只填候选区域\n",
    "    candidate_data = np.zeros((result_c, h, w), dtype=np.float32)\n",
    "    for i, (r, c_) in enumerate(coords):\n",
    "        candidate_data[:, r, c_] = final_data[i]\n",
    "\n",
    "    return candidate_data, reduced, coords, var_ratio\n",
    "com =60\n",
    "# 应用 PCA 降维\n",
    "pca_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(casi, candidate_truth, num_components=com)\n",
    "\n",
    "print(f\"PCA 降维后的数据形状: {pca_data.shape}\")  # (40, 349, 1905)\n",
    "print(f\"PCA 累计解释方差比: {np.sum(var_ratio):.4f}\")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的立方块形状: (60, 11, 11)\n",
      "子立方块 A 形状: torch.Size([11, 11, 30])\n",
      "子立方块 B 形状: torch.Size([11, 11, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    c1 = c // 2  # 每个子块保留一半的通道\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "# 提取 11x11 的立方块\n",
    "s = 11  # 立方块的宽和高\n",
    "patch_size = (s, s)\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 进行对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "# 提取某像素点周围的立方块\n",
    "x, y = 100, 100  # 中心像素位置\n",
    "cube = extract_cube(pca_data, x, y, patch_size)\n",
    "print(\"提取的立方块形状:\", cube.shape)  # (40, 11, 11)\n",
    "# 切分通道\n",
    "cube_tensor = torch.tensor(cube).permute(1, 2, 0)  # 转换为 [H, W, C]\n",
    "cube_a, cube_b = split_cube(cube_tensor)\n",
    "\n",
    "print(\"子立方块 A 形状:\", cube_a.shape)  # (11, 11, 20)\n",
    "print(\"子立方块 B 形状:\", cube_b.shape)  # (11, 11, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=20):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cpu\n",
      "torch.float32 cpu\n"
     ]
    }
   ],
   "source": [
    "print(cube_a.dtype, cube_a.device)\n",
    "print(cube_b.dtype, cube_b.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n",
    "\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5007\n",
      "Epoch [2/50], Loss: 0.4428\n",
      "Epoch [3/50], Loss: 0.4396\n",
      "Epoch [4/50], Loss: 0.4382\n",
      "Epoch [5/50], Loss: 0.4372\n",
      "Epoch [6/50], Loss: 0.4365\n",
      "Epoch [7/50], Loss: 0.4361\n",
      "Epoch [8/50], Loss: 0.4359\n",
      "Epoch [9/50], Loss: 0.4356\n",
      "Epoch [10/50], Loss: 0.4354\n",
      "Epoch [11/50], Loss: 0.4355\n",
      "Epoch [12/50], Loss: 0.4352\n",
      "Epoch [13/50], Loss: 0.4351\n",
      "Epoch [14/50], Loss: 0.4351\n",
      "Epoch [15/50], Loss: 0.4350\n",
      "Epoch [16/50], Loss: 0.4349\n",
      "Epoch [17/50], Loss: 0.4349\n",
      "Epoch [18/50], Loss: 0.4348\n",
      "Epoch [19/50], Loss: 0.4348\n",
      "Epoch [20/50], Loss: 0.4348\n",
      "Epoch [21/50], Loss: 0.4347\n",
      "Epoch [22/50], Loss: 0.4347\n",
      "Epoch [23/50], Loss: 0.4347\n",
      "Epoch [24/50], Loss: 0.4347\n",
      "Epoch [25/50], Loss: 0.4346\n",
      "Epoch [26/50], Loss: 0.4346\n",
      "Epoch [27/50], Loss: 0.4346\n",
      "Epoch [28/50], Loss: 0.4346\n",
      "Epoch [29/50], Loss: 0.4345\n",
      "Epoch [30/50], Loss: 0.4346\n",
      "Epoch [31/50], Loss: 0.4345\n",
      "Epoch [32/50], Loss: 0.4345\n",
      "Epoch [33/50], Loss: 0.4345\n",
      "Epoch [34/50], Loss: 0.4345\n",
      "Epoch [35/50], Loss: 0.4346\n",
      "Epoch [36/50], Loss: 0.4345\n",
      "Epoch [37/50], Loss: 0.4344\n",
      "Epoch [38/50], Loss: 0.4344\n",
      "Epoch [39/50], Loss: 0.4344\n",
      "Epoch [40/50], Loss: 0.4345\n",
      "Epoch [41/50], Loss: 0.4344\n",
      "Epoch [42/50], Loss: 0.4345\n",
      "Epoch [43/50], Loss: 0.4344\n",
      "Epoch [44/50], Loss: 0.4344\n",
      "Epoch [45/50], Loss: 0.4344\n",
      "Epoch [46/50], Loss: 0.4344\n",
      "Epoch [47/50], Loss: 0.4344\n",
      "Epoch [48/50], Loss: 0.4344\n",
      "Epoch [49/50], Loss: 0.4345\n",
      "Epoch [50/50], Loss: 0.4345\n",
      "Model saved at epoch 50 to final/Hous_lin_50_model1_60ep.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 自定义数据集类\n",
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, pca_data, patch_size=11, num_samples=1000):\n",
    "        self.data = pca_data  # PCA 降维后的高光谱数据\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.h, self.w = pca_data.shape[1], pca_data.shape[2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.randint(self.patch_size // 2, self.h - self.patch_size // 2, (1,)).item()\n",
    "        y = torch.randint(self.patch_size // 2, self.w - self.patch_size // 2, (1,)).item()\n",
    "        \n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))\n",
    "        cube_tensor = torch.tensor(cube).permute(1, 2, 0)\n",
    "        \n",
    "        cube_a, cube_b = split_cube(cube_tensor)\n",
    "        cube_a = cube_a.permute(2, 0, 1)\n",
    "        cube_b = cube_b.permute(2, 0, 1)\n",
    "        \n",
    "        return cube_a, cube_b\n",
    "\n",
    "\n",
    "class MultiPositivePatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 展平坐标：一个中心对应 4 个邻居位置\n",
    "        self.flattened_coords = []\n",
    "        for x, y in coords:\n",
    "            self.flattened_coords += [\n",
    "                (x, y, x-1, y),  # 上\n",
    "                (x, y, x+1, y),  # 下\n",
    "                (x, y, x, y-1),  # 左\n",
    "                (x, y, x, y+1),  # 右\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1, x2, y2 = self.flattened_coords[idx]\n",
    "        patch_a = extract_cube(self.data, x1, y1, (self.patch_size, self.patch_size))\n",
    "        patch_b = extract_cube(self.data, x2, y2, (self.patch_size, self.patch_size))\n",
    "        patch_a = torch.tensor(patch_a, dtype=torch.float32)\n",
    "        patch_b = torch.tensor(patch_b, dtype=torch.float32)\n",
    "        return patch_a, patch_b\n",
    "\n",
    "class MultiPositivePatchDataset1(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 展平坐标：一个中心对应 4 个邻居位置\n",
    "        self.flattened_coords = []\n",
    "        for x, y in coords:\n",
    "            self.flattened_coords += [\n",
    "                (x, y, x-1, y),  # 上\n",
    "                (x, y, x+1, y),  # 下\n",
    "                (x, y, x, y-1),  # 左\n",
    "                (x, y, x, y+1),  # 右\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1, x2, y2 = self.flattened_coords[idx]\n",
    "        patch_a = extract_cube(self.data, x1, y1, (self.patch_size, self.patch_size))\n",
    "        patch_b = extract_cube(self.data, x2, y2, (self.patch_size, self.patch_size))\n",
    "        \n",
    "        patch_a = torch.tensor(patch_a, dtype=torch.float32)  # shape: (C, H, W)\n",
    "        patch_b = torch.tensor(patch_b, dtype=torch.float32)\n",
    "\n",
    "        # 拆分光谱维度 C\n",
    "        C = patch_a.shape[0]\n",
    "        c_half = C // 2\n",
    "        a1, a2 = patch_a[:c_half], patch_a[c_half:]\n",
    "        b1, b2 = patch_b[:c_half], patch_b[c_half:]\n",
    "\n",
    "        # 组合成混合补丁\n",
    "        patch_mix1 = torch.cat([a1, b1], dim=0)  # shape: (C, H, W)\n",
    "        patch_mix2 = torch.cat([a2, b2], dim=0)\n",
    "\n",
    "        return patch_mix1, patch_mix2\n",
    "pca_data_tensor = torch.tensor(pca_data).float()\n",
    "dataset = MultiPositivePatchDataset(pca_data_tensor, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)  # 每 batch 会生成 64×4=256 对\n",
    "\n",
    "# 初始化网络和优化器\n",
    "feature_extractor = FeatureExtractor(input_channels=com).cuda()\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "\n",
    "# 训练循环\n",
    "#os.mkdir('final')\n",
    "num_epochs = 50\n",
    "loss_values = []\n",
    "temperature = 1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for cube_a, cube_b in dataloader:  #\n",
    "        cube_a, cube_b = cube_a.cuda(), cube_b.cuda()\n",
    "\n",
    "        # 提取特征\n",
    "        features_a = feature_extractor(cube_a)\n",
    "        features_b = feature_extractor(cube_b)\n",
    "\n",
    "        # 投影\n",
    "        proj_a = projection_head(features_a)\n",
    "        proj_b = projection_head(features_b)\n",
    "\n",
    "        # 计算对比损失\n",
    "        loss = contrastive_loss_ce_hard_negatives(proj_a,proj_b, temperature=1, num_negatives=5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 在第50、100、150轮存储模型\n",
    "    if (epoch + 1) in [50, 100, 150]:\n",
    "        model_path = f'final/Hous_lin_{epoch+1}_model1_60ep.pth'\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "                'projection_head_state_dict': projection_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            },\n",
    "            model_path\n",
    "        )\n",
    "        print(f\"Model saved at epoch {epoch+1} to {model_path}\")\n",
    "\n",
    "# 训练完成后绘制损失值曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/Hous_lin_50_model1_60ep.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 12197\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "test_labels = extract_labels(test_truth, info['label_dict'])\n",
    "\n",
    "\n",
    "print(f\"Number of testing samples: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing label distribution: Counter({6: 1072, 1: 1064, 8: 1059, 3: 1056, 4: 1056, 10: 1054, 0: 1053, 7: 1053, 11: 1041, 9: 1036, 2: 505, 14: 473, 12: 285, 13: 247, 5: 143})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "test_label_counts = Counter([label for _, _, label in test_labels])\n",
    "\n",
    "\n",
    "print(\"Testing label distribution:\", test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 提取立方块函数\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "# PCA 降维函数\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    参数:\n",
    "        hsi_data: 高光谱数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: 保留的主成分数量\n",
    "    返回:\n",
    "        pca_data: 降维后的数据, 形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "\n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "\n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "\n",
    "    # 转换整个数据集\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "\n",
    "    # 恢复为原始图像的形状\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, label\n",
    "\n",
    "\n",
    "# 候选集生成函数\n",
    "def create_candidate_dataset(train_labels, num_classes, samples_per_class):\n",
    "    \"\"\"\n",
    "    从训练样本中按每类抽取指定数量的样本，构造候选集。\n",
    "    参数:\n",
    "        train_labels: 原始训练样本 [(row, col, label), ...]\n",
    "        num_classes: 类别数量\n",
    "        samples_per_class: 每个类别抽取的样本数量\n",
    "    返回:\n",
    "        candidate_labels: 候选样本 [(row, col, label), ...]\n",
    "    \"\"\"\n",
    "    class_samples = defaultdict(list)\n",
    "    for sample in train_labels:\n",
    "        class_samples[sample[2]].append(sample)\n",
    "\n",
    "    candidate_labels = []\n",
    "    for cls in range(num_classes):\n",
    "        if cls in class_samples:\n",
    "            samples = class_samples[cls]\n",
    "            if len(samples) < samples_per_class:\n",
    "                print(f\"Warning: Class {cls} has only {len(samples)} samples, less than {samples_per_class}.\")\n",
    "            candidate_labels.extend(random.sample(samples, min(samples_per_class, len(samples))))\n",
    "        else:\n",
    "            print(f\"Warning: Class {cls} has no samples in training set.\")\n",
    "    return candidate_labels\n",
    "\n",
    "\n",
    "def extract_labels(truth, label_dict):\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 标签从 1~15 映射为 0~14\n",
    "    return [(r, c, label - 1) for r, c, label in zip(rows, cols, labels)]\n",
    "\n",
    "num_classes = len(set(train_truth.data))\n",
    "\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = extract_labels(train_truth, info['label_dict'])\n",
    "test_labels = extract_labels(test_truth, info['label_dict'])\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "pca_data, explained_variance_ratio = apply_pca_train_only(casi, train_truth, num_components=20)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "\n",
    "test_dataset = ClassificationDataset(pca_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载对比学习训练的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "#checkpoint_path = \"./pth/model_epoch_160.pth\"  # 修改为对比学习模型的路径\n",
    "checkpoint_path = \"final/Hous_lin_50_model1_20ep.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n",
      "Epoch [1/200], Loss: 2.7285\n",
      "Epoch [2/200], Loss: 2.3452\n",
      "Epoch [3/200], Loss: 2.1501\n",
      "Epoch [4/200], Loss: 1.9466\n",
      "Epoch [5/200], Loss: 1.7633\n",
      "Epoch [6/200], Loss: 1.6330\n",
      "Epoch [7/200], Loss: 1.4997\n",
      "Epoch [8/200], Loss: 1.4057\n",
      "Epoch [9/200], Loss: 1.3275\n",
      "Epoch [10/200], Loss: 1.2098\n",
      "Epoch [11/200], Loss: 1.1650\n",
      "Epoch [12/200], Loss: 1.1001\n",
      "Epoch [13/200], Loss: 1.0328\n",
      "Epoch [14/200], Loss: 1.0002\n",
      "Epoch [15/200], Loss: 0.9275\n",
      "Epoch [16/200], Loss: 0.8903\n",
      "Epoch [17/200], Loss: 0.8611\n",
      "Epoch [18/200], Loss: 0.8223\n",
      "Epoch [19/200], Loss: 0.7636\n",
      "Epoch [20/200], Loss: 0.7049\n",
      "Epoch [21/200], Loss: 0.7190\n",
      "Epoch [22/200], Loss: 0.6697\n",
      "Epoch [23/200], Loss: 0.6148\n",
      "Epoch [24/200], Loss: 0.6375\n",
      "Epoch [25/200], Loss: 0.5971\n",
      "Epoch [26/200], Loss: 0.5526\n",
      "Epoch [27/200], Loss: 0.5474\n",
      "Epoch [28/200], Loss: 0.5072\n",
      "Epoch [29/200], Loss: 0.4856\n",
      "Epoch [30/200], Loss: 0.4646\n",
      "Epoch [31/200], Loss: 0.4354\n",
      "Epoch [32/200], Loss: 0.4450\n",
      "Epoch [33/200], Loss: 0.4495\n",
      "Epoch [34/200], Loss: 0.3923\n",
      "Epoch [35/200], Loss: 0.3490\n",
      "Epoch [36/200], Loss: 0.3564\n",
      "Epoch [37/200], Loss: 0.3973\n",
      "Epoch [38/200], Loss: 0.3486\n",
      "Epoch [39/200], Loss: 0.3230\n",
      "Epoch [40/200], Loss: 0.3029\n",
      "Epoch [41/200], Loss: 0.3266\n",
      "Epoch [42/200], Loss: 0.3141\n",
      "Epoch [43/200], Loss: 0.2876\n",
      "Epoch [44/200], Loss: 0.2406\n",
      "Epoch [45/200], Loss: 0.2674\n",
      "Epoch [46/200], Loss: 0.2392\n",
      "Epoch [47/200], Loss: 0.2441\n",
      "Epoch [48/200], Loss: 0.2250\n",
      "Epoch [49/200], Loss: 0.2137\n",
      "Epoch [50/200], Loss: 0.2175\n",
      "Epoch [51/200], Loss: 0.2076\n",
      "Epoch [52/200], Loss: 0.1942\n",
      "Epoch [53/200], Loss: 0.1890\n",
      "Epoch [54/200], Loss: 0.1699\n",
      "Epoch [55/200], Loss: 0.1941\n",
      "Epoch [56/200], Loss: 0.1534\n",
      "Epoch [57/200], Loss: 0.1813\n",
      "Epoch [58/200], Loss: 0.1421\n",
      "Epoch [59/200], Loss: 0.1346\n",
      "Epoch [60/200], Loss: 0.1367\n",
      "Epoch [61/200], Loss: 0.1272\n",
      "Epoch [62/200], Loss: 0.1372\n",
      "Epoch [63/200], Loss: 0.1363\n",
      "Epoch [64/200], Loss: 0.1313\n",
      "Epoch [65/200], Loss: 0.1245\n",
      "Epoch [66/200], Loss: 0.1172\n",
      "Epoch [67/200], Loss: 0.1526\n",
      "Epoch [68/200], Loss: 0.1385\n",
      "Epoch [69/200], Loss: 0.0970\n",
      "Epoch [70/200], Loss: 0.0990\n",
      "Epoch [71/200], Loss: 0.0825\n",
      "Epoch [72/200], Loss: 0.0896\n",
      "Epoch [73/200], Loss: 0.0773\n",
      "Epoch [74/200], Loss: 0.0971\n",
      "Epoch [75/200], Loss: 0.0620\n",
      "Epoch [76/200], Loss: 0.0854\n",
      "Epoch [77/200], Loss: 0.0776\n",
      "Epoch [78/200], Loss: 0.0588\n",
      "Epoch [79/200], Loss: 0.0696\n",
      "Epoch [80/200], Loss: 0.0573\n",
      "Epoch [81/200], Loss: 0.0609\n",
      "Epoch [82/200], Loss: 0.0524\n",
      "Epoch [83/200], Loss: 0.0594\n",
      "Epoch [84/200], Loss: 0.0610\n",
      "Epoch [85/200], Loss: 0.0474\n",
      "Epoch [86/200], Loss: 0.0623\n",
      "Epoch [87/200], Loss: 0.0566\n",
      "Epoch [88/200], Loss: 0.0439\n",
      "Epoch [89/200], Loss: 0.0538\n",
      "Epoch [90/200], Loss: 0.0466\n",
      "Epoch [91/200], Loss: 0.0393\n",
      "Epoch [92/200], Loss: 0.0337\n",
      "Epoch [93/200], Loss: 0.0336\n",
      "Epoch [94/200], Loss: 0.0369\n",
      "Epoch [95/200], Loss: 0.0591\n",
      "Epoch [96/200], Loss: 0.0369\n",
      "Epoch [97/200], Loss: 0.0309\n",
      "Epoch [98/200], Loss: 0.0386\n",
      "Epoch [99/200], Loss: 0.0349\n",
      "Epoch [100/200], Loss: 0.0279\n",
      "Epoch [101/200], Loss: 0.0284\n",
      "Epoch [102/200], Loss: 0.0251\n",
      "Epoch [103/200], Loss: 0.0258\n",
      "Epoch [104/200], Loss: 0.0257\n",
      "Epoch [105/200], Loss: 0.0286\n",
      "Epoch [106/200], Loss: 0.0260\n",
      "Epoch [107/200], Loss: 0.0295\n",
      "Epoch [108/200], Loss: 0.0190\n",
      "Epoch [109/200], Loss: 0.0270\n",
      "Epoch [110/200], Loss: 0.0188\n",
      "Epoch [111/200], Loss: 0.0241\n",
      "Epoch [112/200], Loss: 0.0202\n",
      "Epoch [113/200], Loss: 0.0501\n",
      "Epoch [114/200], Loss: 0.0234\n",
      "Epoch [115/200], Loss: 0.0313\n",
      "Epoch [116/200], Loss: 0.0259\n",
      "Epoch [117/200], Loss: 0.0252\n",
      "Epoch [118/200], Loss: 0.0173\n",
      "Epoch [119/200], Loss: 0.0185\n",
      "Epoch [120/200], Loss: 0.0249\n",
      "Epoch [121/200], Loss: 0.0171\n",
      "Epoch [122/200], Loss: 0.0305\n",
      "Epoch [123/200], Loss: 0.0127\n",
      "Epoch [124/200], Loss: 0.0213\n",
      "Epoch [125/200], Loss: 0.0213\n",
      "Epoch [126/200], Loss: 0.0178\n",
      "Epoch [127/200], Loss: 0.0232\n",
      "Epoch [128/200], Loss: 0.0169\n",
      "Epoch [129/200], Loss: 0.0149\n",
      "Epoch [130/200], Loss: 0.0193\n",
      "Epoch [131/200], Loss: 0.0143\n",
      "Epoch [132/200], Loss: 0.0148\n",
      "Epoch [133/200], Loss: 0.0130\n",
      "Epoch [134/200], Loss: 0.0125\n",
      "Epoch [135/200], Loss: 0.0150\n",
      "Epoch [136/200], Loss: 0.0125\n",
      "Epoch [137/200], Loss: 0.0093\n",
      "Epoch [138/200], Loss: 0.0121\n",
      "Epoch [139/200], Loss: 0.0131\n",
      "Epoch [140/200], Loss: 0.0098\n",
      "Epoch [141/200], Loss: 0.0100\n",
      "Epoch [142/200], Loss: 0.0102\n",
      "Epoch [143/200], Loss: 0.0197\n",
      "Epoch [144/200], Loss: 0.0088\n",
      "Epoch [145/200], Loss: 0.0117\n",
      "Epoch [146/200], Loss: 0.0092\n",
      "Epoch [147/200], Loss: 0.0160\n",
      "Epoch [148/200], Loss: 0.0099\n",
      "Epoch [149/200], Loss: 0.0084\n",
      "Epoch [150/200], Loss: 0.0089\n",
      "Epoch [151/200], Loss: 0.0146\n",
      "Epoch [152/200], Loss: 0.0093\n",
      "Epoch [153/200], Loss: 0.0106\n",
      "Epoch [154/200], Loss: 0.0102\n",
      "Epoch [155/200], Loss: 0.0084\n",
      "Epoch [156/200], Loss: 0.0085\n",
      "Epoch [157/200], Loss: 0.0095\n",
      "Epoch [158/200], Loss: 0.0067\n",
      "Epoch [159/200], Loss: 0.0075\n",
      "Epoch [160/200], Loss: 0.0091\n",
      "Epoch [161/200], Loss: 0.0081\n",
      "Epoch [162/200], Loss: 0.0094\n",
      "Epoch [163/200], Loss: 0.0073\n",
      "Epoch [164/200], Loss: 0.0113\n",
      "Epoch [165/200], Loss: 0.0086\n",
      "Epoch [166/200], Loss: 0.0085\n",
      "Epoch [167/200], Loss: 0.0073\n",
      "Epoch [168/200], Loss: 0.0072\n",
      "Epoch [169/200], Loss: 0.0124\n",
      "Epoch [170/200], Loss: 0.0083\n",
      "Epoch [171/200], Loss: 0.0090\n",
      "Epoch [172/200], Loss: 0.0064\n",
      "Epoch [173/200], Loss: 0.0053\n",
      "Epoch [174/200], Loss: 0.0066\n",
      "Epoch [175/200], Loss: 0.0047\n",
      "Epoch [176/200], Loss: 0.0071\n",
      "Epoch [177/200], Loss: 0.0066\n",
      "Epoch [178/200], Loss: 0.0093\n",
      "Epoch [179/200], Loss: 0.0091\n",
      "Epoch [180/200], Loss: 0.0064\n",
      "Epoch [181/200], Loss: 0.0090\n",
      "Epoch [182/200], Loss: 0.0049\n",
      "Epoch [183/200], Loss: 0.0131\n",
      "Epoch [184/200], Loss: 0.0052\n",
      "Epoch [185/200], Loss: 0.0093\n",
      "Epoch [186/200], Loss: 0.0092\n",
      "Epoch [187/200], Loss: 0.0086\n",
      "Epoch [188/200], Loss: 0.0052\n",
      "Epoch [189/200], Loss: 0.0072\n",
      "Epoch [190/200], Loss: 0.0048\n",
      "Epoch [191/200], Loss: 0.0051\n",
      "Epoch [192/200], Loss: 0.0050\n",
      "Epoch [193/200], Loss: 0.0067\n",
      "Epoch [194/200], Loss: 0.0053\n",
      "Epoch [195/200], Loss: 0.0054\n",
      "Epoch [196/200], Loss: 0.0060\n",
      "Epoch [197/200], Loss: 0.0046\n",
      "Epoch [198/200], Loss: 0.0122\n",
      "Epoch [199/200], Loss: 0.0057\n",
      "Epoch [200/200], Loss: 0.0055\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 20）\n",
    "feature_extractor = FeatureExtractor(input_channels=20).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 定义分类头\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=15).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练分类头和特征提取器\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()  # 微调特征提取器\n",
    "    classification_head.train()  # 训练分类头\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda().long()\n",
    "\n",
    "            # 提取特征\n",
    "            features = feature_extractor(cubes)\n",
    "\n",
    "            # 分类头进行训练\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7838\n",
      "Average Accuracy: 0.7858\n",
      "Kappa Coefficient: 0.7657\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 886 predictions\n",
      "Class 1: 960 predictions\n",
      "Class 2: 915 predictions\n",
      "Class 3: 977 predictions\n",
      "Class 4: 1099 predictions\n",
      "Class 5: 172 predictions\n",
      "Class 6: 1852 predictions\n",
      "Class 7: 622 predictions\n",
      "Class 8: 994 predictions\n",
      "Class 9: 709 predictions\n",
      "Class 10: 817 predictions\n",
      "Class 11: 1151 predictions\n",
      "Class 12: 349 predictions\n",
      "Class 13: 256 predictions\n",
      "Class 14: 438 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.8224\n",
      "Class 1: 0.8477\n",
      "Class 2: 0.8594\n",
      "Class 3: 0.9081\n",
      "Class 4: 0.9744\n",
      "Class 5: 0.7133\n",
      "Class 6: 0.8881\n",
      "Class 7: 0.5261\n",
      "Class 8: 0.7762\n",
      "Class 9: 0.5396\n",
      "Class 10: 0.5977\n",
      "Class 11: 0.8915\n",
      "Class 12: 0.8702\n",
      "Class 13: 0.7449\n",
      "Class 14: 0.8266\n",
      "0.8224\n",
      "0.8477\n",
      "0.8594\n",
      "0.9081\n",
      "0.9744\n",
      "0.7133\n",
      "0.8881\n",
      "0.5261\n",
      "0.7762\n",
      "0.5396\n",
      "0.5977\n",
      "0.8915\n",
      "0.8702\n",
      "0.7449\n",
      "0.8266\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Seed 42 → OA: 0.7902, AA: 0.8037, Kappa: 0.7732\n",
      "[2/100] Seed 43 → OA: 0.7994, AA: 0.8108, Kappa: 0.7829\n",
      "[3/100] Seed 44 → OA: 0.7764, AA: 0.7831, Kappa: 0.7583\n",
      "[4/100] Seed 45 → OA: 0.7899, AA: 0.8000, Kappa: 0.7729\n",
      "[5/100] Seed 46 → OA: 0.7904, AA: 0.7960, Kappa: 0.7733\n",
      "[6/100] Seed 47 → OA: 0.8028, AA: 0.8056, Kappa: 0.7867\n",
      "[7/100] Seed 48 → OA: 0.7939, AA: 0.7976, Kappa: 0.7768\n",
      "[8/100] Seed 49 → OA: 0.7949, AA: 0.7980, Kappa: 0.7780\n",
      "[9/100] Seed 50 → OA: 0.7848, AA: 0.7992, Kappa: 0.7673\n",
      "[10/100] Seed 51 → OA: 0.8090, AA: 0.8206, Kappa: 0.7930\n",
      "[11/100] Seed 52 → OA: 0.7843, AA: 0.7909, Kappa: 0.7669\n",
      "[12/100] Seed 53 → OA: 0.7813, AA: 0.7860, Kappa: 0.7636\n",
      "[13/100] Seed 54 → OA: 0.7835, AA: 0.7884, Kappa: 0.7659\n",
      "[14/100] Seed 55 → OA: 0.7910, AA: 0.8033, Kappa: 0.7741\n",
      "[15/100] Seed 56 → OA: 0.7981, AA: 0.8038, Kappa: 0.7818\n",
      "[16/100] Seed 57 → OA: 0.7932, AA: 0.8092, Kappa: 0.7758\n",
      "[17/100] Seed 58 → OA: 0.8002, AA: 0.8118, Kappa: 0.7834\n",
      "[18/100] Seed 59 → OA: 0.7848, AA: 0.7898, Kappa: 0.7674\n",
      "[19/100] Seed 60 → OA: 0.7897, AA: 0.8013, Kappa: 0.7720\n",
      "[20/100] Seed 61 → OA: 0.8023, AA: 0.8036, Kappa: 0.7863\n",
      "[21/100] Seed 62 → OA: 0.7843, AA: 0.7874, Kappa: 0.7667\n",
      "[22/100] Seed 63 → OA: 0.7878, AA: 0.7965, Kappa: 0.7703\n",
      "[23/100] Seed 64 → OA: 0.7913, AA: 0.7940, Kappa: 0.7744\n",
      "[24/100] Seed 65 → OA: 0.7895, AA: 0.7980, Kappa: 0.7724\n",
      "[25/100] Seed 66 → OA: 0.7873, AA: 0.7958, Kappa: 0.7696\n",
      "[26/100] Seed 67 → OA: 0.8022, AA: 0.8131, Kappa: 0.7862\n",
      "[27/100] Seed 68 → OA: 0.7762, AA: 0.7821, Kappa: 0.7580\n",
      "[28/100] Seed 69 → OA: 0.7945, AA: 0.8012, Kappa: 0.7780\n",
      "[29/100] Seed 70 → OA: 0.7732, AA: 0.7762, Kappa: 0.7549\n",
      "[30/100] Seed 71 → OA: 0.7977, AA: 0.8063, Kappa: 0.7812\n",
      "[31/100] Seed 72 → OA: 0.7837, AA: 0.7870, Kappa: 0.7662\n",
      "[32/100] Seed 73 → OA: 0.7845, AA: 0.7847, Kappa: 0.7665\n",
      "[33/100] Seed 74 → OA: 0.7863, AA: 0.8046, Kappa: 0.7691\n",
      "[34/100] Seed 75 → OA: 0.7912, AA: 0.7986, Kappa: 0.7740\n",
      "[35/100] Seed 76 → OA: 0.7881, AA: 0.7874, Kappa: 0.7708\n",
      "[36/100] Seed 77 → OA: 0.7853, AA: 0.7977, Kappa: 0.7679\n",
      "[37/100] Seed 78 → OA: 0.7927, AA: 0.8055, Kappa: 0.7758\n",
      "[38/100] Seed 79 → OA: 0.8011, AA: 0.8127, Kappa: 0.7850\n",
      "[39/100] Seed 80 → OA: 0.7947, AA: 0.8073, Kappa: 0.7779\n",
      "[40/100] Seed 81 → OA: 0.7881, AA: 0.7952, Kappa: 0.7707\n",
      "[41/100] Seed 82 → OA: 0.7905, AA: 0.8040, Kappa: 0.7735\n",
      "[42/100] Seed 83 → OA: 0.7918, AA: 0.7994, Kappa: 0.7747\n",
      "[43/100] Seed 84 → OA: 0.7888, AA: 0.7992, Kappa: 0.7711\n",
      "[44/100] Seed 85 → OA: 0.7888, AA: 0.8035, Kappa: 0.7716\n",
      "[45/100] Seed 86 → OA: 0.7895, AA: 0.7981, Kappa: 0.7721\n",
      "[46/100] Seed 87 → OA: 0.7883, AA: 0.8029, Kappa: 0.7711\n",
      "[47/100] Seed 88 → OA: 0.7927, AA: 0.8107, Kappa: 0.7757\n",
      "[48/100] Seed 89 → OA: 0.7813, AA: 0.7862, Kappa: 0.7636\n",
      "[49/100] Seed 90 → OA: 0.8008, AA: 0.8117, Kappa: 0.7841\n",
      "[50/100] Seed 91 → OA: 0.7877, AA: 0.8060, Kappa: 0.7705\n",
      "[51/100] Seed 92 → OA: 0.7927, AA: 0.8080, Kappa: 0.7759\n",
      "[52/100] Seed 93 → OA: 0.7954, AA: 0.8038, Kappa: 0.7788\n",
      "[53/100] Seed 94 → OA: 0.7899, AA: 0.7954, Kappa: 0.7728\n",
      "[54/100] Seed 95 → OA: 0.8024, AA: 0.8075, Kappa: 0.7863\n",
      "[55/100] Seed 96 → OA: 0.7942, AA: 0.8070, Kappa: 0.7769\n",
      "[56/100] Seed 97 → OA: 0.7808, AA: 0.7981, Kappa: 0.7631\n",
      "[57/100] Seed 98 → OA: 0.7954, AA: 0.8098, Kappa: 0.7789\n",
      "[58/100] Seed 99 → OA: 0.7806, AA: 0.7872, Kappa: 0.7627\n",
      "[59/100] Seed 100 → OA: 0.7918, AA: 0.8160, Kappa: 0.7751\n",
      "[60/100] Seed 101 → OA: 0.7762, AA: 0.7859, Kappa: 0.7581\n",
      "[61/100] Seed 102 → OA: 0.7980, AA: 0.8028, Kappa: 0.7810\n",
      "[62/100] Seed 103 → OA: 0.7930, AA: 0.8009, Kappa: 0.7757\n",
      "[63/100] Seed 104 → OA: 0.7828, AA: 0.7898, Kappa: 0.7646\n",
      "[64/100] Seed 105 → OA: 0.7796, AA: 0.7824, Kappa: 0.7617\n",
      "[65/100] Seed 106 → OA: 0.7805, AA: 0.7794, Kappa: 0.7628\n",
      "[66/100] Seed 107 → OA: 0.8046, AA: 0.8194, Kappa: 0.7885\n",
      "[67/100] Seed 108 → OA: 0.8020, AA: 0.7974, Kappa: 0.7858\n",
      "[68/100] Seed 109 → OA: 0.7848, AA: 0.7967, Kappa: 0.7673\n",
      "[69/100] Seed 110 → OA: 0.7822, AA: 0.7953, Kappa: 0.7645\n",
      "[70/100] Seed 111 → OA: 0.7872, AA: 0.7938, Kappa: 0.7699\n",
      "[71/100] Seed 112 → OA: 0.7943, AA: 0.8040, Kappa: 0.7776\n",
      "[72/100] Seed 113 → OA: 0.7970, AA: 0.8111, Kappa: 0.7807\n",
      "[73/100] Seed 114 → OA: 0.7916, AA: 0.7989, Kappa: 0.7743\n",
      "[74/100] Seed 115 → OA: 0.7924, AA: 0.8007, Kappa: 0.7756\n",
      "[75/100] Seed 116 → OA: 0.7791, AA: 0.7899, Kappa: 0.7611\n",
      "[76/100] Seed 117 → OA: 0.7938, AA: 0.8017, Kappa: 0.7770\n",
      "[77/100] Seed 118 → OA: 0.7938, AA: 0.7967, Kappa: 0.7770\n",
      "[78/100] Seed 119 → OA: 0.7847, AA: 0.7853, Kappa: 0.7666\n",
      "[79/100] Seed 120 → OA: 0.8010, AA: 0.8055, Kappa: 0.7841\n",
      "[80/100] Seed 121 → OA: 0.7877, AA: 0.7977, Kappa: 0.7698\n",
      "[81/100] Seed 122 → OA: 0.7750, AA: 0.7838, Kappa: 0.7568\n",
      "[82/100] Seed 123 → OA: 0.7798, AA: 0.7865, Kappa: 0.7620\n",
      "[83/100] Seed 124 → OA: 0.7915, AA: 0.8029, Kappa: 0.7742\n",
      "[84/100] Seed 125 → OA: 0.8100, AA: 0.8238, Kappa: 0.7946\n",
      "[85/100] Seed 126 → OA: 0.8022, AA: 0.8019, Kappa: 0.7855\n",
      "[86/100] Seed 127 → OA: 0.7806, AA: 0.7830, Kappa: 0.7629\n",
      "[87/100] Seed 128 → OA: 0.8023, AA: 0.8189, Kappa: 0.7859\n",
      "[88/100] Seed 129 → OA: 0.7899, AA: 0.7837, Kappa: 0.7728\n",
      "[89/100] Seed 130 → OA: 0.7919, AA: 0.8004, Kappa: 0.7748\n",
      "[90/100] Seed 131 → OA: 0.7952, AA: 0.8089, Kappa: 0.7786\n",
      "[91/100] Seed 132 → OA: 0.8050, AA: 0.8129, Kappa: 0.7889\n",
      "[92/100] Seed 133 → OA: 0.7795, AA: 0.7948, Kappa: 0.7618\n",
      "[93/100] Seed 134 → OA: 0.7850, AA: 0.7999, Kappa: 0.7676\n",
      "[94/100] Seed 135 → OA: 0.8000, AA: 0.7979, Kappa: 0.7831\n",
      "[95/100] Seed 136 → OA: 0.7925, AA: 0.8008, Kappa: 0.7757\n",
      "[96/100] Seed 137 → OA: 0.7987, AA: 0.8109, Kappa: 0.7824\n",
      "[97/100] Seed 138 → OA: 0.7830, AA: 0.7927, Kappa: 0.7654\n",
      "[98/100] Seed 139 → OA: 0.7795, AA: 0.7826, Kappa: 0.7616\n",
      "[99/100] Seed 140 → OA: 0.8000, AA: 0.8066, Kappa: 0.7837\n",
      "[100/100] Seed 141 → OA: 0.7931, AA: 0.7988, Kappa: 0.7759\n",
      "\n",
      "🏆 最佳结果:\n",
      "Seed: 125\n",
      "OA: 0.8100\n",
      "AA: 0.8238\n",
      "Kappa: 0.7946\n",
      "已保存最佳预测结果至: best_seed_125_results.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train_and_evaluate_once(seed, pca_data, train_labels, test_labels, checkpoint, num_classes, num_epochs=200):\n",
    "    set_seed(seed)\n",
    "\n",
    "    train_dataset = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "    test_dataset = ClassificationDataset(pca_data, test_labels, patch_size=11)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    feature_extractor = FeatureExtractor(input_channels=40).cuda()\n",
    "    classification_head = ClassificationHead(input_dim=128, num_classes=num_classes).cuda()\n",
    "    feature_extractor.load_state_dict(checkpoint[\"feature_extractor_state_dict\"])\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": classification_head.parameters(), \"lr\": 1e-3},\n",
    "    ])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    feature_extractor.train()\n",
    "    classification_head.train()\n",
    "    for _ in range(num_epochs):\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda().long()\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            outputs = classification_head(feature_extractor(cubes))\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    oa = accuracy_score(all_labels, all_preds)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    conf = confusion_matrix(all_labels, all_preds)\n",
    "    class_acc = np.diag(conf) / conf.sum(axis=1)\n",
    "    aa = np.nanmean(class_acc)\n",
    "\n",
    "    return oa, aa, kappa, all_preds, all_labels, seed\n",
    "\n",
    "\n",
    "# 运行评估\n",
    "checkpoint_path = \"pth/linyu_50_model1.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "results = []\n",
    "best_result = None\n",
    "best_oa = -1\n",
    "\n",
    "for i in range(100):\n",
    "    seed = 42 + i\n",
    "    oa, aa, kappa, preds, labels, seed_used = train_and_evaluate_once(\n",
    "        seed, pca_data, train_labels, test_labels, checkpoint, num_classes\n",
    "    )\n",
    "    results.append((seed, oa, aa, kappa))\n",
    "    print(f\"[{i+1}/100] Seed {seed} → OA: {oa:.4f}, AA: {aa:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    if oa > best_oa:\n",
    "        best_oa = oa\n",
    "        best_result = {\n",
    "            \"seed\": seed,\n",
    "            \"oa\": oa,\n",
    "            \"aa\": aa,\n",
    "            \"kappa\": kappa,\n",
    "            \"predictions\": preds,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "# 输出最佳结果\n",
    "print(\"\\n🏆 最佳结果:\")\n",
    "print(f\"Seed: {best_result['seed']}\")\n",
    "print(f\"OA: {best_result['oa']:.4f}\")\n",
    "print(f\"AA: {best_result['aa']:.4f}\")\n",
    "print(f\"Kappa: {best_result['kappa']:.4f}\")\n",
    "\n",
    "# 保存预测结果（可选）\n",
    "df = pd.DataFrame({\n",
    "    \"TrueLabel\": best_result[\"labels\"],\n",
    "    \"Predicted\": best_result[\"predictions\"]\n",
    "})\n",
    "df.to_csv(f\"best_seed_{best_result['seed']}_results.csv\", index=False)\n",
    "\n",
    "print(f\"已保存最佳预测结果至: best_seed_{best_result['seed']}_results.csv\")\n",
    "results_array = np.array(results)  # shape: (100, 4) (seed, oa, aa, kappa)\n",
    "mean_oa = results_array[:, 1].mean()\n",
    "mean_aa = results_array[:, 2].mean()\n",
    "mean_kappa = results_array[:, 3].mean()\n",
    "\n",
    "print(\"\\n🔎 100 次重复实验的平均结果：\")\n",
    "print(f\"平均 OA: {mean_oa:.4f}\")\n",
    "print(f\"平均 AA: {mean_aa:.4f}\")\n",
    "print(f\"平均 Kappa: {mean_kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8162\n",
      "Average Accuracy: 0.8232\n",
      "Kappa Coefficient: 0.8003\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 876 predictions\n",
      "Class 1: 974 predictions\n",
      "Class 2: 491 predictions\n",
      "Class 3: 1001 predictions\n",
      "Class 4: 1101 predictions\n",
      "Class 5: 135 predictions\n",
      "Class 6: 2167 predictions\n",
      "Class 7: 704 predictions\n",
      "Class 8: 970 predictions\n",
      "Class 9: 727 predictions\n",
      "Class 10: 886 predictions\n",
      "Class 11: 1167 predictions\n",
      "Class 12: 306 predictions\n",
      "Class 13: 199 predictions\n",
      "Class 14: 493 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.8196\n",
      "Class 1: 0.8477\n",
      "Class 2: 0.9683\n",
      "Class 3: 0.8949\n",
      "Class 4: 0.9706\n",
      "Class 5: 0.7483\n",
      "Class 6: 0.9030\n",
      "Class 7: 0.6068\n",
      "Class 8: 0.7592\n",
      "Class 9: 0.5473\n",
      "Class 10: 0.7296\n",
      "Class 11: 0.9328\n",
      "Class 12: 0.8737\n",
      "Class 13: 0.7490\n",
      "Class 14: 0.9979\n",
      "0.8196\n",
      "0.8477\n",
      "0.9683\n",
      "0.8949\n",
      "0.9706\n",
      "0.7483\n",
      "0.9030\n",
      "0.6068\n",
      "0.7592\n",
      "0.5473\n",
      "0.7296\n",
      "0.9328\n",
      "0.8737\n",
      "0.7490\n",
      "0.9979\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "seed = 125\n",
    "set_seed(seed)\n",
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
