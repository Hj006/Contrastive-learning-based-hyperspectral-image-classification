{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.exposure\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation\n",
    "import random\n",
    "from scipy.sparse import coo_array\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 如果你显示中文，改为你系统支持的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pavia University shape: (103, 610, 340)\n",
      "Train samples: 135\n",
      "Candidate samples: 3921\n",
      "Test samples: 42776\n"
     ]
    }
   ],
   "source": [
    "def load_pavia_university_with_full_test(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 Pavia University 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 10 个作为训练样本\n",
    "    - 所有 ground truth 像素都作为测试样本（包括候选/训练区域）\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    pavia_data = loadmat(data_path / 'PaviaU.mat')['paviaU']\n",
    "    gt = loadmat(data_path / 'PaviaU_gt.mat')['paviaU_gt']\n",
    "    h, w, c = pavia_data.shape\n",
    "\n",
    "    label_dict = {\n",
    "        1: 'Asphalt road', 2: 'Meadows', 3: 'Gravel',\n",
    "        4: 'Trees', 5: 'Painted metal sheets', 6: 'Bare Soil',\n",
    "        7: 'Bitumen', 8: 'Self-Blocking Bricks', 9: 'Shadows',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\" 类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    #  测试集直接包含所有 ground truth\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return pavia_data.transpose(2, 0, 1), train_truth, candidate_truth, test_truth, info\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\otherdataset\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 548, 2: 540, 3: 392,\n",
    "    4: 524, 5: 265, 6: 532,\n",
    "    7: 375, 8: 514, 9: 231\n",
    "}\n",
    "\n",
    "pavia, train_truth, candidate_truth, test_truth, info = load_pavia_university_with_full_test(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=15\n",
    ")\n",
    "\n",
    "print(f\"Pavia University shape: {pavia.shape}\")\n",
    "print(f\"Train samples: {train_truth.count_nonzero()}\")         #  90\n",
    "print(f\"Candidate samples: {candidate_truth.count_nonzero()}\") #  3921\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           #  42776\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计 train_truth 中的类别数量（非零值的唯一值数量）\n",
    "num_classes = len(set(train_truth.data))\n",
    "num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选区降维结果 shape: (60, 610, 340)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def apply_pca_on_candidate(hsi_data, candidate_truth, num_components=40, use_pca=True):\n",
    "    \"\"\"\n",
    "    在 candidate_truth 区域进行 PCA 或保留原始光谱，返回结果格式统一。\n",
    "\n",
    "    返回：\n",
    "    - data: shape [C, H, W]，只在候选区域填值，其余为 0\n",
    "    - samples: shape [N, C]，候选像素的特征\n",
    "    - coords: List of (row, col)\n",
    "    - explained_variance_ratio 或 None\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = candidate_truth.row, candidate_truth.col\n",
    "    spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "\n",
    "    coords = list(zip(rows, cols))\n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced = pca.fit_transform(spectra)  # shape: (N, num_components)\n",
    "        result_c = num_components\n",
    "        final_data = reduced\n",
    "        var_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        reduced = spectra  # shape: (N, C)\n",
    "        result_c = c\n",
    "        final_data = reduced\n",
    "        var_ratio = None\n",
    "\n",
    "    # 构建 [C, H, W] 格式，只填候选区域\n",
    "    candidate_data = np.zeros((result_c, h, w), dtype=np.float32)\n",
    "    for i, (r, c_) in enumerate(coords):\n",
    "        candidate_data[:, r, c_] = final_data[i]\n",
    "\n",
    "    return candidate_data, reduced, coords, var_ratio\n",
    "\n",
    "com = 60\n",
    "\n",
    "# 应用 PCA 降维\n",
    "pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(pavia, candidate_truth, num_components=com)\n",
    "#不用pca降维\n",
    "#original_candidate_data, raw_samples, coords, _\n",
    "#pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(pavia, candidate_truth, use_pca=False)\n",
    "\n",
    "print(f\"候选区降维结果 shape: {pca_candidate_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的立方块形状: (60, 11, 11)\n",
      "子立方块 A 形状: torch.Size([11, 11, 30])\n",
      "子立方块 B 形状: torch.Size([11, 11, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    通道维度为奇数时，丢弃最后一个通道，保持对称划分。\n",
    "\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    if c % 2 != 0:\n",
    "        hsi_cube = hsi_cube[:, :, :c - 1]  # 丢掉最后一个通道\n",
    "    c1 = hsi_cube.shape[2] // 2\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "# 提取 11x11 的立方块\n",
    "s = 11  # 立方块的宽和高\n",
    "patch_size = (s, s)\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 进行对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "# 提取某像素点周围的立方块\n",
    "x, y = 100, 100  # 中心像素位置\n",
    "cube = extract_cube(pca_candidate_data, x, y, patch_size)\n",
    "print(\"提取的立方块形状:\", cube.shape)  # (40, 11, 11)\n",
    "# 切分通道\n",
    "cube_tensor = torch.tensor(cube).permute(1, 2, 0)  # 转换为 [H, W, C]\n",
    "cube_a, cube_b = split_cube(cube_tensor)\n",
    "\n",
    "print(\"子立方块 A 形状:\", cube_a.shape)  # (11, 11, 20)\n",
    "print(\"子立方块 B 形状:\", cube_b.shape)  # (11, 11, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # 如果为 False，CUDA 不可用\n",
    "print(torch.cuda.current_device())  # 当前设备编号\n",
    "print(torch.cuda.get_device_name(0))  # 查看设备名称\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=20):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cpu\n",
      "torch.float32 cpu\n"
     ]
    }
   ],
   "source": [
    "print(cube_a.dtype, cube_a.device)\n",
    "print(cube_b.dtype, cube_b.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6149\n",
      "Epoch [2/50], Loss: 0.5133\n",
      "Epoch [3/50], Loss: 0.4953\n",
      "Epoch [4/50], Loss: 0.4857\n",
      "Epoch [5/50], Loss: 0.4769\n",
      "Epoch [6/50], Loss: 0.4758\n",
      "Epoch [7/50], Loss: 0.4703\n",
      "Epoch [8/50], Loss: 0.4745\n",
      "Epoch [9/50], Loss: 0.4629\n",
      "Epoch [10/50], Loss: 0.4677\n",
      "Epoch [11/50], Loss: 0.4673\n",
      "Epoch [12/50], Loss: 0.4713\n",
      "Epoch [13/50], Loss: 0.4597\n",
      "Epoch [14/50], Loss: 0.4650\n",
      "Epoch [15/50], Loss: 0.4652\n",
      "Epoch [16/50], Loss: 0.4575\n",
      "Epoch [17/50], Loss: 0.4692\n",
      "Epoch [18/50], Loss: 0.4602\n",
      "Epoch [19/50], Loss: 0.4575\n",
      "Epoch [20/50], Loss: 0.4687\n",
      "Epoch [21/50], Loss: 0.4598\n",
      "Epoch [22/50], Loss: 0.4587\n",
      "Epoch [23/50], Loss: 0.4627\n",
      "Epoch [24/50], Loss: 0.4671\n",
      "Epoch [25/50], Loss: 0.4593\n",
      "Epoch [26/50], Loss: 0.4561\n",
      "Epoch [27/50], Loss: 0.4578\n",
      "Epoch [28/50], Loss: 0.4563\n",
      "Epoch [29/50], Loss: 0.4519\n",
      "Epoch [30/50], Loss: 0.4522\n",
      "Epoch [31/50], Loss: 0.4555\n",
      "Epoch [32/50], Loss: 0.4607\n",
      "Epoch [33/50], Loss: 0.4580\n",
      "Epoch [34/50], Loss: 0.4538\n",
      "Epoch [35/50], Loss: 0.4540\n",
      "Epoch [36/50], Loss: 0.4547\n",
      "Epoch [37/50], Loss: 0.4567\n",
      "Epoch [38/50], Loss: 0.4505\n",
      "Epoch [39/50], Loss: 0.4532\n",
      "Epoch [40/50], Loss: 0.4554\n",
      "Epoch [41/50], Loss: 0.4551\n",
      "Epoch [42/50], Loss: 0.4549\n",
      "Epoch [43/50], Loss: 0.4525\n",
      "Epoch [44/50], Loss: 0.4496\n",
      "Epoch [45/50], Loss: 0.4543\n",
      "Epoch [46/50], Loss: 0.4529\n",
      "Epoch [47/50], Loss: 0.4528\n",
      "Epoch [48/50], Loss: 0.4546\n",
      "Epoch [49/50], Loss: 0.4498\n",
      "Epoch [50/50], Loss: 0.4566\n",
      "Model saved at epoch 50 to final/Pavia_lin_50_model1_60ep.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CandidatePatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.coords[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # [C, H, W]\n",
    "        cube = torch.tensor(cube).permute(1, 2, 0)  # [H, W, C]\n",
    "        cube_a, cube_b = split_cube(cube)\n",
    "        cube_a = cube_a.permute(2, 0, 1)\n",
    "        cube_b = cube_b.permute(2, 0, 1)\n",
    "        return cube_a, cube_b\n",
    "\n",
    "class MultiPositivePatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 展平坐标：一个中心对应 4 个邻居位置\n",
    "        self.flattened_coords = []\n",
    "        for x, y in coords:\n",
    "            self.flattened_coords += [\n",
    "                (x, y, x-1, y),  # 上\n",
    "                (x, y, x+1, y),  # 下\n",
    "                (x, y, x, y-1),  # 左\n",
    "                (x, y, x, y+1),  # 右\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1, x2, y2 = self.flattened_coords[idx]\n",
    "        patch_a = extract_cube(self.data, x1, y1, (self.patch_size, self.patch_size))\n",
    "        patch_b = extract_cube(self.data, x2, y2, (self.patch_size, self.patch_size))\n",
    "        patch_a = torch.tensor(patch_a, dtype=torch.float32)\n",
    "        patch_b = torch.tensor(patch_b, dtype=torch.float32)\n",
    "        return patch_a, patch_b\n",
    "\n",
    "class MultiPositivePatchDataset1(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 展平坐标：一个中心对应 4 个邻居位置\n",
    "        self.flattened_coords = []\n",
    "        for x, y in coords:\n",
    "            self.flattened_coords += [\n",
    "                (x, y, x-1, y),  # 上\n",
    "                (x, y, x+1, y),  # 下\n",
    "                (x, y, x, y-1),  # 左\n",
    "                (x, y, x, y+1),  # 右\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1, x2, y2 = self.flattened_coords[idx]\n",
    "        patch_a = extract_cube(self.data, x1, y1, (self.patch_size, self.patch_size))\n",
    "        patch_b = extract_cube(self.data, x2, y2, (self.patch_size, self.patch_size))\n",
    "        \n",
    "        patch_a = torch.tensor(patch_a, dtype=torch.float32)  # shape: (C, H, W)\n",
    "        patch_b = torch.tensor(patch_b, dtype=torch.float32)\n",
    "\n",
    "        # 拆分光谱维度 C\n",
    "        C = patch_a.shape[0]\n",
    "        c_half = C // 2\n",
    "        a1, a2 = patch_a[:c_half], patch_a[c_half:]\n",
    "        b1, b2 = patch_b[:c_half], patch_b[c_half:]\n",
    "\n",
    "        # 组合成混合补丁\n",
    "        patch_mix1 = torch.cat([a1, b1], dim=0)  # shape: (C, H, W)\n",
    "        patch_mix2 = torch.cat([a2, b2], dim=0)\n",
    "\n",
    "        return patch_mix1, patch_mix2\n",
    "    \n",
    "pca_data_tensor = torch.tensor(pca_candidate_data).float()\n",
    "dataset = MultiPositivePatchDataset1(pca_data_tensor, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)  # 每 batch 会生成 64×4=256 对\n",
    "\n",
    "# 初始化网络和优化器\n",
    "feature_extractor = FeatureExtractor(input_channels=com).cuda()\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 50\n",
    "loss_values = []\n",
    "temperature = 1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for cube_a, cube_b in dataloader:  # ⬅️ 直接解包两个 batch tensor\n",
    "        cube_a, cube_b = cube_a.cuda(), cube_b.cuda()\n",
    "\n",
    "        # 提取特征\n",
    "        features_a = feature_extractor(cube_a)\n",
    "        features_b = feature_extractor(cube_b)\n",
    "\n",
    "        # 投影\n",
    "        proj_a = projection_head(features_a)\n",
    "        proj_b = projection_head(features_b)\n",
    "\n",
    "        # 计算对比损失\n",
    "        loss = contrastive_loss_ce_hard_negatives(proj_a,proj_b, temperature=1, num_negatives=5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 在第50、100、150轮存储模型\n",
    "    if (epoch + 1) in [50, 100, 150]:\n",
    "        model_path = f'final/Pavia_lin_{epoch+1}_model1_60ep.pth'\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "                'projection_head_state_dict': projection_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            },\n",
    "            model_path\n",
    "        )\n",
    "        print(f\"Model saved at epoch {epoch+1} to {model_path}\")\n",
    "\n",
    "# 训练完成后绘制损失值曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/Pavia_lin_50_model1_60ep.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 42776\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "test_labels = extract_labels(test_truth, info['label_dict'])\n",
    "\n",
    "\n",
    "print(f\"Number of testing samples: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(70, 0, 0), (71, 0, 0), (72, 0, 0), (87, 0, 1), (88, 0, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing label distribution: Counter({1: 18649, 0: 6631, 5: 5029, 7: 3682, 3: 3064, 2: 2099, 4: 1345, 6: 1330, 8: 947})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "test_label_counts = Counter([label for _, _, label in test_labels])\n",
    "\n",
    "\n",
    "print(\"Testing label distribution:\", test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (60, 610, 340)\n",
      "Number of training samples: 135\n",
      "Number of testing samples: 42776\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 提取立方块函数\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "# PCA 降维函数\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    参数:\n",
    "        hsi_data: 高光谱数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: 保留的主成分数量\n",
    "    返回:\n",
    "        pca_data: 降维后的数据, 形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "\n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "\n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "\n",
    "    # 转换整个数据集\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "\n",
    "    # 恢复为原始图像的形状\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, torch.tensor(label - 1, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(train_truth.row, train_truth.col, train_truth.data)\n",
    "]\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "pca_data, explained_variance_ratio = apply_pca_train_only(pavia, train_truth, num_components=60)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "\n",
    "test_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(test_truth.row, test_truth.col, test_truth.data)\n",
    "]\n",
    "test_dataset = ClassificationDataset(pca_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印样本信息\n",
    "print(f\"PCA 降维后的数据形状: {pca_data.shape}\")\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载对比学习训练的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "#checkpoint_path = \"./pth/model_epoch_160.pth\"  # 修改为对比学习模型的路径\n",
    "checkpoint_path = \"final/Pavia_lin_50_model1_60ep.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n",
      "Epoch [1/200], Loss: 2.4479\n",
      "Epoch [2/200], Loss: 2.3150\n",
      "Epoch [3/200], Loss: 2.0899\n",
      "Epoch [4/200], Loss: 1.9719\n",
      "Epoch [5/200], Loss: 1.8558\n",
      "Epoch [6/200], Loss: 1.9244\n",
      "Epoch [7/200], Loss: 1.7818\n",
      "Epoch [8/200], Loss: 1.9878\n",
      "Epoch [9/200], Loss: 1.6695\n",
      "Epoch [10/200], Loss: 1.6440\n",
      "Epoch [11/200], Loss: 1.6450\n",
      "Epoch [12/200], Loss: 1.5384\n",
      "Epoch [13/200], Loss: 1.5814\n",
      "Epoch [14/200], Loss: 1.5336\n",
      "Epoch [15/200], Loss: 1.5210\n",
      "Epoch [16/200], Loss: 1.4326\n",
      "Epoch [17/200], Loss: 1.3666\n",
      "Epoch [18/200], Loss: 1.3776\n",
      "Epoch [19/200], Loss: 1.3249\n",
      "Epoch [20/200], Loss: 1.3565\n",
      "Epoch [21/200], Loss: 1.2569\n",
      "Epoch [22/200], Loss: 1.1942\n",
      "Epoch [23/200], Loss: 1.1334\n",
      "Epoch [24/200], Loss: 1.1775\n",
      "Epoch [25/200], Loss: 1.0959\n",
      "Epoch [26/200], Loss: 1.1006\n",
      "Epoch [27/200], Loss: 0.9352\n",
      "Epoch [28/200], Loss: 1.0049\n",
      "Epoch [29/200], Loss: 1.0722\n",
      "Epoch [30/200], Loss: 0.8430\n",
      "Epoch [31/200], Loss: 0.8671\n",
      "Epoch [32/200], Loss: 0.8151\n",
      "Epoch [33/200], Loss: 0.7521\n",
      "Epoch [34/200], Loss: 0.9264\n",
      "Epoch [35/200], Loss: 0.7132\n",
      "Epoch [36/200], Loss: 0.7675\n",
      "Epoch [37/200], Loss: 0.7377\n",
      "Epoch [38/200], Loss: 0.7587\n",
      "Epoch [39/200], Loss: 0.6516\n",
      "Epoch [40/200], Loss: 0.6598\n",
      "Epoch [41/200], Loss: 0.6840\n",
      "Epoch [42/200], Loss: 0.6527\n",
      "Epoch [43/200], Loss: 0.5423\n",
      "Epoch [44/200], Loss: 0.5785\n",
      "Epoch [45/200], Loss: 0.5426\n",
      "Epoch [46/200], Loss: 0.6787\n",
      "Epoch [47/200], Loss: 0.4802\n",
      "Epoch [48/200], Loss: 0.5662\n",
      "Epoch [49/200], Loss: 0.4726\n",
      "Epoch [50/200], Loss: 0.5092\n",
      "Epoch [51/200], Loss: 0.5920\n",
      "Epoch [52/200], Loss: 0.4200\n",
      "Epoch [53/200], Loss: 0.4334\n",
      "Epoch [54/200], Loss: 0.4071\n",
      "Epoch [55/200], Loss: 0.5354\n",
      "Epoch [56/200], Loss: 0.4365\n",
      "Epoch [57/200], Loss: 0.4479\n",
      "Epoch [58/200], Loss: 0.6584\n",
      "Epoch [59/200], Loss: 0.4552\n",
      "Epoch [60/200], Loss: 0.4870\n",
      "Epoch [61/200], Loss: 0.3753\n",
      "Epoch [62/200], Loss: 0.3676\n",
      "Epoch [63/200], Loss: 0.5697\n",
      "Epoch [64/200], Loss: 0.4424\n",
      "Epoch [65/200], Loss: 0.3999\n",
      "Epoch [66/200], Loss: 0.3213\n",
      "Epoch [67/200], Loss: 0.3096\n",
      "Epoch [68/200], Loss: 0.3189\n",
      "Epoch [69/200], Loss: 0.3197\n",
      "Epoch [70/200], Loss: 0.3246\n",
      "Epoch [71/200], Loss: 0.2623\n",
      "Epoch [72/200], Loss: 0.4215\n",
      "Epoch [73/200], Loss: 0.2547\n",
      "Epoch [74/200], Loss: 0.2325\n",
      "Epoch [75/200], Loss: 0.2215\n",
      "Epoch [76/200], Loss: 0.2034\n",
      "Epoch [77/200], Loss: 0.3433\n",
      "Epoch [78/200], Loss: 0.2141\n",
      "Epoch [79/200], Loss: 0.2083\n",
      "Epoch [80/200], Loss: 0.1835\n",
      "Epoch [81/200], Loss: 0.3494\n",
      "Epoch [82/200], Loss: 0.3370\n",
      "Epoch [83/200], Loss: 0.1842\n",
      "Epoch [84/200], Loss: 0.4381\n",
      "Epoch [85/200], Loss: 0.2084\n",
      "Epoch [86/200], Loss: 0.1892\n",
      "Epoch [87/200], Loss: 0.3682\n",
      "Epoch [88/200], Loss: 0.3541\n",
      "Epoch [89/200], Loss: 0.1854\n",
      "Epoch [90/200], Loss: 0.1742\n",
      "Epoch [91/200], Loss: 0.2400\n",
      "Epoch [92/200], Loss: 0.1818\n",
      "Epoch [93/200], Loss: 0.1521\n",
      "Epoch [94/200], Loss: 0.1507\n",
      "Epoch [95/200], Loss: 0.1319\n",
      "Epoch [96/200], Loss: 0.1830\n",
      "Epoch [97/200], Loss: 0.1210\n",
      "Epoch [98/200], Loss: 0.1408\n",
      "Epoch [99/200], Loss: 0.1158\n",
      "Epoch [100/200], Loss: 0.3408\n",
      "Epoch [101/200], Loss: 0.1544\n",
      "Epoch [102/200], Loss: 0.2202\n",
      "Epoch [103/200], Loss: 0.1443\n",
      "Epoch [104/200], Loss: 0.2004\n",
      "Epoch [105/200], Loss: 0.1589\n",
      "Epoch [106/200], Loss: 0.2519\n",
      "Epoch [107/200], Loss: 0.0813\n",
      "Epoch [108/200], Loss: 0.1196\n",
      "Epoch [109/200], Loss: 0.2051\n",
      "Epoch [110/200], Loss: 0.1456\n",
      "Epoch [111/200], Loss: 0.1458\n",
      "Epoch [112/200], Loss: 0.1028\n",
      "Epoch [113/200], Loss: 0.2015\n",
      "Epoch [114/200], Loss: 0.1425\n",
      "Epoch [115/200], Loss: 0.1132\n",
      "Epoch [116/200], Loss: 0.0980\n",
      "Epoch [117/200], Loss: 0.2033\n",
      "Epoch [118/200], Loss: 0.1340\n",
      "Epoch [119/200], Loss: 0.1105\n",
      "Epoch [120/200], Loss: 0.1468\n",
      "Epoch [121/200], Loss: 0.0654\n",
      "Epoch [122/200], Loss: 0.2717\n",
      "Epoch [123/200], Loss: 0.0675\n",
      "Epoch [124/200], Loss: 0.1160\n",
      "Epoch [125/200], Loss: 0.0745\n",
      "Epoch [126/200], Loss: 0.0856\n",
      "Epoch [127/200], Loss: 0.0713\n",
      "Epoch [128/200], Loss: 0.0700\n",
      "Epoch [129/200], Loss: 0.1556\n",
      "Epoch [130/200], Loss: 0.0977\n",
      "Epoch [131/200], Loss: 0.0528\n",
      "Epoch [132/200], Loss: 0.1950\n",
      "Epoch [133/200], Loss: 0.0779\n",
      "Epoch [134/200], Loss: 0.0517\n",
      "Epoch [135/200], Loss: 0.0814\n",
      "Epoch [136/200], Loss: 0.7451\n",
      "Epoch [137/200], Loss: 0.0474\n",
      "Epoch [138/200], Loss: 0.0531\n",
      "Epoch [139/200], Loss: 0.1053\n",
      "Epoch [140/200], Loss: 0.1020\n",
      "Epoch [141/200], Loss: 0.0662\n",
      "Epoch [142/200], Loss: 0.0536\n",
      "Epoch [143/200], Loss: 0.0612\n",
      "Epoch [144/200], Loss: 0.0428\n",
      "Epoch [145/200], Loss: 0.1220\n",
      "Epoch [146/200], Loss: 0.0472\n",
      "Epoch [147/200], Loss: 0.0665\n",
      "Epoch [148/200], Loss: 0.1166\n",
      "Epoch [149/200], Loss: 0.0338\n",
      "Epoch [150/200], Loss: 0.0439\n",
      "Epoch [151/200], Loss: 0.1632\n",
      "Epoch [152/200], Loss: 0.0868\n",
      "Epoch [153/200], Loss: 0.0624\n",
      "Epoch [154/200], Loss: 0.0960\n",
      "Epoch [155/200], Loss: 0.0874\n",
      "Epoch [156/200], Loss: 0.0795\n",
      "Epoch [157/200], Loss: 0.0403\n",
      "Epoch [158/200], Loss: 0.0411\n",
      "Epoch [159/200], Loss: 0.0371\n",
      "Epoch [160/200], Loss: 0.0937\n",
      "Epoch [161/200], Loss: 0.0380\n",
      "Epoch [162/200], Loss: 0.0525\n",
      "Epoch [163/200], Loss: 0.0421\n",
      "Epoch [164/200], Loss: 0.1503\n",
      "Epoch [165/200], Loss: 0.0765\n",
      "Epoch [166/200], Loss: 0.0296\n",
      "Epoch [167/200], Loss: 0.0287\n",
      "Epoch [168/200], Loss: 0.0419\n",
      "Epoch [169/200], Loss: 0.1022\n",
      "Epoch [170/200], Loss: 0.0359\n",
      "Epoch [171/200], Loss: 0.0422\n",
      "Epoch [172/200], Loss: 0.0180\n",
      "Epoch [173/200], Loss: 0.0182\n",
      "Epoch [174/200], Loss: 0.0282\n",
      "Epoch [175/200], Loss: 0.0465\n",
      "Epoch [176/200], Loss: 0.0231\n",
      "Epoch [177/200], Loss: 0.0345\n",
      "Epoch [178/200], Loss: 0.1299\n",
      "Epoch [179/200], Loss: 0.0203\n",
      "Epoch [180/200], Loss: 0.0344\n",
      "Epoch [181/200], Loss: 0.0771\n",
      "Epoch [182/200], Loss: 0.0216\n",
      "Epoch [183/200], Loss: 0.0289\n",
      "Epoch [184/200], Loss: 0.0451\n",
      "Epoch [185/200], Loss: 0.1489\n",
      "Epoch [186/200], Loss: 0.0188\n",
      "Epoch [187/200], Loss: 0.0325\n",
      "Epoch [188/200], Loss: 0.0548\n",
      "Epoch [189/200], Loss: 0.0296\n",
      "Epoch [190/200], Loss: 0.0332\n",
      "Epoch [191/200], Loss: 0.1118\n",
      "Epoch [192/200], Loss: 0.0204\n",
      "Epoch [193/200], Loss: 0.0262\n",
      "Epoch [194/200], Loss: 0.0326\n",
      "Epoch [195/200], Loss: 0.0406\n",
      "Epoch [196/200], Loss: 0.0643\n",
      "Epoch [197/200], Loss: 0.0182\n",
      "Epoch [198/200], Loss: 0.0429\n",
      "Epoch [199/200], Loss: 0.0740\n",
      "Epoch [200/200], Loss: 0.0341\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 20）\n",
    "feature_extractor = FeatureExtractor(input_channels=60).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 定义分类头\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=9).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练分类头和特征提取器\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()  # 微调特征提取器\n",
    "    classification_head.train()  # 训练分类头\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征\n",
    "            features = feature_extractor(cubes)\n",
    "\n",
    "            # 分类头进行训练\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8204\n",
      "Average Accuracy: 0.8636\n",
      "Kappa Coefficient: 0.7714\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 5478 predictions\n",
      "Class 1: 14838 predictions\n",
      "Class 2: 2118 predictions\n",
      "Class 3: 3074 predictions\n",
      "Class 4: 1340 predictions\n",
      "Class 5: 8955 predictions\n",
      "Class 6: 2150 predictions\n",
      "Class 7: 3881 predictions\n",
      "Class 8: 942 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.7561\n",
      "Class 1: 0.7813\n",
      "Class 2: 0.6775\n",
      "Class 3: 0.9654\n",
      "Class 4: 0.9911\n",
      "Class 5: 0.9897\n",
      "Class 6: 0.9060\n",
      "Class 7: 0.7300\n",
      "Class 8: 0.9757\n",
      "0.7561\n",
      "0.7813\n",
      "0.6775\n",
      "0.9654\n",
      "0.9911\n",
      "0.9897\n",
      "0.9060\n",
      "0.7300\n",
      "0.9757\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
