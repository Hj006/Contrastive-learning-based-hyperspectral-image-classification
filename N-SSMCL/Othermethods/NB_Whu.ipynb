{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_array\n",
    "import skimage.exposure\n",
    "from scipy.sparse import coo_matrix\n",
    "import warnings\n",
    "from io import StringIO\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\rasterio\\__init__.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHU shape: (270, 550, 400)\n",
      "Train samples: 135\n",
      "Candidate samples: 2700\n",
      "Test samples: 204542\n",
      "Test samples: 204542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_whu_longkou(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 WHU-Hi-LongKou 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 num_train_per_class 个作为训练样本\n",
    "    - 所有 ground truth 标签 > 0 的像素作为测试集\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 读取 hyperspectral 数据\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou.tif\") as src:\n",
    "        hyperspectral = src.read()  # shape: (bands, height, width)\n",
    "    c, h, w = hyperspectral.shape\n",
    "\n",
    "    # 读取 ground truth 标签\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou_gt.tif\") as src:\n",
    "        gt = src.read(1)  # shape: (height, width)\n",
    "\n",
    "    label_dict = {\n",
    "        1: '玉米', 2: '棉花', 3: '芝麻',\n",
    "        4: '圆叶大豆', 5: '长叶大豆', 6: '水稻',\n",
    "        7: '水体', 8: '房屋和道路', 9: '混合杂草',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\"类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    # 所有标签 > 0 的都作为测试样本\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return hyperspectral, train_truth, candidate_truth, test_truth, info\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\WHU\\Tiff_format\\WHU-Hi-LongKou\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 300, 2: 300, 3: 300,\n",
    "    4: 300, 5: 300, 6: 300,\n",
    "    7: 300, 8: 300, 9: 300\n",
    "}\n",
    "\n",
    "whu, train_truth, candidate_truth, test_truth, info = load_whu_longkou(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=15\n",
    ")\n",
    "\n",
    "print(f\"WHU shape: {whu.shape}\")  # 应该是 (270, 400, 550)\n",
    "print(f\"Train samples: {train_truth.count_nonzero()}\")         # 90\n",
    "print(f\"Candidate samples: {candidate_truth.count_nonzero()}\") # 2700\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           # 应该接近你截图里的 201842\n",
    "\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           # 应该接近你截图里的 201842\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计 train_truth 中的类别数量（非零值的唯一值数量）\n",
    "num_classes = len(set(train_truth.data))\n",
    "num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选区降维结果 shape: (60, 550, 400)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def apply_pca_on_candidate(hsi_data, candidate_truth, num_components=40, use_pca=True):\n",
    "    \"\"\"\n",
    "    在 candidate_truth 区域进行 PCA 或保留原始光谱，返回结果格式统一。\n",
    "\n",
    "    返回：\n",
    "    - data: shape [C, H, W]，只在候选区域填值，其余为 0\n",
    "    - samples: shape [N, C]，候选像素的特征\n",
    "    - coords: List of (row, col)\n",
    "    - explained_variance_ratio 或 None\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = candidate_truth.row, candidate_truth.col\n",
    "    spectra = hsi_data[:, rows, cols].T  # shape: (N, C)\n",
    "\n",
    "    coords = list(zip(rows, cols))\n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced = pca.fit_transform(spectra)  # shape: (N, num_components)\n",
    "        result_c = num_components\n",
    "        final_data = reduced\n",
    "        var_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        reduced = spectra  # shape: (N, C)\n",
    "        result_c = c\n",
    "        final_data = reduced\n",
    "        var_ratio = None\n",
    "\n",
    "    # 构建 [C, H, W] 格式，只填候选区域\n",
    "    candidate_data = np.zeros((result_c, h, w), dtype=np.float32)\n",
    "    for i, (r, c_) in enumerate(coords):\n",
    "        candidate_data[:, r, c_] = final_data[i]\n",
    "\n",
    "    return candidate_data, reduced, coords, var_ratio\n",
    "\n",
    "com = 60\n",
    "\n",
    "# 应用 PCA 降维\n",
    "pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(whu, candidate_truth, num_components=com)\n",
    "#不用pca降维\n",
    "#original_candidate_data, raw_samples, coords, _\n",
    "#pca_candidate_data, reduced_samples, coords, var_ratio = apply_pca_on_candidate(whu, candidate_truth, use_pca=False)\n",
    "\n",
    "print(f\"候选区降维结果 shape: {pca_candidate_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的立方块形状: (60, 11, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 提取 11x11 的立方块\n",
    "s = 11  # 立方块的宽和高\n",
    "patch_size = (s, s)\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 进行对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"edge\")\n",
    "    return cube\n",
    "\n",
    "# 提取某像素点周围的立方块\n",
    "x, y = 100, 100  # 中心像素位置\n",
    "cube = extract_cube(pca_candidate_data, x, y, patch_size)\n",
    "print(\"提取的立方块形状:\", cube.shape)  # (40, 11, 11)\n",
    "# 切分通道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=20):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    c1 = c // 2  # 每个子块保留一半的通道\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱数据中提取局部立方块，并在边界不足时进行填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy.ndarray, 形状为 [C, H, W]\n",
    "        x, y: int, 立方块的中心像素坐标\n",
    "        size: tuple, 立方块的大小 (s, s)，要求 s 必须是奇数\n",
    "    \n",
    "    返回:\n",
    "        cube: numpy.ndarray, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    assert size[0] % 2 == 1, \"立方块大小必须是奇数，以确保中心点对齐。\"\n",
    "    \n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2  # 计算半径\n",
    "\n",
    "    # 计算提取区域的坐标范围\n",
    "    x_min, x_max = max(0, x - half_size), min(h, x + half_size + 1)\n",
    "    y_min, y_max = max(0, y - half_size), min(w, y + half_size + 1)\n",
    "\n",
    "    # 提取局部数据\n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 计算需要填充的大小\n",
    "    pad_x_min, pad_x_max = max(0, half_size - x), max(0, x + half_size + 1 - h)\n",
    "    pad_y_min, pad_y_max = max(0, half_size - y), max(0, y + half_size + 1 - w)\n",
    "\n",
    "    # 使用边缘填充，确保输出形状为 (C, size, size)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (pad_x_min, pad_x_max),  # 高度填充\n",
    "        (pad_y_min, pad_y_max),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"edge\")  # 填充值是边界像素，而不是反射\n",
    "    #cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5026\n",
      "Epoch [2/50], Loss: 0.4531\n",
      "Epoch [3/50], Loss: 0.4476\n",
      "Epoch [4/50], Loss: 0.4449\n",
      "Epoch [5/50], Loss: 0.4437\n",
      "Epoch [6/50], Loss: 0.4425\n",
      "Epoch [7/50], Loss: 0.4415\n",
      "Epoch [8/50], Loss: 0.4407\n",
      "Epoch [9/50], Loss: 0.4400\n",
      "Epoch [10/50], Loss: 0.4398\n",
      "Epoch [11/50], Loss: 0.4400\n",
      "Epoch [12/50], Loss: 0.4394\n",
      "Epoch [13/50], Loss: 0.4389\n",
      "Epoch [14/50], Loss: 0.4388\n",
      "Epoch [15/50], Loss: 0.4385\n",
      "Epoch [16/50], Loss: 0.4386\n",
      "Epoch [17/50], Loss: 0.4383\n",
      "Epoch [18/50], Loss: 0.4386\n",
      "Epoch [19/50], Loss: 0.4383\n",
      "Epoch [20/50], Loss: 0.4382\n",
      "Epoch [21/50], Loss: 0.4375\n",
      "Epoch [22/50], Loss: 0.4373\n",
      "Epoch [23/50], Loss: 0.4377\n",
      "Epoch [24/50], Loss: 0.4377\n",
      "Epoch [25/50], Loss: 0.4371\n",
      "Epoch [26/50], Loss: 0.4378\n",
      "Epoch [27/50], Loss: 0.4372\n",
      "Epoch [28/50], Loss: 0.4371\n",
      "Epoch [29/50], Loss: 0.4369\n",
      "Epoch [30/50], Loss: 0.4375\n",
      "Epoch [31/50], Loss: 0.4367\n",
      "Epoch [32/50], Loss: 0.4367\n",
      "Epoch [33/50], Loss: 0.4364\n",
      "Epoch [34/50], Loss: 0.4365\n",
      "Epoch [35/50], Loss: 0.4365\n",
      "Epoch [36/50], Loss: 0.4362\n",
      "Epoch [37/50], Loss: 0.4361\n",
      "Epoch [38/50], Loss: 0.4363\n",
      "Epoch [39/50], Loss: 0.4362\n",
      "Epoch [40/50], Loss: 0.4364\n",
      "Epoch [41/50], Loss: 0.4359\n",
      "Epoch [42/50], Loss: 0.4357\n",
      "Epoch [43/50], Loss: 0.4356\n",
      "Epoch [44/50], Loss: 0.4359\n",
      "Epoch [45/50], Loss: 0.4355\n",
      "Epoch [46/50], Loss: 0.4355\n",
      "Epoch [47/50], Loss: 0.4358\n",
      "Epoch [48/50], Loss: 0.4358\n",
      "Epoch [49/50], Loss: 0.4356\n",
      "Epoch [50/50], Loss: 0.4354\n",
      "Model saved at epoch 50 to final/Whu_lin_50_60e.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "class MultiPositivePatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 展平坐标：一个中心对应 4 个邻居位置\n",
    "        self.flattened_coords = []\n",
    "        for x, y in coords:\n",
    "            self.flattened_coords += [\n",
    "                (x, y, x-1, y),  # 上\n",
    "                (x, y, x+1, y),  # 下\n",
    "                (x, y, x, y-1),  # 左\n",
    "                (x, y, x, y+1),  # 右\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1, x2, y2 = self.flattened_coords[idx]\n",
    "        patch_a = extract_cube(self.data, x1, y1, (self.patch_size, self.patch_size))\n",
    "        patch_b = extract_cube(self.data, x2, y2, (self.patch_size, self.patch_size))\n",
    "        patch_a = torch.tensor(patch_a, dtype=torch.float32)\n",
    "        patch_b = torch.tensor(patch_b, dtype=torch.float32)\n",
    "        return patch_a, patch_b\n",
    "\n",
    "class MultiPositivePatchDataset1(Dataset):\n",
    "    def __init__(self, pca_data, coords, patch_size=11):\n",
    "        self.data = pca_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 展平坐标：一个中心对应 4 个邻居位置\n",
    "        self.flattened_coords = []\n",
    "        for x, y in coords:\n",
    "            self.flattened_coords += [\n",
    "                (x, y, x-1, y),  # 上\n",
    "                (x, y, x+1, y),  # 下\n",
    "                (x, y, x, y-1),  # 左\n",
    "                (x, y, x, y+1),  # 右\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1, x2, y2 = self.flattened_coords[idx]\n",
    "        patch_a = extract_cube(self.data, x1, y1, (self.patch_size, self.patch_size))\n",
    "        patch_b = extract_cube(self.data, x2, y2, (self.patch_size, self.patch_size))\n",
    "        \n",
    "        patch_a = torch.tensor(patch_a, dtype=torch.float32)  # shape: (C, H, W)\n",
    "        patch_b = torch.tensor(patch_b, dtype=torch.float32)\n",
    "\n",
    "        # 拆分光谱维度 C\n",
    "        C = patch_a.shape[0]\n",
    "        c_half = C // 2\n",
    "        a1, a2 = patch_a[:c_half], patch_a[c_half:]\n",
    "        b1, b2 = patch_b[:c_half], patch_b[c_half:]\n",
    "\n",
    "        # 组合成混合补丁\n",
    "        patch_mix1 = torch.cat([a1, b1], dim=0)  # shape: (C, H, W)\n",
    "        patch_mix2 = torch.cat([a2, b2], dim=0)\n",
    "\n",
    "        return patch_mix1, patch_mix2\n",
    "\n",
    "\n",
    "pca_data_tensor = torch.tensor(pca_candidate_data).float()\n",
    "dataset = MultiPositivePatchDataset(pca_data_tensor, coords)\n",
    "#dataset = MultiPositivePatchDataset1(pca_data_tensor, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)  # 每 batch 会生成 64×4=256 对\n",
    "\n",
    "# 初始化网络和优化器\n",
    "feature_extractor = FeatureExtractor(input_channels=com).cuda()\n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "# 训练循环\n",
    "\n",
    "num_epochs = 50\n",
    "loss_values = []\n",
    "temperature = 1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for cube_a, cube_b in dataloader:  #\n",
    "        cube_a, cube_b = cube_a.cuda(), cube_b.cuda()\n",
    "\n",
    "        # 提取特征\n",
    "        features_a = feature_extractor(cube_a)\n",
    "        features_b = feature_extractor(cube_b)\n",
    "\n",
    "        # 投影\n",
    "        proj_a = projection_head(features_a)\n",
    "        proj_b = projection_head(features_b)\n",
    "\n",
    "        # 计算对比损失\n",
    "        loss = contrastive_loss_ce_hard_negatives(proj_a,proj_b, temperature=1, num_negatives=5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 在第50、100、150轮存储模型\n",
    "    if (epoch + 1) in [50, 100, 150]:\n",
    "        model_path = f'final/Whu_lin_{epoch+1}_60e.pth'\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "                'projection_head_state_dict': projection_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            },\n",
    "            model_path\n",
    "        )\n",
    "        print(f\"Model saved at epoch {epoch+1} to {model_path}\")\n",
    "\n",
    "# 训练完成后绘制损失值曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/Whu_lin_50_60e.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 204542\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "test_labels = extract_labels(test_truth, info['label_dict'])\n",
    "\n",
    "\n",
    "print(f\"Number of testing samples: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0), (5, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing label distribution: Counter({6: 67056, 3: 63212, 0: 34511, 5: 11854, 1: 8374, 7: 7124, 8: 5229, 4: 4151, 2: 3031})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "test_label_counts = Counter([label for _, _, label in test_labels])\n",
    "\n",
    "\n",
    "print(\"Testing label distribution:\", test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (20, 550, 400)\n",
      "Number of training samples: 135\n",
      "Number of testing samples: 204542\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 提取立方块函数\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱图像中提取一个立方块，并在边缘不足时进行填充。\n",
    "    参数:\n",
    "        data: 高光谱数据, 形状为 [C, H, W]\n",
    "        x, y: 中心像素的坐标\n",
    "        size: 立方块的大小 (s, s)\n",
    "    返回:\n",
    "        cube: 提取的立方块, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2\n",
    "    x_min = max(0, x - half_size)\n",
    "    x_max = min(h, x + half_size + 1)\n",
    "    y_min = max(0, y - half_size)\n",
    "    y_max = min(w, y + half_size + 1)\n",
    "    \n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 对称填充，确保形状为 (C, s, s)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (max(0, half_size - x), max(0, x + half_size + 1 - h)),  # 高度填充\n",
    "        (max(0, half_size - y), max(0, y + half_size + 1 - w)),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "# PCA 降维函数\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    参数:\n",
    "        hsi_data: 高光谱数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: 保留的主成分数量\n",
    "    返回:\n",
    "        pca_data: 降维后的数据, 形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "\n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "\n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "\n",
    "    # 转换整个数据集\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "\n",
    "    # 恢复为原始图像的形状\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, torch.tensor(label - 1, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(train_truth.row, train_truth.col, train_truth.data)\n",
    "]\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "pca_data, explained_variance_ratio = apply_pca_train_only(whu, train_truth, num_components=20)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "\n",
    "test_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(test_truth.row, test_truth.col, test_truth.data)\n",
    "]\n",
    "test_dataset = ClassificationDataset(pca_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 打印样本信息\n",
    "print(f\"PCA 降维后的数据形状: {pca_data.shape}\")\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载对比学习训练的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "#checkpoint_path = \"./pth/model_epoch_160.pth\"  # 修改为对比学习模型的路径\n",
    "checkpoint_path = \"final/Whu_lin_50_20e.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n",
      "Epoch [1/200], Loss: 2.5618\n",
      "Epoch [2/200], Loss: 2.3734\n",
      "Epoch [3/200], Loss: 2.1239\n",
      "Epoch [4/200], Loss: 1.9574\n",
      "Epoch [5/200], Loss: 1.7471\n",
      "Epoch [6/200], Loss: 1.6593\n",
      "Epoch [7/200], Loss: 1.5154\n",
      "Epoch [8/200], Loss: 1.8421\n",
      "Epoch [9/200], Loss: 1.4890\n",
      "Epoch [10/200], Loss: 1.6474\n",
      "Epoch [11/200], Loss: 1.4029\n",
      "Epoch [12/200], Loss: 1.5514\n",
      "Epoch [13/200], Loss: 1.1521\n",
      "Epoch [14/200], Loss: 1.4375\n",
      "Epoch [15/200], Loss: 1.2638\n",
      "Epoch [16/200], Loss: 1.1911\n",
      "Epoch [17/200], Loss: 1.7999\n",
      "Epoch [18/200], Loss: 1.3572\n",
      "Epoch [19/200], Loss: 1.0963\n",
      "Epoch [20/200], Loss: 1.1607\n",
      "Epoch [21/200], Loss: 1.2423\n",
      "Epoch [22/200], Loss: 1.0830\n",
      "Epoch [23/200], Loss: 0.9531\n",
      "Epoch [24/200], Loss: 1.1033\n",
      "Epoch [25/200], Loss: 1.0495\n",
      "Epoch [26/200], Loss: 1.0428\n",
      "Epoch [27/200], Loss: 0.9888\n",
      "Epoch [28/200], Loss: 0.8660\n",
      "Epoch [29/200], Loss: 0.8275\n",
      "Epoch [30/200], Loss: 0.9698\n",
      "Epoch [31/200], Loss: 0.8939\n",
      "Epoch [32/200], Loss: 0.8681\n",
      "Epoch [33/200], Loss: 0.8152\n",
      "Epoch [34/200], Loss: 0.7845\n",
      "Epoch [35/200], Loss: 0.8986\n",
      "Epoch [36/200], Loss: 0.8042\n",
      "Epoch [37/200], Loss: 0.7608\n",
      "Epoch [38/200], Loss: 0.7565\n",
      "Epoch [39/200], Loss: 0.7953\n",
      "Epoch [40/200], Loss: 0.7175\n",
      "Epoch [41/200], Loss: 0.7054\n",
      "Epoch [42/200], Loss: 0.7112\n",
      "Epoch [43/200], Loss: 0.8077\n",
      "Epoch [44/200], Loss: 0.6295\n",
      "Epoch [45/200], Loss: 0.5802\n",
      "Epoch [46/200], Loss: 0.7444\n",
      "Epoch [47/200], Loss: 0.6209\n",
      "Epoch [48/200], Loss: 0.5555\n",
      "Epoch [49/200], Loss: 0.5445\n",
      "Epoch [50/200], Loss: 0.6842\n",
      "Epoch [51/200], Loss: 0.5730\n",
      "Epoch [52/200], Loss: 0.8504\n",
      "Epoch [53/200], Loss: 0.5991\n",
      "Epoch [54/200], Loss: 0.5641\n",
      "Epoch [55/200], Loss: 0.6080\n",
      "Epoch [56/200], Loss: 0.7575\n",
      "Epoch [57/200], Loss: 0.6350\n",
      "Epoch [58/200], Loss: 0.5996\n",
      "Epoch [59/200], Loss: 0.4450\n",
      "Epoch [60/200], Loss: 0.3842\n",
      "Epoch [61/200], Loss: 0.5176\n",
      "Epoch [62/200], Loss: 0.5679\n",
      "Epoch [63/200], Loss: 0.5528\n",
      "Epoch [64/200], Loss: 0.4113\n",
      "Epoch [65/200], Loss: 0.3532\n",
      "Epoch [66/200], Loss: 0.5840\n",
      "Epoch [67/200], Loss: 0.3454\n",
      "Epoch [68/200], Loss: 0.4097\n",
      "Epoch [69/200], Loss: 0.4544\n",
      "Epoch [70/200], Loss: 0.3917\n",
      "Epoch [71/200], Loss: 0.5799\n",
      "Epoch [72/200], Loss: 0.2838\n",
      "Epoch [73/200], Loss: 0.6409\n",
      "Epoch [74/200], Loss: 0.3534\n",
      "Epoch [75/200], Loss: 0.3200\n",
      "Epoch [76/200], Loss: 0.3250\n",
      "Epoch [77/200], Loss: 0.2803\n",
      "Epoch [78/200], Loss: 0.3233\n",
      "Epoch [79/200], Loss: 0.2773\n",
      "Epoch [80/200], Loss: 0.5868\n",
      "Epoch [81/200], Loss: 0.2768\n",
      "Epoch [82/200], Loss: 0.4657\n",
      "Epoch [83/200], Loss: 0.3554\n",
      "Epoch [84/200], Loss: 0.6583\n",
      "Epoch [85/200], Loss: 0.2893\n",
      "Epoch [86/200], Loss: 0.4516\n",
      "Epoch [87/200], Loss: 0.2340\n",
      "Epoch [88/200], Loss: 0.2783\n",
      "Epoch [89/200], Loss: 0.5543\n",
      "Epoch [90/200], Loss: 0.1741\n",
      "Epoch [91/200], Loss: 0.2065\n",
      "Epoch [92/200], Loss: 0.1702\n",
      "Epoch [93/200], Loss: 0.2018\n",
      "Epoch [94/200], Loss: 0.3307\n",
      "Epoch [95/200], Loss: 0.2515\n",
      "Epoch [96/200], Loss: 0.1820\n",
      "Epoch [97/200], Loss: 0.3194\n",
      "Epoch [98/200], Loss: 0.1703\n",
      "Epoch [99/200], Loss: 0.2518\n",
      "Epoch [100/200], Loss: 0.2121\n",
      "Epoch [101/200], Loss: 0.1785\n",
      "Epoch [102/200], Loss: 0.3708\n",
      "Epoch [103/200], Loss: 0.6486\n",
      "Epoch [104/200], Loss: 0.4055\n",
      "Epoch [105/200], Loss: 0.1900\n",
      "Epoch [106/200], Loss: 0.1136\n",
      "Epoch [107/200], Loss: 0.4585\n",
      "Epoch [108/200], Loss: 0.1102\n",
      "Epoch [109/200], Loss: 0.1314\n",
      "Epoch [110/200], Loss: 0.1989\n",
      "Epoch [111/200], Loss: 0.2921\n",
      "Epoch [112/200], Loss: 0.3461\n",
      "Epoch [113/200], Loss: 0.3396\n",
      "Epoch [114/200], Loss: 0.2381\n",
      "Epoch [115/200], Loss: 0.1390\n",
      "Epoch [116/200], Loss: 0.3491\n",
      "Epoch [117/200], Loss: 0.1878\n",
      "Epoch [118/200], Loss: 0.2078\n",
      "Epoch [119/200], Loss: 0.4978\n",
      "Epoch [120/200], Loss: 0.1311\n",
      "Epoch [121/200], Loss: 0.1267\n",
      "Epoch [122/200], Loss: 0.0784\n",
      "Epoch [123/200], Loss: 0.2779\n",
      "Epoch [124/200], Loss: 0.1375\n",
      "Epoch [125/200], Loss: 0.2085\n",
      "Epoch [126/200], Loss: 0.1054\n",
      "Epoch [127/200], Loss: 0.0972\n",
      "Epoch [128/200], Loss: 0.1177\n",
      "Epoch [129/200], Loss: 0.3880\n",
      "Epoch [130/200], Loss: 0.1689\n",
      "Epoch [131/200], Loss: 0.1465\n",
      "Epoch [132/200], Loss: 0.0748\n",
      "Epoch [133/200], Loss: 0.1143\n",
      "Epoch [134/200], Loss: 0.3798\n",
      "Epoch [135/200], Loss: 0.1869\n",
      "Epoch [136/200], Loss: 0.2458\n",
      "Epoch [137/200], Loss: 0.0878\n",
      "Epoch [138/200], Loss: 0.2558\n",
      "Epoch [139/200], Loss: 0.0650\n",
      "Epoch [140/200], Loss: 0.1448\n",
      "Epoch [141/200], Loss: 0.2043\n",
      "Epoch [142/200], Loss: 0.3902\n",
      "Epoch [143/200], Loss: 0.1442\n",
      "Epoch [144/200], Loss: 0.1709\n",
      "Epoch [145/200], Loss: 0.1038\n",
      "Epoch [146/200], Loss: 0.1925\n",
      "Epoch [147/200], Loss: 0.1477\n",
      "Epoch [148/200], Loss: 0.0850\n",
      "Epoch [149/200], Loss: 0.1979\n",
      "Epoch [150/200], Loss: 0.0922\n",
      "Epoch [151/200], Loss: 0.2005\n",
      "Epoch [152/200], Loss: 0.0701\n",
      "Epoch [153/200], Loss: 0.0895\n",
      "Epoch [154/200], Loss: 0.0882\n",
      "Epoch [155/200], Loss: 0.1160\n",
      "Epoch [156/200], Loss: 0.0731\n",
      "Epoch [157/200], Loss: 0.1360\n",
      "Epoch [158/200], Loss: 0.2905\n",
      "Epoch [159/200], Loss: 0.0872\n",
      "Epoch [160/200], Loss: 0.1913\n",
      "Epoch [161/200], Loss: 0.1402\n",
      "Epoch [162/200], Loss: 0.0788\n",
      "Epoch [163/200], Loss: 0.0619\n",
      "Epoch [164/200], Loss: 0.2683\n",
      "Epoch [165/200], Loss: 0.0785\n",
      "Epoch [166/200], Loss: 0.0369\n",
      "Epoch [167/200], Loss: 0.0403\n",
      "Epoch [168/200], Loss: 0.1666\n",
      "Epoch [169/200], Loss: 0.0355\n",
      "Epoch [170/200], Loss: 0.0637\n",
      "Epoch [171/200], Loss: 0.0712\n",
      "Epoch [172/200], Loss: 0.2652\n",
      "Epoch [173/200], Loss: 0.0361\n",
      "Epoch [174/200], Loss: 0.2663\n",
      "Epoch [175/200], Loss: 0.1582\n",
      "Epoch [176/200], Loss: 0.0711\n",
      "Epoch [177/200], Loss: 0.0413\n",
      "Epoch [178/200], Loss: 0.0683\n",
      "Epoch [179/200], Loss: 0.1468\n",
      "Epoch [180/200], Loss: 0.0481\n",
      "Epoch [181/200], Loss: 0.0407\n",
      "Epoch [182/200], Loss: 0.0535\n",
      "Epoch [183/200], Loss: 0.0586\n",
      "Epoch [184/200], Loss: 0.0408\n",
      "Epoch [185/200], Loss: 0.2731\n",
      "Epoch [186/200], Loss: 0.0603\n",
      "Epoch [187/200], Loss: 0.0333\n",
      "Epoch [188/200], Loss: 0.0597\n",
      "Epoch [189/200], Loss: 0.1020\n",
      "Epoch [190/200], Loss: 0.1028\n",
      "Epoch [191/200], Loss: 0.0600\n",
      "Epoch [192/200], Loss: 0.2260\n",
      "Epoch [193/200], Loss: 0.1405\n",
      "Epoch [194/200], Loss: 0.0429\n",
      "Epoch [195/200], Loss: 0.6579\n",
      "Epoch [196/200], Loss: 0.0327\n",
      "Epoch [197/200], Loss: 0.2785\n",
      "Epoch [198/200], Loss: 0.2281\n",
      "Epoch [199/200], Loss: 0.1669\n",
      "Epoch [200/200], Loss: 0.0412\n"
     ]
    }
   ],
   "source": [
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 20）\n",
    "feature_extractor = FeatureExtractor(input_channels=20).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 定义分类头\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=9).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练分类头和特征提取器\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()  # 微调特征提取器\n",
    "    classification_head.train()  # 训练分类头\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征\n",
    "            features = feature_extractor(cubes)\n",
    "\n",
    "            # 分类头进行训练\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9524\n",
      "Average Accuracy: 0.9512\n",
      "Kappa Coefficient: 0.9382\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 35763 predictions\n",
      "Class 1: 10199 predictions\n",
      "Class 2: 4797 predictions\n",
      "Class 3: 56227 predictions\n",
      "Class 4: 6311 predictions\n",
      "Class 5: 11796 predictions\n",
      "Class 6: 66848 predictions\n",
      "Class 7: 7848 predictions\n",
      "Class 8: 4753 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.9947\n",
      "Class 1: 0.9818\n",
      "Class 2: 0.9815\n",
      "Class 3: 0.8807\n",
      "Class 4: 0.9641\n",
      "Class 5: 0.9906\n",
      "Class 6: 0.9961\n",
      "Class 7: 0.9569\n",
      "Class 8: 0.8143\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "领域： 原始loss\n",
    "Overall Accuracy: 0.9616\n",
    "Average Accuracy: 0.9388\n",
    "Kappa Coefficient: 0.9499\n",
    "\n",
    "Prediction Distribution:\n",
    "Class 0: 34349 predictions\n",
    "Class 1: 8503 predictions\n",
    "Class 2: 5258 predictions\n",
    "Class 3: 59185 predictions\n",
    "Class 4: 6096 predictions\n",
    "Class 5: 11427 predictions\n",
    "Class 6: 66828 predictions\n",
    "Class 7: 8892 predictions\n",
    "Class 8: 4004 predictions\n",
    "\n",
    "\n",
    "Overall Accuracy: 0.9567\n",
    "Average Accuracy: 0.9483\n",
    "Kappa Coefficient: 0.9438\n",
    "\n",
    "Prediction Distribution:\n",
    "Class 0: 34410 predictions\n",
    "Class 1: 9838 predictions\n",
    "Class 2: 5257 predictions\n",
    "Class 3: 57291 predictions\n",
    "Class 4: 6542 predictions\n",
    "Class 5: 11611 predictions\n",
    "Class 6: 66905 predictions\n",
    "Class 7: 8491 predictions\n",
    "Class 8: 4197 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 74:\n",
      "  OA    = 0.9634\n",
      "  AA    = 0.9398\n",
      "  Kappa = 0.9521\n",
      "Per-class accuracy:\n",
      "  Class 1: 0.9951\n",
      "  Class 2: 0.8957\n",
      "  Class 3: 0.9805\n",
      "  Class 4: 0.9369\n",
      "  Class 5: 0.9477\n",
      "  Class 6: 0.9544\n",
      "  Class 7: 0.9953\n",
      "  Class 8: 0.9778\n",
      "  Class 9: 0.7745\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "\n",
    "# ...extract_cube、apply_pca_train_only、ClassificationDataset、FeatureExtractor、ClassificationHead等定义...\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_and_evaluate(seed, pca_data, train_labels, test_labels, checkpoint, num_classes=9, epochs=200):\n",
    "    set_seed(seed)\n",
    "\n",
    "    feat = FeatureExtractor(input_channels=40).cuda()\n",
    "    feat.load_state_dict(checkpoint[\"feature_extractor_state_dict\"])\n",
    "\n",
    "    head = ClassificationHead(input_dim=128, num_classes=num_classes).cuda()\n",
    "\n",
    "    train_ds = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "    test_ds  = ClassificationDataset(pca_data, test_labels,  patch_size=11)\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': feat.parameters(), 'lr': 1e-4},\n",
    "        {'params': head.parameters(), 'lr': 1e-3},\n",
    "    ])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        feat.train(); head.train()\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            feats = feat(cubes)\n",
    "            outputs = head(feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "\n",
    "    # 测试\n",
    "    feat.eval(); head.eval()\n",
    "    all_preds, all_lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            outs = head(feat(cubes))\n",
    "            preds = outs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_lbls.extend(labels.cpu().numpy())\n",
    "\n",
    "    oa = accuracy_score(all_lbls, all_preds)\n",
    "\n",
    "    # 计算每类的准确率\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_lbls = np.array(all_lbls)\n",
    "    class_accs = []\n",
    "    for cls in range(num_classes):\n",
    "        idx = (all_lbls == cls)\n",
    "        if np.sum(idx) == 0:\n",
    "            acc = np.nan\n",
    "        else:\n",
    "            acc = np.mean(all_preds[idx] == cls)\n",
    "        class_accs.append(acc)\n",
    "\n",
    "    # 计算AA（不计nan）\n",
    "    aa = np.nanmean(class_accs)\n",
    "\n",
    "    # 计算Kappa\n",
    "    kappa = cohen_kappa_score(all_lbls, all_preds)\n",
    "\n",
    "    return oa, aa, kappa, class_accs\n",
    "\n",
    "# 主流程\n",
    "SEED = 74\n",
    "checkpoint = torch.load(\"final/Whu_lin_50_model1.pth\")\n",
    "\n",
    "oa, aa, kappa, class_accs = train_and_evaluate(SEED, pca_data, train_labels, test_labels, checkpoint)\n",
    "\n",
    "print(f\"  OA    = {oa:.4f}\")\n",
    "print(f\"  AA    = {aa:.4f}\")\n",
    "print(f\"  Kappa = {kappa:.4f}\")\n",
    "print(\"Per-class accuracy:\")\n",
    "for i, acc in enumerate(class_accs, 1):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1: OA = 0.9457\n",
      "Seed 2: OA = 0.9388\n",
      "Seed 3: OA = 0.9373\n",
      "Seed 4: OA = 0.9278\n",
      "Seed 5: OA = 0.9426\n",
      "Seed 6: OA = 0.9341\n",
      "Seed 7: OA = 0.9482\n",
      "Seed 8: OA = 0.9533\n",
      "Seed 9: OA = 0.9452\n",
      "Seed 10: OA = 0.9468\n",
      "Seed 11: OA = 0.9454\n",
      "Seed 12: OA = 0.9441\n",
      "Seed 13: OA = 0.9432\n",
      "Seed 14: OA = 0.9379\n",
      "Seed 15: OA = 0.9493\n",
      "Seed 16: OA = 0.9472\n",
      "Seed 17: OA = 0.9367\n",
      "Seed 18: OA = 0.9546\n",
      "Seed 19: OA = 0.9468\n",
      "Seed 20: OA = 0.9434\n",
      "Seed 21: OA = 0.9410\n",
      "Seed 22: OA = 0.9477\n",
      "Seed 23: OA = 0.9366\n",
      "Seed 24: OA = 0.9439\n",
      "Seed 25: OA = 0.9348\n",
      "Seed 26: OA = 0.9442\n",
      "Seed 27: OA = 0.9461\n",
      "Seed 28: OA = 0.9456\n",
      "Seed 29: OA = 0.9435\n",
      "Seed 30: OA = 0.9360\n",
      "Seed 31: OA = 0.9419\n",
      "Seed 32: OA = 0.9416\n",
      "Seed 33: OA = 0.9422\n",
      "Seed 34: OA = 0.9500\n",
      "Seed 35: OA = 0.9497\n",
      "Seed 36: OA = 0.9420\n",
      "Seed 37: OA = 0.9461\n",
      "Seed 38: OA = 0.9285\n",
      "Seed 39: OA = 0.9382\n",
      "Seed 40: OA = 0.9424\n",
      "Seed 41: OA = 0.9466\n",
      "Seed 42: OA = 0.9499\n",
      "Seed 43: OA = 0.9377\n",
      "Seed 44: OA = 0.9472\n",
      "Seed 45: OA = 0.9503\n",
      "Seed 46: OA = 0.9433\n",
      "Seed 47: OA = 0.9479\n",
      "Seed 48: OA = 0.9376\n",
      "Seed 49: OA = 0.9429\n",
      "Seed 50: OA = 0.9435\n",
      "Seed 51: OA = 0.9488\n",
      "Seed 52: OA = 0.9434\n",
      "Seed 53: OA = 0.9476\n",
      "Seed 54: OA = 0.9335\n",
      "Seed 55: OA = 0.9472\n",
      "Seed 56: OA = 0.9350\n",
      "Seed 57: OA = 0.9435\n",
      "Seed 58: OA = 0.9469\n",
      "Seed 59: OA = 0.9460\n",
      "Seed 60: OA = 0.9432\n",
      "Seed 61: OA = 0.9543\n",
      "Seed 62: OA = 0.9357\n",
      "Seed 63: OA = 0.9417\n",
      "Seed 64: OA = 0.9404\n",
      "Seed 65: OA = 0.9422\n",
      "Seed 66: OA = 0.9468\n",
      "Seed 67: OA = 0.9398\n",
      "Seed 68: OA = 0.9458\n",
      "Seed 69: OA = 0.9464\n",
      "Seed 70: OA = 0.9441\n",
      "Seed 71: OA = 0.9300\n",
      "Seed 72: OA = 0.9432\n",
      "Seed 73: OA = 0.9475\n",
      "Seed 74: OA = 0.9619\n",
      "Seed 75: OA = 0.9374\n",
      "Seed 76: OA = 0.9466\n",
      "Seed 77: OA = 0.9469\n",
      "Seed 78: OA = 0.9390\n",
      "Seed 79: OA = 0.9456\n",
      "Seed 80: OA = 0.9337\n",
      "Seed 81: OA = 0.9433\n",
      "Seed 82: OA = 0.9387\n",
      "Seed 83: OA = 0.9473\n",
      "Seed 84: OA = 0.9516\n",
      "Seed 85: OA = 0.9480\n",
      "Seed 86: OA = 0.9476\n",
      "Seed 87: OA = 0.9458\n",
      "Seed 88: OA = 0.9411\n",
      "Seed 89: OA = 0.9418\n",
      "Seed 90: OA = 0.9452\n",
      "Seed 91: OA = 0.9430\n",
      "Seed 92: OA = 0.9550\n",
      "Seed 93: OA = 0.9494\n",
      "Seed 94: OA = 0.9496\n",
      "Seed 95: OA = 0.9548\n",
      "Seed 96: OA = 0.9393\n",
      "Seed 97: OA = 0.9429\n",
      "Seed 98: OA = 0.9471\n",
      "Seed 99: OA = 0.9526\n",
      "Seed 100: OA = 0.9424\n",
      "\n",
      "Best seed: 74 with OA = 0.9619\n",
      "Average OA over seeds 91~100: 0.9439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# --- Existing helper functions ---\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    c, h, w = data.shape\n",
    "    half = size[0] // 2\n",
    "    x_min, x_max = max(0, x - half), min(h, x + half + 1)\n",
    "    y_min, y_max = max(0, y - half), min(w, y + half + 1)\n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "    pad = [\n",
    "        (0,0),\n",
    "        (max(0, half - x), max(0, x + half + 1 - h)),\n",
    "        (max(0, half - y), max(0, y + half + 1 - w)),\n",
    "    ]\n",
    "    return np.pad(cube, pad, mode=\"edge\")\n",
    "\n",
    "\n",
    "def apply_pca_train_only(hsi, truth, num_components=40):\n",
    "    c, h, w = hsi.shape\n",
    "    rows, cols = truth.row, truth.col\n",
    "    train_spectra = hsi[:, rows, cols].T\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)\n",
    "    flat = hsi.reshape(c, -1).T\n",
    "    reduced = pca.transform(flat)\n",
    "    return reduced.T.reshape(num_components, h, w), pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        self.data, self.labels, self.patch = data, labels, patch_size\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        x,y,l = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch, self.patch))\n",
    "        return torch.tensor(cube).float(), torch.tensor(l-1, dtype=torch.long)\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "\n",
    "# --- Seed search loop ---\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_and_evaluate(seed, pca_data, train_labels, test_labels, checkpoint, num_classes=9, epochs=200):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 加载预训练的 FeatureExtractor 并加载权重\n",
    "    feat = FeatureExtractor(input_channels=40).cuda()\n",
    "    feat.load_state_dict(checkpoint[\"feature_extractor_state_dict\"])\n",
    "\n",
    "    # 可选：是否冻结预训练的特征提取器（如果你只想训练分类头）\n",
    "    # for param in feat.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # 初始化分类头\n",
    "    head = ClassificationHead(input_dim=128, num_classes=num_classes).cuda()\n",
    "\n",
    "    # 构建数据加载器\n",
    "    train_ds = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "    test_ds  = ClassificationDataset(pca_data, test_labels,  patch_size=11)\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': feat.parameters(), 'lr': 1e-4},  # 微调\n",
    "        {'params': head.parameters(), 'lr': 1e-3},  # 分类头训练\n",
    "    ])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        feat.train(); head.train()\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            feats = feat(cubes)\n",
    "            outputs = head(feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "\n",
    "    # 测试\n",
    "    feat.eval(); head.eval()\n",
    "    all_preds, all_lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            outs = head(feat(cubes))\n",
    "            preds = outs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_lbls.extend(labels.cpu().numpy())\n",
    "\n",
    "    oa = accuracy_score(all_lbls, all_preds)\n",
    "    return oa\n",
    "\n",
    "checkpoint = torch.load(\"final/Whu_lin_50_model1.pth\")\n",
    "oas = []\n",
    "best_seed, best_oa = None, -1\n",
    "\n",
    "for seed in range(1, 101):\n",
    "    oa = train_and_evaluate(seed, pca_data, train_labels, test_labels, checkpoint)\n",
    "    print(f\"Seed {seed}: OA = {oa:.4f}\")\n",
    "    oas.append(oa)\n",
    "    if oa > best_oa:\n",
    "        best_oa, best_seed = oa, seed\n",
    "\n",
    "mean_oa = np.mean(oas)\n",
    "print(f\"\\nBest seed: {best_seed} with OA = {best_oa:.4f}\")\n",
    "print(f\"Average OA over seeds 91~100: {mean_oa:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1: OA = 0.9448\n",
      "Seed 2: OA = 0.9344\n",
      "Seed 3: OA = 0.9324\n",
      "Seed 4: OA = 0.9314\n",
      "Seed 5: OA = 0.9378\n",
      "Seed 6: OA = 0.9359\n",
      "Seed 7: OA = 0.9500\n",
      "Seed 8: OA = 0.9519\n",
      "Seed 9: OA = 0.9477\n",
      "Seed 10: OA = 0.9509\n",
      "Seed 11: OA = 0.9366\n",
      "Seed 12: OA = 0.9451\n",
      "Seed 13: OA = 0.9472\n",
      "Seed 14: OA = 0.9296\n",
      "Seed 15: OA = 0.9471\n",
      "Seed 16: OA = 0.9344\n",
      "Seed 17: OA = 0.9350\n",
      "Seed 18: OA = 0.9526\n",
      "Seed 19: OA = 0.9432\n",
      "Seed 20: OA = 0.9415\n",
      "Seed 21: OA = 0.9353\n",
      "Seed 22: OA = 0.9528\n",
      "Seed 23: OA = 0.9239\n",
      "Seed 24: OA = 0.9416\n",
      "Seed 25: OA = 0.9440\n",
      "Seed 26: OA = 0.9414\n",
      "Seed 27: OA = 0.9493\n",
      "Seed 28: OA = 0.9483\n",
      "Seed 29: OA = 0.9466\n",
      "Seed 30: OA = 0.9305\n",
      "Seed 31: OA = 0.9427\n",
      "Seed 32: OA = 0.9451\n",
      "Seed 33: OA = 0.9485\n",
      "Seed 34: OA = 0.9520\n",
      "Seed 35: OA = 0.9429\n",
      "Seed 36: OA = 0.9405\n",
      "Seed 37: OA = 0.9424\n",
      "Seed 38: OA = 0.9262\n",
      "Seed 39: OA = 0.9356\n",
      "Seed 40: OA = 0.9422\n",
      "Seed 41: OA = 0.9411\n",
      "Seed 42: OA = 0.9512\n",
      "Seed 43: OA = 0.9373\n",
      "Seed 44: OA = 0.9432\n",
      "Seed 45: OA = 0.9545\n",
      "Seed 46: OA = 0.9360\n",
      "Seed 47: OA = 0.9381\n",
      "Seed 48: OA = 0.9383\n",
      "Seed 49: OA = 0.9429\n",
      "Seed 50: OA = 0.9409\n",
      "Seed 51: OA = 0.9411\n",
      "Seed 52: OA = 0.9428\n",
      "Seed 53: OA = 0.9448\n",
      "Seed 54: OA = 0.9293\n",
      "Seed 55: OA = 0.9404\n",
      "Seed 56: OA = 0.9199\n",
      "Seed 57: OA = 0.9457\n",
      "Seed 58: OA = 0.9515\n",
      "Seed 59: OA = 0.9433\n",
      "Seed 60: OA = 0.9361\n",
      "Seed 61: OA = 0.9498\n",
      "Seed 62: OA = 0.9442\n",
      "Seed 63: OA = 0.9393\n",
      "Seed 64: OA = 0.9422\n",
      "Seed 65: OA = 0.9322\n",
      "Seed 66: OA = 0.9490\n",
      "Seed 67: OA = 0.9258\n",
      "Seed 68: OA = 0.9419\n",
      "Seed 69: OA = 0.9574\n",
      "Seed 70: OA = 0.9454\n",
      "Seed 71: OA = 0.9312\n",
      "Seed 72: OA = 0.9426\n",
      "Seed 73: OA = 0.9455\n",
      "Seed 74: OA = 0.9563\n",
      "Seed 75: OA = 0.9351\n",
      "Seed 76: OA = 0.9339\n",
      "Seed 77: OA = 0.9431\n",
      "Seed 78: OA = 0.9299\n",
      "Seed 79: OA = 0.9377\n",
      "Seed 80: OA = 0.9327\n",
      "Seed 81: OA = 0.9377\n",
      "Seed 82: OA = 0.9260\n",
      "Seed 83: OA = 0.9476\n",
      "Seed 84: OA = 0.9515\n",
      "Seed 85: OA = 0.9457\n",
      "Seed 86: OA = 0.9483\n",
      "Seed 87: OA = 0.9427\n",
      "Seed 88: OA = 0.9457\n",
      "Seed 89: OA = 0.9355\n",
      "Seed 90: OA = 0.9446\n",
      "Seed 91: OA = 0.9429\n",
      "Seed 92: OA = 0.9438\n",
      "Seed 93: OA = 0.9388\n",
      "Seed 94: OA = 0.9450\n",
      "Seed 95: OA = 0.9508\n",
      "Seed 96: OA = 0.9387\n",
      "Seed 97: OA = 0.9475\n",
      "Seed 98: OA = 0.9437\n",
      "Seed 99: OA = 0.9535\n",
      "Seed 100: OA = 0.9398\n",
      "\n",
      "Best seed: 69 with OA = 0.9574\n",
      "Average OA over seeds 91~100: 0.9416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# --- Existing helper functions ---\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    c, h, w = data.shape\n",
    "    half = size[0] // 2\n",
    "    x_min, x_max = max(0, x - half), min(h, x + half + 1)\n",
    "    y_min, y_max = max(0, y - half), min(w, y + half + 1)\n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "    pad = [\n",
    "        (0,0),\n",
    "        (max(0, half - x), max(0, x + half + 1 - h)),\n",
    "        (max(0, half - y), max(0, y + half + 1 - w)),\n",
    "    ]\n",
    "    return np.pad(cube, pad, mode=\"edge\")\n",
    "\n",
    "\n",
    "def apply_pca_train_only(hsi, truth, num_components=40):\n",
    "    c, h, w = hsi.shape\n",
    "    rows, cols = truth.row, truth.col\n",
    "    train_spectra = hsi[:, rows, cols].T\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)\n",
    "    flat = hsi.reshape(c, -1).T\n",
    "    reduced = pca.transform(flat)\n",
    "    return reduced.T.reshape(num_components, h, w), pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        self.data, self.labels, self.patch = data, labels, patch_size\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        x,y,l = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch, self.patch))\n",
    "        return torch.tensor(cube).float(), torch.tensor(l-1, dtype=torch.long)\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "\n",
    "# --- Seed search loop ---\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_and_evaluate(seed, pca_data, train_labels, test_labels, checkpoint, num_classes=9, epochs=200):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 加载预训练的 FeatureExtractor 并加载权重\n",
    "    feat = FeatureExtractor(input_channels=40).cuda()\n",
    "    feat.load_state_dict(checkpoint[\"feature_extractor_state_dict\"])\n",
    "\n",
    "    # 可选：是否冻结预训练的特征提取器（如果你只想训练分类头）\n",
    "    # for param in feat.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # 初始化分类头\n",
    "    head = ClassificationHead(input_dim=128, num_classes=num_classes).cuda()\n",
    "\n",
    "    # 构建数据加载器\n",
    "    train_ds = ClassificationDataset(pca_data, train_labels, patch_size=11)\n",
    "    test_ds  = ClassificationDataset(pca_data, test_labels,  patch_size=11)\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': feat.parameters(), 'lr': 1e-4},  # 微调\n",
    "        {'params': head.parameters(), 'lr': 1e-3},  # 分类头训练\n",
    "    ])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        feat.train(); head.train()\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            feats = feat(cubes)\n",
    "            outputs = head(feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "\n",
    "    # 测试\n",
    "    feat.eval(); head.eval()\n",
    "    all_preds, all_lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            outs = head(feat(cubes))\n",
    "            preds = outs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_lbls.extend(labels.cpu().numpy())\n",
    "\n",
    "    oa = accuracy_score(all_lbls, all_preds)\n",
    "    return oa\n",
    "\n",
    "checkpoint = torch.load(\"final/Whu_lin_150_model1.pth\")\n",
    "oas = []\n",
    "best_seed, best_oa = None, -1\n",
    "\n",
    "for seed in range(1, 101):\n",
    "    oa = train_and_evaluate(seed, pca_data, train_labels, test_labels, checkpoint)\n",
    "    print(f\"Seed {seed}: OA = {oa:.4f}\")\n",
    "    oas.append(oa)\n",
    "    if oa > best_oa:\n",
    "        best_oa, best_seed = oa, seed\n",
    "\n",
    "mean_oa = np.mean(oas)\n",
    "print(f\"\\nBest seed: {best_seed} with OA = {best_oa:.4f}\")\n",
    "print(f\"Average OA over seeds 91~100: {mean_oa:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
