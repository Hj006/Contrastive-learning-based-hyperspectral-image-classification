{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.exposure\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation\n",
    "import random\n",
    "from scipy.sparse import coo_array\n",
    "from scipy.io import loadmat\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 如果你显示中文，改为你系统支持的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pavia_university_with_full_test(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 Pavia University 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 10 个作为训练样本\n",
    "    - 所有 ground truth 像素都作为测试样本（包括候选/训练区域）\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    pavia_data = loadmat(data_path / 'PaviaU.mat')['paviaU']\n",
    "    gt = loadmat(data_path / 'PaviaU_gt.mat')['paviaU_gt']\n",
    "    h, w, c = pavia_data.shape\n",
    "\n",
    "    label_dict = {\n",
    "        1: 'Asphalt road', 2: 'Meadows', 3: 'Gravel',\n",
    "        4: 'Trees', 5: 'Painted metal sheets', 6: 'Bare Soil',\n",
    "        7: 'Bitumen', 8: 'Self-Blocking Bricks', 9: 'Shadows',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\" 类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    #  测试集直接包含所有 ground truth\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return pavia_data.transpose(2, 0, 1), train_truth, candidate_truth, test_truth, info\n",
    "\n",
    "\n",
    "def merge_train_test(train_truth, test_truth, shape):\n",
    "    \"\"\"\n",
    "    合并训练集和测试集稀疏矩阵为一个新的训练集矩阵。\n",
    "    \n",
    "    参数:\n",
    "        train_truth: coo_matrix, 原始训练集稀疏矩阵\n",
    "        test_truth: coo_matrix, 原始测试集稀疏矩阵\n",
    "        shape: tuple, 数据的形状 (height, width)\n",
    "        \n",
    "    返回:\n",
    "        merged_truth: coo_matrix, 合并后的训练集稀疏矩阵\n",
    "    \"\"\"\n",
    "    # 合并行、列和数据\n",
    "    merged_rows = np.concatenate([train_truth.row, test_truth.row])\n",
    "    merged_cols = np.concatenate([train_truth.col, test_truth.col])\n",
    "    merged_data = np.concatenate([train_truth.data, test_truth.data])\n",
    "    \n",
    "    # 创建新的稀疏矩阵\n",
    "    merged_truth = coo_matrix((merged_data, (merged_rows, merged_cols)), shape=shape)\n",
    "    return merged_truth\n",
    "\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=40):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 高光谱图像数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: int, 保留的主成分数量\n",
    "        \n",
    "    返回:\n",
    "        pca_data: numpy.ndarray, PCA 降维后的数据，形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape  # 高光谱数据的形状\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "    \n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "    \n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "    \n",
    "    # 转换整个数据集 [C, H, W] -> [H×W, C]\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "    \n",
    "    # 恢复为原始图像的形状 [num_components, H, W]\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "def superpixel_segmentation(hsi_data, num_superpixels=100):\n",
    "    \"\"\"\n",
    "    使用 SLIC 超像素分割对 HSI 进行分割。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        num_superpixels: 生成的超像素数量\n",
    "        \n",
    "    返回:\n",
    "        labels: 超像素标签矩阵，形状为 (H, W)\n",
    "    \"\"\"\n",
    "    # 先用 PCA 提取第一主成分\n",
    "    first_pc = PCA(n_components=1).fit_transform(hsi_data.reshape(hsi_data.shape[0], -1).T)\n",
    "    first_pc = first_pc.reshape(hsi_data.shape[1:])  # 变成 (H, W)\n",
    "\n",
    "    # 修正错误：复制 3 通道，使其符合 SLIC 需 \n",
    "    first_pc_rgb = np.stack([first_pc] * 3, axis=-1)  # 变成 (H, W, 3)\n",
    "\n",
    "    # 正确调用 skimage.segmentation.sli \n",
    "    labels = skimage.segmentation.slic(first_pc_rgb, n_segments=num_superpixels, compactness=10, start_label=0, channel_axis=-1)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_superpixel_pca(hsi_data, superpixel_labels, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算每个超像素的局部 PCA，并返回降维后的特征。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        superpixel_labels: numpy.ndarray, 形状为 (H, W)\n",
    "        merged_train_truth: coo_matrix, 训练区域掩码\n",
    "        num_components: int, PCA 维度\n",
    "        \n",
    "    返回:\n",
    "        superpixel_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "        superpixel_pca_dict: dict, 每个超像素的局部PCA结果\n",
    "    \"\"\"\n",
    "    h, w = superpixel_labels.shape\n",
    "    c = hsi_data.shape[0]\n",
    "    superpixel_pca_map = np.zeros((num_components, h, w))\n",
    "    superpixel_pca_dict = {}\n",
    "\n",
    "    # 获取训练区域坐标\n",
    "    mask_train = merged_train_truth.toarray() > 0\n",
    "\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "\n",
    "        # 当前超像素区域内的训练区域\n",
    "        train_mask = np.logical_and(mask, mask_train)\n",
    "        if np.sum(train_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        pixels = hsi_data[:, train_mask].T  # shape: (num_samples, num_channels)\n",
    "\n",
    "        # 如果样本数不足，跳过\n",
    "        if pixels.shape[0] <= num_components:\n",
    "            continue\n",
    "\n",
    "        # 执行局部 PCA\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced_pixels = pca.fit_transform(pixels)\n",
    "        superpixel_pca_dict[label] = reduced_pixels.T  # shape: (num_components, N)\n",
    "\n",
    "        # 计算均值写入整块区域\n",
    "        for i in range(num_components):\n",
    "            superpixel_pca_map[i, mask] = np.mean(reduced_pixels[:, i])\n",
    "\n",
    "    return superpixel_pca_map, superpixel_pca_dict\n",
    "\n",
    "\n",
    "\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    c1 = c // 2  # 每个子块保留一半的通道\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱数据中提取局部立方块，并在边界不足时进行填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy.ndarray, 形状为 [C, H, W]\n",
    "        x, y: int, 立方块的中心像素坐标\n",
    "        size: tuple, 立方块的大小 (s, s)，要求 s 必须是奇数\n",
    "    \n",
    "    返回:\n",
    "        cube: numpy.ndarray, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    assert size[0] % 2 == 1, \"立方块大小必须是奇数，以确保中心点对齐。\"\n",
    "    \n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2  # 计算半径\n",
    "\n",
    "    # 计算提取区域的坐标范围\n",
    "    x_min, x_max = max(0, x - half_size), min(h, x + half_size + 1)\n",
    "    y_min, y_max = max(0, y - half_size), min(w, y + half_size + 1)\n",
    "\n",
    "    # 提取局部数据\n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 计算需要填充的大小\n",
    "    pad_x_min, pad_x_max = max(0, half_size - x), max(0, x + half_size + 1 - h)\n",
    "    pad_y_min, pad_y_max = max(0, half_size - y), max(0, y + half_size + 1 - w)\n",
    "\n",
    "    # 使用边缘填充，确保输出形状为 (C, size, size)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (pad_x_min, pad_x_max),  # 高度填充\n",
    "        (pad_y_min, pad_y_max),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"edge\")  # 填充值是边界像素，而不是反射\n",
    "    #cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=40):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n",
    "    \n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss_wrong(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, margin=1.0, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Triplet-based contrastive loss with multiple hard negatives.\n",
    "    - anchor: features_a[i]\n",
    "    - positive: features_b[i]\n",
    "    - negatives: top-k most dissimilar samples from [features_a; features_b]\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine all features as potential negatives\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # shape: [2N, D]\n",
    "\n",
    "    # Compute cosine similarity: [N, 2N]\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T)\n",
    "\n",
    "    # Mask out own positive at index i + batch_size\n",
    "    mask = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), mask + batch_size] = -1.0\n",
    "\n",
    "    # Get indices of top-k *least* similar samples (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Repeat anchors and positives for each negative\n",
    "    anchors = features_a.unsqueeze(1).repeat(1, num_negatives, 1).reshape(-1, features_a.shape[1])       # [N*k, D]\n",
    "    positives = features_b.unsqueeze(1).repeat(1, num_negatives, 1).reshape(-1, features_b.shape[1])     # [N*k, D]\n",
    "    negatives = all_features[neg_indices.reshape(-1)]  # [N*k, D]\n",
    "\n",
    "    # Compute triplet loss\n",
    "    triplet_loss_fn = nn.TripletMarginLoss(margin=margin, p=2, reduction='mean')\n",
    "    loss = triplet_loss_fn(anchors, positives, negatives)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def extract_precise_superpixel_pca(superpixel_pca_dict, superpixel_labels, x, y):\n",
    "    \"\"\"\n",
    "    获取像素 (x, y) 所属超像素的 SuperPCA 特征。\n",
    "    \n",
    "    参数:\n",
    "        superpixel_pca_dict: 字典，存储每个超像素的 PCA 结果\n",
    "        superpixel_labels: 超像素标签矩阵\n",
    "        x, y: 目标像素坐标\n",
    "        \n",
    "    返回:\n",
    "        superpixel_features: numpy.ndarray, 形状为 (20,)\n",
    "    \"\"\"\n",
    "    superpixel_label = superpixel_labels[x, y]  # 获取该像素的超像素标签\n",
    "    \n",
    "    # 获取该超像素块的所有 PCA 结果\n",
    "    superpixel_features = superpixel_pca_dict[superpixel_label]  # 形状为 (20, N)，N 是该超像素块内像素数\n",
    "\n",
    "    # 取所有像素的平均值，确保返回 20 维的特征向量\n",
    "    superpixel_features = np.mean(superpixel_features, axis=1)  # 形状变为 (20,)\n",
    "\n",
    "    return superpixel_features\n",
    "\n",
    "\n",
    "\n",
    "class S3PCADataset(Dataset):\n",
    "    def __init__(self, pca_data, superpixel_pca_map, superpixel_pca_dict, superpixel_labels, global_pca, patch_size=11, num_samples=1000):\n",
    "        self.pca_data = pca_data\n",
    "        self.superpixel_pca_map = superpixel_pca_map\n",
    "        self.superpixel_pca_dict = superpixel_pca_dict\n",
    "        self.superpixel_labels = superpixel_labels\n",
    "        self.global_pca = global_pca\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.h, self.w = pca_data.shape[1], pca_data.shape[2]\n",
    "\n",
    "        #  构造 valid_coords 列表\n",
    "        self.valid_coords = []\n",
    "        for x in range(patch_size // 2, self.h - patch_size // 2):\n",
    "            for y in range(patch_size // 2, self.w - patch_size // 2):\n",
    "                label = superpixel_labels[x, y]\n",
    "                if label in superpixel_pca_dict:\n",
    "                    self.valid_coords.append((x, y))\n",
    "\n",
    "        if len(self.valid_coords) == 0:\n",
    "            raise ValueError(\"没有找到任何有效的 superpixel 区域坐标！\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.num_samples, len(self.valid_coords))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #  从 valid_coords 中采样\n",
    "        x, y = self.valid_coords[idx % len(self.valid_coords)]  # 防止超出索引\n",
    "\n",
    "        # 提取 PCA patch\n",
    "        pca_patch = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "        pca_patch = torch.tensor(pca_patch, dtype=torch.float32)\n",
    "\n",
    "        # 拆分成两半\n",
    "        pca_channels = pca_patch.shape[0]\n",
    "        half_channels = pca_channels // 2\n",
    "        pca_patch_a, pca_patch_b = torch.split(pca_patch, [half_channels, pca_channels - half_channels], dim=0)\n",
    "\n",
    "        # 提取 Superpixel PCA\n",
    "        superpixel_patch = extract_precise_superpixel_pca(self.superpixel_pca_dict, self.superpixel_labels, x, y)\n",
    "        superpixel_patch = torch.tensor(superpixel_patch[:, None, None], dtype=torch.float32)\n",
    "        superpixel_patch = superpixel_patch.expand(-1, self.patch_size, self.patch_size)\n",
    "\n",
    "        # 提取 Global PCA\n",
    "        global_patch = extract_cube(self.global_pca, x, y, (self.patch_size, self.patch_size))\n",
    "        global_patch = torch.tensor(global_patch, dtype=torch.float32)\n",
    "\n",
    "        # 拼接形成 cube_a 和 cube_b\n",
    "        cube_a = torch.cat([pca_patch_a, superpixel_patch], dim=0)\n",
    "        cube_b = torch.cat([pca_patch_b, global_patch], dim=0)\n",
    "\n",
    "        return cube_a, cube_b\n",
    "\n",
    "class PCA_LDA_PatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, lda_data, coords, patch_size=11):\n",
    "        self.pca_data = pca_data\n",
    "        self.lda_data = lda_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.coords[idx]\n",
    "\n",
    "        cube_pca = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "        cube_lda = extract_cube(self.lda_data, x, y, (self.patch_size, self.patch_size))\n",
    "\n",
    "        return torch.tensor(cube_pca).float(), torch.tensor(cube_lda).float()\n",
    "\n",
    "\n",
    "\n",
    "def compute_global_pca(hsi_data, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算全局 PCA，并应用到整个 HSI。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (B, H, W)\n",
    "        merged_train_truth: coo_matrix, 标注的训练区域\n",
    "        num_components: int, PCA 降维维度\n",
    "        \n",
    "    返回:\n",
    "        global_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = merged_train_truth.row, merged_train_truth.col  # 获取训练样本的位置\n",
    "\n",
    "    # 取出训练区域的数据\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # (num_samples, num_channels)\n",
    "\n",
    "    # 在训练数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 只在训练数据上拟合\n",
    "\n",
    "    # 对整个 HSI 应用 PCA 变换\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # (H*W, C)\n",
    "    reduced_data = pca.transform(reshaped_data)  # (H*W, num_components)\n",
    "\n",
    "    global_pca_map = reduced_data.T.reshape(num_components, h, w)  # 还原形状\n",
    "    return global_pca_map\n",
    "\n",
    "\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    #pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    pos_sim = torch.bmm(features_a.unsqueeze(1), features_b.unsqueeze(2)).squeeze() / temperature\n",
    "\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "    \n",
    "def superpixel_local_reconstruction_exact(hsi_data, superpixel_labels, k=15):\n",
    "    \"\"\"\n",
    "    精确实现 S³-PCA 论文中基于超像素的局部重构（图1 & 公式 4, 5）。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: np.ndarray, 原始 HSI 图像，形状 [C, H, W]\n",
    "        superpixel_labels: np.ndarray, 超像素标签图 [H, W]\n",
    "        k: int, 每像素用于重构的邻居数\n",
    "\n",
    "    返回:\n",
    "        reconstructed_data: np.ndarray, 重构后的图像 [C, H, W]\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    reconstructed_data = np.copy(hsi_data)  # 初始化为原始数据（可选择覆盖）\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "        coords = np.argwhere(mask)\n",
    "\n",
    "        if coords.shape[0] < k + 1:\n",
    "            continue  # 样本数不足跳过\n",
    "\n",
    "        # 当前超像素的所有光谱数据，shape: [N, C]\n",
    "        spectra = np.array([hsi_data[:, x, y] for x, y in coords])\n",
    "\n",
    "        for i, (x, y) in enumerate(coords):\n",
    "            xi = spectra[i]  # 当前像素的光谱\n",
    "            dists = np.linalg.norm(spectra - xi, axis=1)\n",
    "\n",
    "            # 排除自身取前 k 个最近邻\n",
    "            nearest_indices = np.argsort(dists)[1:k+1]\n",
    "            zj = spectra[nearest_indices]\n",
    "\n",
    "            # 论文公式 h = (1/k) * sum(||xi - zj||^2)\n",
    "            h_val = np.mean(np.linalg.norm(zj - xi, axis=1) ** 2)\n",
    "\n",
    "            # 论文公式 (4): 计算重构权重\n",
    "            weights = np.exp(-np.linalg.norm(zj - xi, axis=1)**2 / (2 * h_val))\n",
    "            weights /= np.sum(weights)  # 归一化\n",
    "\n",
    "            # 论文公式 (5): 加权求和重构 xi*\n",
    "            x_recon = np.sum(weights[:, None] * zj, axis=0)\n",
    "\n",
    "            # 写入重构结果\n",
    "            reconstructed_data[:, x, y] = x_recon\n",
    "\n",
    "    return reconstructed_data\n",
    "\n",
    "\n",
    "\n",
    "def apply_lda_train_only(hsi_data, train_truth, num_components=30):\n",
    "    \"\"\"\n",
    "    用训练区域进行 LDA 有监督降维，并将变换应用于全图。\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col\n",
    "    X_train = hsi_data[:, rows, cols].T  # [num_samples, C]\n",
    "    y_train = train_truth.data           # shape: [num_samples]\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=num_components)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    full_X = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    full_lda = lda.transform(full_X)\n",
    "    lda_data = full_lda.T.reshape(num_components, h, w)\n",
    "\n",
    "    return lda_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pavia University shape: (103, 610, 340)\n",
      "Train samples: 90\n",
      "Candidate samples: 3921\n",
      "Test samples: 42776\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\otherdataset\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 548, 2: 540, 3: 392,\n",
    "    4: 524, 5: 265, 6: 532,\n",
    "    7: 375, 8: 514, 9: 231\n",
    "}\n",
    "\n",
    "pavia, train_truth, candidate_truth, test_truth, info = load_pavia_university_with_full_test(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=10\n",
    ")\n",
    "\n",
    "print(f\"Pavia University shape: {pavia.shape}\")\n",
    "print(f\"Train samples: {train_truth.count_nonzero()}\")         #  90\n",
    "print(f\"Candidate samples: {candidate_truth.count_nonzero()}\") #  3921\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           #  42776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(candidate_truth.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.1000\n",
      "Epoch [2/100], Loss: 0.1000\n",
      "Epoch [3/100], Loss: 0.1000\n",
      "Epoch [4/100], Loss: 0.1000\n",
      "Epoch [5/100], Loss: 0.1000\n",
      "Epoch [6/100], Loss: 0.1000\n",
      "Epoch [7/100], Loss: 0.1000\n",
      "Epoch [8/100], Loss: 0.1000\n",
      "Epoch [9/100], Loss: 0.1000\n",
      "Epoch [10/100], Loss: 0.1000\n",
      "Epoch [11/100], Loss: 0.1000\n",
      "Epoch [12/100], Loss: 0.1000\n",
      "Epoch [13/100], Loss: 0.1000\n",
      "Epoch [14/100], Loss: 0.1000\n",
      "Epoch [15/100], Loss: 0.1000\n",
      "Epoch [16/100], Loss: 0.1000\n",
      "Epoch [17/100], Loss: 0.1000\n",
      "Epoch [18/100], Loss: 0.1000\n",
      "Epoch [19/100], Loss: 0.1000\n",
      "Epoch [20/100], Loss: 0.1000\n",
      "Epoch [21/100], Loss: 0.1000\n",
      "Epoch [22/100], Loss: 0.1000\n",
      "Epoch [23/100], Loss: 0.1000\n",
      "Epoch [24/100], Loss: 0.1000\n",
      "Epoch [25/100], Loss: 0.1000\n",
      "Epoch [26/100], Loss: 0.1000\n",
      "Epoch [27/100], Loss: 0.1000\n",
      "Epoch [28/100], Loss: 0.1000\n",
      "Epoch [29/100], Loss: 0.1000\n",
      "Epoch [30/100], Loss: 0.1000\n",
      "Epoch [31/100], Loss: 0.1000\n",
      "Epoch [32/100], Loss: 0.1000\n",
      "Epoch [33/100], Loss: 0.1000\n",
      "Epoch [34/100], Loss: 0.1000\n",
      "Epoch [35/100], Loss: 0.1000\n",
      "Epoch [36/100], Loss: 0.1000\n",
      "Epoch [37/100], Loss: 0.1000\n",
      "Epoch [38/100], Loss: 0.1000\n",
      "Epoch [39/100], Loss: 0.1000\n",
      "Epoch [40/100], Loss: 0.1000\n",
      "Epoch [41/100], Loss: 0.1000\n",
      "Epoch [42/100], Loss: 0.1000\n",
      "Epoch [43/100], Loss: 0.1000\n",
      "Epoch [44/100], Loss: 0.1000\n",
      "Epoch [45/100], Loss: 0.1000\n",
      "Epoch [46/100], Loss: 0.1000\n",
      "Epoch [47/100], Loss: 0.1000\n",
      "Epoch [48/100], Loss: 0.1000\n",
      "Epoch [49/100], Loss: 0.1000\n",
      "Epoch [50/100], Loss: 0.1000\n",
      "Epoch [51/100], Loss: 0.1000\n",
      "Epoch [52/100], Loss: 0.1000\n",
      "Epoch [53/100], Loss: 0.1000\n",
      "Epoch [54/100], Loss: 0.1000\n",
      "Epoch [55/100], Loss: 0.1000\n",
      "Epoch [56/100], Loss: 0.1000\n",
      "Epoch [57/100], Loss: 0.1000\n",
      "Epoch [58/100], Loss: 0.1000\n",
      "Epoch [59/100], Loss: 0.1000\n",
      "Epoch [60/100], Loss: 0.1000\n",
      "Epoch [61/100], Loss: 0.1000\n",
      "Epoch [62/100], Loss: 0.1000\n",
      "Epoch [63/100], Loss: 0.1000\n",
      "Epoch [64/100], Loss: 0.1000\n",
      "Epoch [65/100], Loss: 0.1000\n",
      "Epoch [66/100], Loss: 0.1000\n",
      "Epoch [67/100], Loss: 0.1000\n",
      "Epoch [68/100], Loss: 0.1000\n",
      "Epoch [69/100], Loss: 0.1000\n",
      "Epoch [70/100], Loss: 0.1000\n",
      "Epoch [71/100], Loss: 0.1000\n",
      "Epoch [72/100], Loss: 0.1000\n",
      "Epoch [73/100], Loss: 0.1000\n",
      "Epoch [74/100], Loss: 0.1000\n",
      "Epoch [75/100], Loss: 0.1000\n",
      "Epoch [76/100], Loss: 0.1000\n",
      "Epoch [77/100], Loss: 0.1000\n",
      "Epoch [78/100], Loss: 0.1000\n",
      "Epoch [79/100], Loss: 0.1000\n",
      "Epoch [80/100], Loss: 0.1000\n",
      "Epoch [81/100], Loss: 0.1000\n",
      "Epoch [82/100], Loss: 0.1000\n",
      "Epoch [83/100], Loss: 0.1000\n",
      "Epoch [84/100], Loss: 0.1000\n",
      "Epoch [85/100], Loss: 0.1000\n",
      "Epoch [86/100], Loss: 0.1000\n",
      "Epoch [87/100], Loss: 0.1000\n",
      "Epoch [88/100], Loss: 0.1000\n",
      "Epoch [89/100], Loss: 0.1000\n",
      "Epoch [90/100], Loss: 0.1000\n",
      "Epoch [91/100], Loss: 0.1000\n",
      "Epoch [92/100], Loss: 0.1000\n",
      "Epoch [93/100], Loss: 0.1000\n",
      "Epoch [94/100], Loss: 0.1000\n",
      "Epoch [95/100], Loss: 0.1000\n",
      "Epoch [96/100], Loss: 0.1000\n",
      "Epoch [97/100], Loss: 0.1000\n",
      "Epoch [98/100], Loss: 0.1000\n",
      "Epoch [99/100], Loss: 0.1000\n",
      "Epoch [100/100], Loss: 0.1000\n",
      "Final model saved to final/lda_oldloss.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_28352\\1137597517.py:78: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  plt.savefig('final/lda_oldloss.png')\n",
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 假设 hsi_data 是原始高光谱数据: [144, H, W]\n",
    "pca_data, _ = apply_pca_train_only(pavia, candidate_truth, num_components=8)\n",
    "lda_data = apply_lda_train_only(pavia, candidate_truth, num_components=8)\n",
    "\n",
    "# 选点（如所有 train_truth、或 valid 区域）\n",
    "coords = list(zip(candidate_truth.row, candidate_truth.col))\n",
    "\n",
    "# 创建 Dataset 和 DataLoader\n",
    "dataset = PCA_LDA_PatchDataset(pca_data, lda_data, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# 初始化网络\n",
    "feature_extractor = FeatureExtractor(input_channels=8).cuda()  \n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "# 创建保存模型的文件夹\n",
    "os.makedirs('./pth', exist_ok=True)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 100\n",
    "temperature = 0.2\n",
    "loss_values = []\n",
    "neg = 5\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for cube_pca, cube_lda in dataloader:\n",
    "        cube_pca, cube_lda = cube_pca.cuda(), cube_lda.cuda()\n",
    "        \n",
    "        feat_pca = feature_extractor(cube_pca)\n",
    "        feat_lda = feature_extractor(cube_lda)\n",
    "        \n",
    "        proj_pca = projection_head(feat_pca)\n",
    "        proj_lda = projection_head(feat_lda)\n",
    "\n",
    "        \n",
    "        loss = contrastive_loss(proj_pca, proj_lda, temperature)\n",
    "        #loss = contrastive_loss(proj_a, proj_b, margin=1.0, num_negatives=2)  # 或 margin=0.5\n",
    "        #loss = contrastive_loss_ce_hard_negatives(proj_pca, proj_pca, temperature=1, num_negatives=neg)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 仅保存最后一个模型\n",
    "model_path = 'final/lda_oldloss.pth'\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': num_epochs,\n",
    "        'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "        'projection_head_state_dict': projection_head.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss_values[-1],\n",
    "    },\n",
    "    model_path\n",
    ")\n",
    "print(f\"Final model saved to {model_path}\")\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/lda_oldloss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, torch.tensor(label - 1, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "num_classes = len(set(train_truth.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (8, 610, 340)\n",
      "Number of training samples: 90\n",
      "Number of testing samples: 42776\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(train_truth.data))\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(train_truth.row, train_truth.col, train_truth.data)\n",
    "]\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "#pca_data, explained_variance_ratio = apply_pca_train_only(pavia, train_truth, num_components=5)\n",
    "# 先做 PCA 和 LDA 降维\n",
    "pca_data, _ = apply_pca_train_only(pavia, candidate_truth, num_components=4)\n",
    "lda_data = apply_lda_train_only(pavia, candidate_truth, num_components=4)\n",
    "\n",
    "# 拼接 [C_pca + C_lda, H, W]\n",
    "combined_data = np.concatenate([pca_data, lda_data], axis=0)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(combined_data , train_labels, patch_size=11)\n",
    "\n",
    "test_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(test_truth.row, test_truth.col, test_truth.data)\n",
    "]\n",
    "test_dataset = ClassificationDataset(combined_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印样本信息\n",
    "print(f\"PCA 降维后的数据形状: {combined_data.shape}\")\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "#checkpoint_path = \"./pth/model_epoch_160.pth\"  # 修改为对比学习模型的路径\n",
    "checkpoint_path = \"final/lda_oldloss.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 25）\n",
    "feature_extractor = FeatureExtractor(input_channels=8).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=15).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()\n",
    "    classification_head.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        loss_values.append(avg_loss)  # 记录损失值\n",
    "\n",
    "        #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7375\n",
      "Average Accuracy: 0.8125\n",
      "Kappa Coefficient: 0.6724\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 5255 predictions\n",
      "Class 1: 13010 predictions\n",
      "Class 2: 3092 predictions\n",
      "Class 3: 2996 predictions\n",
      "Class 4: 1432 predictions\n",
      "Class 5: 10014 predictions\n",
      "Class 6: 2132 predictions\n",
      "Class 7: 3840 predictions\n",
      "Class 8: 1005 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.7086\n",
      "Class 1: 0.6696\n",
      "Class 2: 0.6989\n",
      "Class 3: 0.9595\n",
      "Class 4: 0.9926\n",
      "Class 5: 0.8314\n",
      "Class 6: 0.8271\n",
      "Class 7: 0.6578\n",
      "Class 8: 0.9673\n",
      "0.7086\n",
      "0.6696\n",
      "0.6989\n",
      "0.9595\n",
      "0.9926\n",
      "0.8314\n",
      "0.8271\n",
      "0.6578\n",
      "0.9673\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"{acc:.4f}\")\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
