{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.exposure\n",
    "import rasterio\n",
    "from io import StringIO\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation\n",
    "import random\n",
    "from scipy.sparse import coo_array\n",
    "from scipy.io import loadmat\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 如果你显示中文，改为你系统支持的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whu_longkou(data_path: Path, candidate_counts: dict, num_train_per_class=10, seed=42):\n",
    "    \"\"\"\n",
    "    加载 WHU-Hi-LongKou 数据集：\n",
    "    - 从每类中抽取固定数量作为候选样本\n",
    "    - 从候选中抽取 num_train_per_class 个作为训练样本\n",
    "    - 所有 ground truth 标签 > 0 的像素作为测试集\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 读取 hyperspectral 数据\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou.tif\") as src:\n",
    "        hyperspectral = src.read()  # shape: (bands, height, width)\n",
    "    c, h, w = hyperspectral.shape\n",
    "\n",
    "    # 读取 ground truth 标签\n",
    "    with rasterio.open(data_path / \"WHU-Hi-LongKou_gt.tif\") as src:\n",
    "        gt = src.read(1)  # shape: (height, width)\n",
    "\n",
    "    label_dict = {\n",
    "        1: '玉米', 2: '棉花', 3: '芝麻',\n",
    "        4: '圆叶大豆', 5: '长叶大豆', 6: '水稻',\n",
    "        7: '水体', 8: '房屋和道路', 9: '混合杂草',\n",
    "    }\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    candidate_rows, candidate_cols, candidate_data = [], [], []\n",
    "\n",
    "    for label, cand_count in candidate_counts.items():\n",
    "        coords = np.argwhere(gt == label)\n",
    "        if len(coords) < cand_count:\n",
    "            raise ValueError(f\"类 {label} 样本不足，只有 {len(coords)}，无法抽取 {cand_count} 个候选样本\")\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        candidate_coords = coords[:cand_count]\n",
    "        train_coords = candidate_coords[:num_train_per_class]\n",
    "\n",
    "        # 训练样本\n",
    "        for r, c in train_coords:\n",
    "            train_rows.append(r)\n",
    "            train_cols.append(c)\n",
    "            train_data.append(label)\n",
    "\n",
    "        # 候选样本（包含训练）\n",
    "        for r, c in candidate_coords:\n",
    "            candidate_rows.append(r)\n",
    "            candidate_cols.append(c)\n",
    "            candidate_data.append(label)\n",
    "\n",
    "    # 构建稀疏矩阵\n",
    "    train_truth = coo_matrix((train_data, (train_rows, train_cols)), shape=(h, w), dtype=int)\n",
    "    candidate_truth = coo_matrix((candidate_data, (candidate_rows, candidate_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    # 所有标签 > 0 的都作为测试样本\n",
    "    test_rows, test_cols = np.where(gt > 0)\n",
    "    test_data = gt[test_rows, test_cols]\n",
    "    test_truth = coo_matrix((test_data, (test_rows, test_cols)), shape=(h, w), dtype=int)\n",
    "\n",
    "    info = {\n",
    "        'n_band': c,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'label_dict': label_dict\n",
    "    }\n",
    "\n",
    "    return hyperspectral, train_truth, candidate_truth, test_truth, info\n",
    "\n",
    "\n",
    "def merge_train_test(train_truth, test_truth, shape):\n",
    "    \"\"\"\n",
    "    合并训练集和测试集稀疏矩阵为一个新的训练集矩阵。\n",
    "    \n",
    "    参数:\n",
    "        train_truth: coo_matrix, 原始训练集稀疏矩阵\n",
    "        test_truth: coo_matrix, 原始测试集稀疏矩阵\n",
    "        shape: tuple, 数据的形状 (height, width)\n",
    "        \n",
    "    返回:\n",
    "        merged_truth: coo_matrix, 合并后的训练集稀疏矩阵\n",
    "    \"\"\"\n",
    "    # 合并行、列和数据\n",
    "    merged_rows = np.concatenate([train_truth.row, test_truth.row])\n",
    "    merged_cols = np.concatenate([train_truth.col, test_truth.col])\n",
    "    merged_data = np.concatenate([train_truth.data, test_truth.data])\n",
    "    \n",
    "    # 创建新的稀疏矩阵\n",
    "    merged_truth = coo_matrix((merged_data, (merged_rows, merged_cols)), shape=shape)\n",
    "    return merged_truth\n",
    "\n",
    "def apply_pca_train_only(hsi_data, train_truth, num_components=40):\n",
    "    \"\"\"\n",
    "    使用训练区域的光谱数据训练 PCA 模型，并应用到整个数据集。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 高光谱图像数据, 形状为 [C, H, W]\n",
    "        train_truth: coo_array, 训练区域的稀疏矩阵，表示训练样本的位置\n",
    "        num_components: int, 保留的主成分数量\n",
    "        \n",
    "    返回:\n",
    "        pca_data: numpy.ndarray, PCA 降维后的数据，形状为 [num_components, H, W]\n",
    "        explained_variance_ratio: PCA 的累计解释方差比\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape  # 高光谱数据的形状\n",
    "    rows, cols = train_truth.row, train_truth.col  # 提取训练区域的行列索引\n",
    "    \n",
    "    # 提取训练区域的光谱数据 [num_samples, num_channels]\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # 转置为 [num_samples, num_channels]\n",
    "    \n",
    "    # 在训练区域数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 仅在训练区域数据上训练 PCA\n",
    "    \n",
    "    # 转换整个数据集 [C, H, W] -> [H×W, C]\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    reduced_data = pca.transform(reshaped_data)  # 降维 [H×W, num_components]\n",
    "    \n",
    "    # 恢复为原始图像的形状 [num_components, H, W]\n",
    "    pca_data = reduced_data.T.reshape(num_components, h, w)  # [num_components, H, W]\n",
    "    \n",
    "    return pca_data, pca.explained_variance_ratio_\n",
    "\n",
    "def superpixel_segmentation(hsi_data, num_superpixels=100):\n",
    "    \"\"\"\n",
    "    使用 SLIC 超像素分割对 HSI 进行分割。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        num_superpixels: 生成的超像素数量\n",
    "        \n",
    "    返回:\n",
    "        labels: 超像素标签矩阵，形状为 (H, W)\n",
    "    \"\"\"\n",
    "    # 先用 PCA 提取第一主成分\n",
    "    first_pc = PCA(n_components=1).fit_transform(hsi_data.reshape(hsi_data.shape[0], -1).T)\n",
    "    first_pc = first_pc.reshape(hsi_data.shape[1:])  # 变成 (H, W)\n",
    "\n",
    "    # 修正错误：复制 3 通道，使其符合 SLIC 需 \n",
    "    first_pc_rgb = np.stack([first_pc] * 3, axis=-1)  # 变成 (H, W, 3)\n",
    "\n",
    "    # 正确调用 skimage.segmentation.sli \n",
    "    labels = skimage.segmentation.slic(first_pc_rgb, n_segments=num_superpixels, compactness=10, start_label=0, channel_axis=-1)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_superpixel_pca(hsi_data, superpixel_labels, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算每个超像素的局部 PCA，并返回降维后的特征。\n",
    "\n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (C, H, W)\n",
    "        superpixel_labels: numpy.ndarray, 形状为 (H, W)\n",
    "        merged_train_truth: coo_matrix, 训练区域掩码\n",
    "        num_components: int, PCA 维度\n",
    "        \n",
    "    返回:\n",
    "        superpixel_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "        superpixel_pca_dict: dict, 每个超像素的局部PCA结果\n",
    "    \"\"\"\n",
    "    h, w = superpixel_labels.shape\n",
    "    c = hsi_data.shape[0]\n",
    "    superpixel_pca_map = np.zeros((num_components, h, w))\n",
    "    superpixel_pca_dict = {}\n",
    "\n",
    "    # 获取训练区域坐标\n",
    "    mask_train = merged_train_truth.toarray() > 0\n",
    "\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "\n",
    "        # 当前超像素区域内的训练区域\n",
    "        train_mask = np.logical_and(mask, mask_train)\n",
    "        if np.sum(train_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        pixels = hsi_data[:, train_mask].T  # shape: (num_samples, num_channels)\n",
    "\n",
    "        # 如果样本数不足，跳过\n",
    "        if pixels.shape[0] <= num_components:\n",
    "            continue\n",
    "\n",
    "        # 执行局部 PCA\n",
    "        pca = PCA(n_components=num_components)\n",
    "        reduced_pixels = pca.fit_transform(pixels)\n",
    "        superpixel_pca_dict[label] = reduced_pixels.T  # shape: (num_components, N)\n",
    "\n",
    "        # 计算均值写入整块区域\n",
    "        for i in range(num_components):\n",
    "            superpixel_pca_map[i, mask] = np.mean(reduced_pixels[:, i])\n",
    "\n",
    "    return superpixel_pca_map, superpixel_pca_dict\n",
    "\n",
    "\n",
    "\n",
    "def split_cube(hsi_cube):\n",
    "    \"\"\"\n",
    "    将高光谱立方块沿通道维度均匀切分。\n",
    "    参数:\n",
    "        hsi_cube: torch.Tensor, 形状为 [H, W, C]\n",
    "    返回:\n",
    "        hsi_cube_a, hsi_cube_b: 两个子立方块\n",
    "    \"\"\"\n",
    "    _, _, c = hsi_cube.shape\n",
    "    c1 = c // 2  # 每个子块保留一半的通道\n",
    "    return hsi_cube[:, :, :c1], hsi_cube[:, :, c1:]\n",
    "\n",
    "def extract_cube(data, x, y, size):\n",
    "    \"\"\"\n",
    "    从高光谱数据中提取局部立方块，并在边界不足时进行填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy.ndarray, 形状为 [C, H, W]\n",
    "        x, y: int, 立方块的中心像素坐标\n",
    "        size: tuple, 立方块的大小 (s, s)，要求 s 必须是奇数\n",
    "    \n",
    "    返回:\n",
    "        cube: numpy.ndarray, 形状为 [C, s, s]\n",
    "    \"\"\"\n",
    "    assert size[0] % 2 == 1, \"立方块大小必须是奇数，以确保中心点对齐。\"\n",
    "    \n",
    "    c, h, w = data.shape\n",
    "    half_size = size[0] // 2  # 计算半径\n",
    "\n",
    "    # 计算提取区域的坐标范围\n",
    "    x_min, x_max = max(0, x - half_size), min(h, x + half_size + 1)\n",
    "    y_min, y_max = max(0, y - half_size), min(w, y + half_size + 1)\n",
    "\n",
    "    # 提取局部数据\n",
    "    cube = data[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # 计算需要填充的大小\n",
    "    pad_x_min, pad_x_max = max(0, half_size - x), max(0, x + half_size + 1 - h)\n",
    "    pad_y_min, pad_y_max = max(0, half_size - y), max(0, y + half_size + 1 - w)\n",
    "\n",
    "    # 使用边缘填充，确保输出形状为 (C, size, size)\n",
    "    pad_width = [\n",
    "        (0, 0),  # 不填充通道维度\n",
    "        (pad_x_min, pad_x_max),  # 高度填充\n",
    "        (pad_y_min, pad_y_max),  # 宽度填充\n",
    "    ]\n",
    "    cube = np.pad(cube, pad_width, mode=\"edge\")  # 填充值是边界像素，而不是反射\n",
    "    #cube = np.pad(cube, pad_width, mode=\"reflect\")\n",
    "    return cube\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=40):\n",
    "        \"\"\"\n",
    "        特征提取网络。\n",
    "        参数:\n",
    "            input_channels: 输入的通道数，例如 20。\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)  # 第一层卷积\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 第二层卷积\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 第三层卷积\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 最大池化层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # 卷积 + 批归一化 + 激活 + 池化\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # 展平特征\n",
    "    \n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=8):\n",
    "        \"\"\"\n",
    "        特征投影模块。\n",
    "        参数:\n",
    "            input_dim: 输入特征的维度，例如 128。\n",
    "            output_dim: 投影后的维度，例如 8。\n",
    "        \"\"\"\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=1)  # 投影后的特征归一化\n",
    "\n",
    "\n",
    "def contrastive_loss_wrong(features_a, features_b, temperature=1.0):\n",
    "    \"\"\"\n",
    "    计算对比损失。\n",
    "    参数:\n",
    "        features_a, features_b: 投影后的特征，形状为 [batch_size, projection_dim]\n",
    "        temperature: 温度系数\n",
    "    返回:\n",
    "        loss: 对比损失值\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "    features = torch.cat([features_a, features_b], dim=0)  # 拼接特征\n",
    "    sim_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)  # 计算相似度\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # 构造标签\n",
    "    labels = torch.arange(batch_size, device=features_a.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    loss = F.cross_entropy(sim_matrix, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def contrastive_loss(features_a, features_b, margin=1.0, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Triplet-based contrastive loss with multiple hard negatives.\n",
    "    - anchor: features_a[i]\n",
    "    - positive: features_b[i]\n",
    "    - negatives: top-k most dissimilar samples from [features_a; features_b]\n",
    "    \"\"\"\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine all features as potential negatives\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # shape: [2N, D]\n",
    "\n",
    "    # Compute cosine similarity: [N, 2N]\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T)\n",
    "\n",
    "    # Mask out own positive at index i + batch_size\n",
    "    mask = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), mask + batch_size] = -1.0\n",
    "\n",
    "    # Get indices of top-k *least* similar samples (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Repeat anchors and positives for each negative\n",
    "    anchors = features_a.unsqueeze(1).repeat(1, num_negatives, 1).reshape(-1, features_a.shape[1])       # [N*k, D]\n",
    "    positives = features_b.unsqueeze(1).repeat(1, num_negatives, 1).reshape(-1, features_b.shape[1])     # [N*k, D]\n",
    "    negatives = all_features[neg_indices.reshape(-1)]  # [N*k, D]\n",
    "\n",
    "    # Compute triplet loss\n",
    "    triplet_loss_fn = nn.TripletMarginLoss(margin=margin, p=2, reduction='mean')\n",
    "    loss = triplet_loss_fn(anchors, positives, negatives)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def extract_precise_superpixel_pca(superpixel_pca_dict, superpixel_labels, x, y):\n",
    "    \"\"\"\n",
    "    获取像素 (x, y) 所属超像素的 SuperPCA 特征。\n",
    "    \n",
    "    参数:\n",
    "        superpixel_pca_dict: 字典，存储每个超像素的 PCA 结果\n",
    "        superpixel_labels: 超像素标签矩阵\n",
    "        x, y: 目标像素坐标\n",
    "        \n",
    "    返回:\n",
    "        superpixel_features: numpy.ndarray, 形状为 (20,)\n",
    "    \"\"\"\n",
    "    superpixel_label = superpixel_labels[x, y]  # 获取该像素的超像素标签\n",
    "    \n",
    "    # 获取该超像素块的所有 PCA 结果\n",
    "    superpixel_features = superpixel_pca_dict[superpixel_label]  # 形状为 (20, N)，N 是该超像素块内像素数\n",
    "\n",
    "    # 取所有像素的平均值，确保返回 20 维的特征向量\n",
    "    superpixel_features = np.mean(superpixel_features, axis=1)  # 形状变为 (20,)\n",
    "\n",
    "    return superpixel_features\n",
    "\n",
    "\n",
    "\n",
    "class S3PCADataset(Dataset):\n",
    "    def __init__(self, pca_data, superpixel_pca_map, superpixel_pca_dict, superpixel_labels, global_pca, patch_size=11, num_samples=1000):\n",
    "        self.pca_data = pca_data\n",
    "        self.superpixel_pca_map = superpixel_pca_map\n",
    "        self.superpixel_pca_dict = superpixel_pca_dict\n",
    "        self.superpixel_labels = superpixel_labels\n",
    "        self.global_pca = global_pca\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.h, self.w = pca_data.shape[1], pca_data.shape[2]\n",
    "\n",
    "        #  构造 valid_coords 列表\n",
    "        self.valid_coords = []\n",
    "        for x in range(patch_size // 2, self.h - patch_size // 2):\n",
    "            for y in range(patch_size // 2, self.w - patch_size // 2):\n",
    "                label = superpixel_labels[x, y]\n",
    "                if label in superpixel_pca_dict:\n",
    "                    self.valid_coords.append((x, y))\n",
    "\n",
    "        if len(self.valid_coords) == 0:\n",
    "            raise ValueError(\"没有找到任何有效的 superpixel 区域坐标！\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.num_samples, len(self.valid_coords))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #  从 valid_coords 中采样\n",
    "        x, y = self.valid_coords[idx % len(self.valid_coords)]  # 防止超出索引\n",
    "\n",
    "        # 提取 PCA patch\n",
    "        pca_patch = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "        pca_patch = torch.tensor(pca_patch, dtype=torch.float32)\n",
    "\n",
    "        # 拆分成两半\n",
    "        pca_channels = pca_patch.shape[0]\n",
    "        half_channels = pca_channels // 2\n",
    "        pca_patch_a, pca_patch_b = torch.split(pca_patch, [half_channels, pca_channels - half_channels], dim=0)\n",
    "\n",
    "        # 提取 Superpixel PCA\n",
    "        superpixel_patch = extract_precise_superpixel_pca(self.superpixel_pca_dict, self.superpixel_labels, x, y)\n",
    "        superpixel_patch = torch.tensor(superpixel_patch[:, None, None], dtype=torch.float32)\n",
    "        superpixel_patch = superpixel_patch.expand(-1, self.patch_size, self.patch_size)\n",
    "\n",
    "        # 提取 Global PCA\n",
    "        global_patch = extract_cube(self.global_pca, x, y, (self.patch_size, self.patch_size))\n",
    "        global_patch = torch.tensor(global_patch, dtype=torch.float32)\n",
    "\n",
    "        # 拼接形成 cube_a 和 cube_b\n",
    "        cube_a = torch.cat([pca_patch_a, superpixel_patch], dim=0)\n",
    "        cube_b = torch.cat([pca_patch_b, global_patch], dim=0)\n",
    "\n",
    "        return cube_a, cube_b\n",
    "\n",
    "class PCA_LDA_PatchDataset(Dataset):\n",
    "    def __init__(self, pca_data, lda_data, coords, patch_size=11):\n",
    "        self.pca_data = pca_data\n",
    "        self.lda_data = lda_data\n",
    "        self.coords = coords\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.coords[idx]\n",
    "\n",
    "        cube_pca = extract_cube(self.pca_data, x, y, (self.patch_size, self.patch_size))\n",
    "        cube_lda = extract_cube(self.lda_data, x, y, (self.patch_size, self.patch_size))\n",
    "\n",
    "        return torch.tensor(cube_pca).float(), torch.tensor(cube_lda).float()\n",
    "\n",
    "\n",
    "\n",
    "def compute_global_pca(hsi_data, merged_train_truth, num_components=20):\n",
    "    \"\"\"\n",
    "    仅在训练区域计算全局 PCA，并应用到整个 HSI。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: numpy.ndarray, 形状为 (B, H, W)\n",
    "        merged_train_truth: coo_matrix, 标注的训练区域\n",
    "        num_components: int, PCA 降维维度\n",
    "        \n",
    "    返回:\n",
    "        global_pca_map: numpy.ndarray, 形状为 (num_components, H, W)\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = merged_train_truth.row, merged_train_truth.col  # 获取训练样本的位置\n",
    "\n",
    "    # 取出训练区域的数据\n",
    "    train_spectra = hsi_data[:, rows, cols].T  # (num_samples, num_channels)\n",
    "\n",
    "    # 在训练数据上拟合 PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_spectra)  # 只在训练数据上拟合\n",
    "\n",
    "    # 对整个 HSI 应用 PCA 变换\n",
    "    reshaped_data = hsi_data.reshape(c, -1).T  # (H*W, C)\n",
    "    reduced_data = pca.transform(reshaped_data)  # (H*W, num_components)\n",
    "\n",
    "    global_pca_map = reduced_data.T.reshape(num_components, h, w)  # 还原形状\n",
    "    return global_pca_map\n",
    "\n",
    "\n",
    "def contrastive_loss_ce_hard_negatives(features_a, features_b, temperature=0.1, num_negatives=2):\n",
    "    \"\"\"\n",
    "    Cross-Entropy Contrastive Loss using hardest negative sampling.\n",
    "    - Each anchor (features_a[i]) uses its positive (features_b[i])\n",
    "    - Negatives are selected as least similar samples in [features_a; features_b]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = features_a.size(0)\n",
    "\n",
    "    # Normalize\n",
    "    features_a = F.normalize(features_a, dim=1)\n",
    "    features_b = F.normalize(features_b, dim=1)\n",
    "\n",
    "    # Combine: total 2N candidates\n",
    "    all_features = torch.cat([features_a, features_b], dim=0)  # [2N, D]\n",
    "\n",
    "    # Cosine sim between anchors and all\n",
    "    sim_matrix = torch.matmul(features_a, all_features.T) / temperature  # [N, 2N]\n",
    "\n",
    "    # Mask out own positive (at i + batch_size)\n",
    "    pos_indices = torch.arange(batch_size, device=features_a.device)\n",
    "    sim_matrix[torch.arange(batch_size), pos_indices + batch_size] = float('-inf')\n",
    "\n",
    "    # Select top-k lowest similarity (hard negatives)\n",
    "    _, neg_indices = torch.topk(sim_matrix, k=num_negatives, dim=1, largest=False)  # [N, k]\n",
    "\n",
    "    # Construct new logits: [N, 1 + k] → positive + k negatives\n",
    "    pos_sim = torch.sum(features_a * features_b, dim=1, keepdim=True) / temperature  # [N, 1]\n",
    "    neg_sims = torch.gather(sim_matrix, 1, neg_indices)  # [N, k]\n",
    "    logits = torch.cat([pos_sim, neg_sims], dim=1)  # [N, 1+k]\n",
    "\n",
    "    # Labels: positive is index 0\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=features_a.device)\n",
    "\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "    \n",
    "def superpixel_local_reconstruction_exact(hsi_data, superpixel_labels, k=15):\n",
    "    \"\"\"\n",
    "    精确实现 S³-PCA 论文中基于超像素的局部重构（图1 & 公式 4, 5）。\n",
    "    \n",
    "    参数:\n",
    "        hsi_data: np.ndarray, 原始 HSI 图像，形状 [C, H, W]\n",
    "        superpixel_labels: np.ndarray, 超像素标签图 [H, W]\n",
    "        k: int, 每像素用于重构的邻居数\n",
    "\n",
    "    返回:\n",
    "        reconstructed_data: np.ndarray, 重构后的图像 [C, H, W]\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    reconstructed_data = np.copy(hsi_data)  # 初始化为原始数据（可选择覆盖）\n",
    "    unique_labels = np.unique(superpixel_labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = (superpixel_labels == label)\n",
    "        coords = np.argwhere(mask)\n",
    "\n",
    "        if coords.shape[0] < k + 1:\n",
    "            continue  # 样本数不足跳过\n",
    "\n",
    "        # 当前超像素的所有光谱数据，shape: [N, C]\n",
    "        spectra = np.array([hsi_data[:, x, y] for x, y in coords])\n",
    "\n",
    "        for i, (x, y) in enumerate(coords):\n",
    "            xi = spectra[i]  # 当前像素的光谱\n",
    "            dists = np.linalg.norm(spectra - xi, axis=1)\n",
    "\n",
    "            # 排除自身取前 k 个最近邻\n",
    "            nearest_indices = np.argsort(dists)[1:k+1]\n",
    "            zj = spectra[nearest_indices]\n",
    "\n",
    "            # 论文公式 h = (1/k) * sum(||xi - zj||^2)\n",
    "            h_val = np.mean(np.linalg.norm(zj - xi, axis=1) ** 2)\n",
    "\n",
    "            # 论文公式 (4): 计算重构权重\n",
    "            weights = np.exp(-np.linalg.norm(zj - xi, axis=1)**2 / (2 * h_val))\n",
    "            weights /= np.sum(weights)  # 归一化\n",
    "\n",
    "            # 论文公式 (5): 加权求和重构 xi*\n",
    "            x_recon = np.sum(weights[:, None] * zj, axis=0)\n",
    "\n",
    "            # 写入重构结果\n",
    "            reconstructed_data[:, x, y] = x_recon\n",
    "\n",
    "    return reconstructed_data\n",
    "\n",
    "\n",
    "\n",
    "def apply_lda_train_only(hsi_data, train_truth, num_components=30):\n",
    "    \"\"\"\n",
    "    用训练区域进行 LDA 有监督降维，并将变换应用于全图。\n",
    "    \"\"\"\n",
    "    c, h, w = hsi_data.shape\n",
    "    rows, cols = train_truth.row, train_truth.col\n",
    "    X_train = hsi_data[:, rows, cols].T  # [num_samples, C]\n",
    "    y_train = train_truth.data           # shape: [num_samples]\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=num_components)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    full_X = hsi_data.reshape(c, -1).T  # [H×W, C]\n",
    "    full_lda = lda.transform(full_X)\n",
    "    lda_data = full_lda.T.reshape(num_components, h, w)\n",
    "\n",
    "    return lda_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\rasterio\\__init__.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pavia University shape: (270, 550, 400)\n",
      "Train samples: 135\n",
      "Candidate samples: 2700\n",
      "Test samples: 204542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = Path(r\"E:\\code\\-\\对比学习\\fx\\WHU\\Tiff_format\\WHU-Hi-LongKou\")\n",
    "\n",
    "candidate_counts = {\n",
    "    1: 300, 2: 300, 3: 300,\n",
    "    4: 300, 5: 300, 6: 300,\n",
    "    7: 300, 8: 300, 9: 300\n",
    "}\n",
    "\n",
    "whu, train_truth, candidate_truth, test_truth, info = load_whu_longkou(\n",
    "    data_path,\n",
    "    candidate_counts=candidate_counts,\n",
    "    num_train_per_class=15\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Pavia University shape: {whu.shape}\")\n",
    "print(f\"Train samples: {train_truth.count_nonzero()}\")         #  90\n",
    "print(f\"Candidate samples: {candidate_truth.count_nonzero()}\") #  3921\n",
    "print(f\"Test samples: {test_truth.count_nonzero()}\")           #  42776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(candidate_truth.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5894\n",
      "Epoch [2/50], Loss: 0.4617\n",
      "Epoch [3/50], Loss: 0.4479\n",
      "Epoch [4/50], Loss: 0.4437\n",
      "Epoch [5/50], Loss: 0.4412\n",
      "Epoch [6/50], Loss: 0.4396\n",
      "Epoch [7/50], Loss: 0.4386\n",
      "Epoch [8/50], Loss: 0.4379\n",
      "Epoch [9/50], Loss: 0.4374\n",
      "Epoch [10/50], Loss: 0.4370\n",
      "Epoch [11/50], Loss: 0.4366\n",
      "Epoch [12/50], Loss: 0.4363\n",
      "Epoch [13/50], Loss: 0.4360\n",
      "Epoch [14/50], Loss: 0.4359\n",
      "Epoch [15/50], Loss: 0.4357\n",
      "Epoch [16/50], Loss: 0.4356\n",
      "Epoch [17/50], Loss: 0.4354\n",
      "Epoch [18/50], Loss: 0.4352\n",
      "Epoch [19/50], Loss: 0.4352\n",
      "Epoch [20/50], Loss: 0.4350\n",
      "Epoch [21/50], Loss: 0.4350\n",
      "Epoch [22/50], Loss: 0.4348\n",
      "Epoch [23/50], Loss: 0.4349\n",
      "Epoch [24/50], Loss: 0.4348\n",
      "Epoch [25/50], Loss: 0.4347\n",
      "Epoch [26/50], Loss: 0.4346\n",
      "Epoch [27/50], Loss: 0.4345\n",
      "Epoch [28/50], Loss: 0.4345\n",
      "Epoch [29/50], Loss: 0.4344\n",
      "Epoch [30/50], Loss: 0.4345\n",
      "Epoch [31/50], Loss: 0.4343\n",
      "Epoch [32/50], Loss: 0.4343\n",
      "Epoch [33/50], Loss: 0.4343\n",
      "Epoch [34/50], Loss: 0.4342\n",
      "Epoch [35/50], Loss: 0.4342\n",
      "Epoch [36/50], Loss: 0.4341\n",
      "Epoch [37/50], Loss: 0.4340\n",
      "Epoch [38/50], Loss: 0.4341\n",
      "Epoch [39/50], Loss: 0.4341\n",
      "Epoch [40/50], Loss: 0.4340\n",
      "Epoch [41/50], Loss: 0.4340\n",
      "Epoch [42/50], Loss: 0.4339\n",
      "Epoch [43/50], Loss: 0.4339\n",
      "Epoch [44/50], Loss: 0.4339\n",
      "Epoch [45/50], Loss: 0.4339\n",
      "Epoch [46/50], Loss: 0.4340\n",
      "Epoch [47/50], Loss: 0.4338\n",
      "Epoch [48/50], Loss: 0.4338\n",
      "Epoch [49/50], Loss: 0.4338\n",
      "Epoch [50/50], Loss: 0.4338\n",
      "Final model saved to final/whu_lda_8d.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 假设 hsi_data 是原始高光谱数据: [144, H, W]\n",
    "pca_data, _ = apply_pca_train_only(whu, candidate_truth, num_components=8)\n",
    "lda_data = apply_lda_train_only(whu, candidate_truth, num_components=8)\n",
    "\n",
    "# 选点（如所有 train_truth、或 valid 区域）\n",
    "coords = list(zip(candidate_truth.row, candidate_truth.col))\n",
    "\n",
    "# 创建 Dataset 和 DataLoader\n",
    "dataset = PCA_LDA_PatchDataset(pca_data, lda_data, coords)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# 初始化网络\n",
    "feature_extractor = FeatureExtractor(input_channels=8).cuda()  \n",
    "projection_head = ProjectionHead(input_dim=128, output_dim=8).cuda()\n",
    "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(projection_head.parameters()), lr=1e-4)\n",
    "\n",
    "# 创建保存模型的文件夹\n",
    "os.makedirs('./final', exist_ok=True)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 50\n",
    "temperature = 1\n",
    "loss_values = []\n",
    "neg = 5\n",
    "for epoch in range(num_epochs):\n",
    "    feature_extractor.train()\n",
    "    projection_head.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for cube_pca, cube_lda in dataloader:\n",
    "        cube_pca, cube_lda = cube_pca.cuda(), cube_lda.cuda()\n",
    "        \n",
    "        feat_pca = feature_extractor(cube_pca)\n",
    "        feat_lda = feature_extractor(cube_lda)\n",
    "        \n",
    "        proj_pca = projection_head(feat_pca)\n",
    "        proj_lda = projection_head(feat_lda)\n",
    "\n",
    "        \n",
    "        #loss = contrastive_loss(proj_a, proj_b, temperature)\n",
    "        #loss = contrastive_loss(proj_a, proj_b, margin=1.0, num_negatives=2)  # 或 margin=0.5\n",
    "        loss = contrastive_loss_ce_hard_negatives(proj_pca, proj_pca, temperature=1, num_negatives=neg)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 仅保存最后一个模型\n",
    "model_path = 'final/whu_lda_8d.pth'\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': num_epochs,\n",
    "        'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "        'projection_head_state_dict': projection_head.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss_values[-1],\n",
    "    },\n",
    "    model_path\n",
    ")\n",
    "print(f\"Final model saved to {model_path}\")\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('final/whu_lda_8d.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def extract_labels(truth, label_dict):\n",
    "    \"\"\"\n",
    "    从稀疏矩阵中提取标注数据，格式为 [(row, col, label), ...]。\n",
    "    并将标签值映射到 [0, len(label_dict)-1] 的范围。\n",
    "    \"\"\"\n",
    "    rows, cols, labels = truth.row, truth.col, truth.data\n",
    "    # 创建从标签值到索引的映射\n",
    "    label_to_index = {label_value: idx for idx, label_value in enumerate(label_dict.keys())}\n",
    "    mapped_labels = [label_to_index[label] for label in labels if label in label_to_index]\n",
    "    return [(row, col, label) for row, col, label in zip(rows, cols, mapped_labels)]\n",
    "\n",
    "\n",
    "# 分类数据集定义\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels, patch_size=11):\n",
    "        \"\"\"\n",
    "        构造分类数据集。\n",
    "        参数:\n",
    "            data: PCA 降维后的数据 [C, H, W]\n",
    "            labels: [(row, col, label), ...]，标注的样本\n",
    "            patch_size: 立方块大小 (patch_size, patch_size)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, label = self.labels[idx]\n",
    "        cube = extract_cube(self.data, x, y, (self.patch_size, self.patch_size))  # 提取立方块\n",
    "        cube_tensor = torch.tensor(cube).float()  # 转换为浮点张量\n",
    "        return cube_tensor, torch.tensor(label - 1, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# 定义特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "num_classes = len(set(train_truth.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 降维后的数据形状: (8, 550, 400)\n",
      "Number of training samples: 135\n",
      "Number of testing samples: 204542\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(train_truth.data))\n",
    "# 从稀疏矩阵 train_truth 中提取训练样本标签 [(row, col, label), ...]\n",
    "train_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(train_truth.row, train_truth.col, train_truth.data)\n",
    "]\n",
    "\n",
    "# 应用 PCA（在训练区域上）\n",
    "#pca_data, explained_variance_ratio = apply_pca_train_only(pavia, train_truth, num_components=5)\n",
    "# 先做 PCA 和 LDA 降维\n",
    "pca_data, _ = apply_pca_train_only(whu, train_truth, num_components=4)\n",
    "lda_data = apply_lda_train_only(whu, train_truth, num_components=4)\n",
    "\n",
    "# 拼接 [C_pca + C_lda, H, W]\n",
    "combined_data = np.concatenate([pca_data, lda_data], axis=0)\n",
    "\n",
    "# 构造训练和测试数据集\n",
    "train_dataset = ClassificationDataset(combined_data , train_labels, patch_size=11)\n",
    "\n",
    "test_labels = [\n",
    "    (r, c, label) \n",
    "    for r, c, label in zip(test_truth.row, test_truth.col, test_truth.data)\n",
    "]\n",
    "test_dataset = ClassificationDataset(combined_data, test_labels, patch_size=11)\n",
    "\n",
    "# 定义 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印样本信息\n",
    "print(f\"PCA 降维后的数据形状: {combined_data.shape}\")\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 加载对比学习的模型权重\n",
    "#checkpoint_path = \"./pth/model_epoch_160.pth\"  # 修改为对比学习模型的路径\n",
    "checkpoint_path = \"final/whu_lda_8d.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 确保权重文件中包含特征提取器的权重\n",
    "if 'feature_extractor_state_dict' not in checkpoint:\n",
    "    raise KeyError(\"Checkpoint does not contain 'feature_extractor_state_dict'. Please check the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained weights for the entire feature extractor.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 初始化特征提取器（与对比学习阶段一致的输入通道数为 25）\n",
    "feature_extractor = FeatureExtractor(input_channels=8).cuda()\n",
    "\n",
    "# 加载所有预训练权重\n",
    "feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "print(\"Loaded pre-trained weights for the entire feature extractor.\")\n",
    "\n",
    "# 检查冻结状态（设置所有层参数为可微调）\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "# 修改输入维度为 128（特征提取器的输出维度）\n",
    "classification_head = ClassificationHead(input_dim=128, num_classes=15).cuda()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": feature_extractor.parameters(), \"lr\": 1e-4},  # 微调特征提取器\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},  # 分类头\n",
    "])\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "def train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=50):\n",
    "    feature_extractor.train()\n",
    "    classification_head.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for cubes, labels in train_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        loss_values.append(avg_loss)  # 记录损失值\n",
    "\n",
    "        #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 运行训练函数\n",
    "train_classification_model(feature_extractor, classification_head, train_loader, optimizer, criterion, num_epochs=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9542\n",
      "Average Accuracy: 0.9437\n",
      "Kappa Coefficient: 0.9405\n",
      "\n",
      "Prediction Distribution:\n",
      "Class 0: 34911 predictions\n",
      "Class 1: 9369 predictions\n",
      "Class 2: 5951 predictions\n",
      "Class 3: 57402 predictions\n",
      "Class 4: 5136 predictions\n",
      "Class 5: 11940 predictions\n",
      "Class 6: 66858 predictions\n",
      "Class 7: 8484 predictions\n",
      "Class 8: 4491 predictions\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: 0.9901\n",
      "Class 1: 0.9619\n",
      "Class 2: 0.9944\n",
      "Class 3: 0.8954\n",
      "Class 4: 0.9299\n",
      "Class 5: 0.9937\n",
      "Class 6: 0.9965\n",
      "Class 7: 0.9645\n",
      "Class 8: 0.7671\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def evaluate_classification_model_with_details(feature_extractor, classification_head, test_loader, num_classes):\n",
    "    \"\"\"\n",
    "    评估分类模型的性能，并输出详细预测结果和分布。\n",
    "\n",
    "    参数:\n",
    "        feature_extractor: 冻结的特征提取器\n",
    "        classification_head: 分类头\n",
    "        test_loader: 测试数据加载器\n",
    "        num_classes: 总类别数\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    classification_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 初始化预测计数，并移动到 GPU\n",
    "    prediction_counts = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_correct = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "    class_total = torch.zeros(num_classes, dtype=torch.int64).cuda()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in test_loader:\n",
    "            cubes, labels = cubes.cuda(), labels.cuda()\n",
    "\n",
    "            # 提取特征并进行预测\n",
    "            features = feature_extractor(cubes)\n",
    "            outputs = classification_head(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 更新统计信息\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            prediction_counts += torch.bincount(predicted, minlength=num_classes).cuda()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "            # 保存详细信息\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = correct / total\n",
    "\n",
    "    # Average Accuracy (每个类别的平均准确率)\n",
    "    average_accuracy = (class_correct.float() / class_total.float()).mean().item()\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    per_class_accuracy = class_correct.float() / class_total.float()\n",
    "\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for cls, count in enumerate(prediction_counts.cpu()):  # 将分布从 GPU 移回 CPU\n",
    "        print(f\"Class {cls}: {count} predictions\")\n",
    "\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in enumerate(per_class_accuracy):\n",
    "        print(f\"Class {cls}: {acc:.4f}\")\n",
    "\n",
    "    return overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy.cpu().numpy()\n",
    "\n",
    "\n",
    "# 调用示例\n",
    "overall_accuracy, average_accuracy, kappa, all_predictions, all_labels, per_class_accuracy = evaluate_classification_model_with_details(\n",
    "    feature_extractor, classification_head, test_loader, num_classes=num_classes\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
