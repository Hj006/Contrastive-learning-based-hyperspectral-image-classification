# **Contrastive Learning-Based Hyperspectral Image Classification**  
ğŸš€ **A novel contrastive learning framework for hyperspectral image classification, leveraging superpixel-based local PCA and global PCA features.**  

## **ğŸ“– Overview**  
Hyperspectral image (HSI) classification is a challenging task due to the high-dimensional spectral information and limited labeled data. This project introduces a **contrastive learning-based framework** that enhances **spectral-spatial feature learning** by incorporating **superpixel segmentation and PCA transformation**.  

By constructing **positive sample pairs** from both **local (SuperPCA) and global (GlobalPCA) spectral features**, the model effectively learns **discriminative representations** for HSI classification.  

---

## **ğŸ“Œ Methodology**  
The proposed framework follows these key steps:  

### **1ï¸âƒ£ PCA Dimensionality Reduction**  
- The raw hyperspectral data is **transformed into 40 principal components** using **Principal Component Analysis (PCA)** to reduce computational complexity while preserving essential spectral information.  

### **2ï¸âƒ£ Superpixel Segmentation**  
- **Simple Linear Iterative Clustering (SLIC)** is used to segment the hyperspectral image into superpixels, capturing structural and local spatial information.  

### **3ï¸âƒ£ Feature Extraction (Local & Global PCA)**  
- **SuperPCA**: PCA is applied **within each superpixel** to extract localized spectral-spatial features.  
- **GlobalPCA**: PCA is computed **across the entire training region**, generating global spectral features.  

### **4ï¸âƒ£ Contrastive Learning - Cube Construction**  
To create effective contrastive learning pairs, **two feature cubes (Cube A & Cube B) are constructed**:  
- **Cube A** = **Random 20 PCA channels** + **SuperPCA (local)**  
- **Cube B** = **Remaining 20 PCA channels** + **GlobalPCA (global)**  

These cubes serve as **positive pairs**, ensuring that they represent the **same spatial region** but with **different feature perspectives**.  

### **5ï¸âƒ£ Contrastive Learning Training**  
- **InfoNCE loss** is applied to **maximize the similarity between Cube A & Cube B** while **minimizing their similarity with negative samples**.  
- The model is trained in a **self-supervised manner**, reducing dependence on labeled data.  

---

## **ğŸ“‚ Project Structure**  
```
ğŸ“ Contrastive-Learning-HSI
â”‚â”€â”€ ğŸ“ data/                  # Hyperspectral dataset (e.g., Houston2013)
â”‚â”€â”€ ğŸ“ models/                # Feature extractor & projection head
â”‚â”€â”€ ğŸ“ utils/                 # Data processing functions (PCA, superpixels, cube extraction)
â”‚â”€â”€ ğŸ“ results/               # Training logs & visualizations
â”‚â”€â”€ train.py                  # Training script for contrastive learning
â”‚â”€â”€ infer.py                  # Inference script for testing the trained model
â”‚â”€â”€ requirements.txt          # Required Python libraries
â”‚â”€â”€ README.md                 # Project documentation
```

---

## **ğŸ”§ Installation**  
1ï¸âƒ£ **Clone the repository**  
```bash
git clone https://github.com/your-repo/Contrastive-Learning-HSI.git
cd Contrastive-Learning-HSI
```
  
2ï¸âƒ£ **Create a virtual environment (optional, but recommended)**  
```bash
python -m venv venv
source venv/bin/activate  # On Linux/macOS
venv\Scripts\activate  # On Windows
```

3ï¸âƒ£ **Install dependencies**  
```bash
pip install -r requirements.txt
```

---

## **ğŸš€ Training the Model**  
Run the following command to train the model using contrastive learning:  
```bash
python train.py --epochs 100 --batch_size 64 --lr 1e-4
```
Arguments:
- `--epochs` â†’ Number of training epochs (default: `100`)
- `--batch_size` â†’ Batch size for training (default: `64`)
- `--lr` â†’ Learning rate (default: `1e-4`)  

---

## **ğŸ“Š Results & Visualizations**  
After training, the results (loss curves, embeddings) will be saved in the `results/` directory.  
To visualize training loss:
```bash
python plot_loss.py
```

---

## **ğŸ“Œ Key Features & Benefits**  
âœ… **Self-supervised learning** â†’ No need for large labeled datasets.  
âœ… **Superpixel-based local feature extraction** â†’ Improved spatial-spectral feature representation.  
âœ… **Contrastive learning framework** â†’ Robust feature learning with positive-negative sample pairs.  
âœ… **Flexible architecture** â†’ Can be adapted to various hyperspectral datasets.  

---

## **ğŸ“š Citation**  
If you find this work useful, please consider citing it:  
```
@article{your_paper_2024,
  title={Contrastive Learning-Based Hyperspectral Image Classification},
  author={Your Name, Collaborator Name},
  journal={Arxiv Preprint},
  year={2024}
}
```

---

## **ğŸ“© Contact**  
For questions or collaboration opportunities, feel free to reach out:  
ğŸ“§ Email: your_email@example.com  
ğŸ“Œ GitHub: [your-repo](https://github.com/your-repo)  

---

ğŸ¯ **Let's build a more effective self-supervised learning framework for hyperspectral image classification! ğŸš€**  

---

ğŸ’¡ **Would you like to add specific dataset details, visualization examples, or an evaluation script? Let me know, and I can further refine the README!** ğŸš€
