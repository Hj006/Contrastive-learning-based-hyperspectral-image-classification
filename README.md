# Contrastive-learning-based-hyperspectral-image-classification
Based on contrastive learning, combined with superpixel segmentation and principal component analysis (PCA), an unsupervised feature learning framework is constructed to improve the performance of hyperspectral image classification.

# Contrastive-learning-based Hyperspectral Image Classification

åŸºäºå¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰ï¼Œç»“åˆè¶…åƒç´ åˆ†å‰²ï¼ˆSuperpixel Segmentationï¼‰ä¸ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ï¼Œæ„å»ºäº†ä¸€ä¸ª**æ— ç›‘ç£ç‰¹å¾å­¦ä¹ æ¡†æ¶**ï¼Œç”¨äºæå‡é«˜å…‰è°±å›¾åƒåˆ†ç±»æ€§èƒ½ã€‚

---

## ğŸ“ æ–‡ä»¶ä»‹ç»

ç”±äºæˆ‘æ²¡æœ‰å°†ä»£ç æ¨¡å—åŒ–ï¼Œæ•´ä¸ªé¡¹ç›®æ¯”è¾ƒâ€œå²å±±â€ï¼ˆé›†ä¸­åœ¨ notebook ä¸­ï¼‰ï¼Œå› æ­¤å¯¹æ¯ä¸ªæ–‡ä»¶åšå¦‚ä¸‹è¯´æ˜ï¼š

> **ä»¥ä¸‹æ–‡ä»¶å‡åŸºäº Houston2013 æ•°æ®é›†å®éªŒ**

---

### 1. `Moco.ipynb`
- å°è¯•ä½¿ç”¨ **MoCoï¼ˆMomentum Contrastï¼‰** å®ç°åŠ¨é‡å¼å¯¹æ¯”å­¦ä¹ ï¼›
- å®éªŒç»“æœæ˜¾ç¤ºç²¾åº¦æœ‰ä¸€å®šæå‡ï¼›
- **ç¼ºç‚¹**ï¼šæ—¶é—´æˆæœ¬è¾ƒé«˜ï¼ŒæŒ‰å½“å‰å‚æ•°è®¾ç½®ï¼Œè®­ç»ƒæ—¶é—´çº¦ä¸ºåŸæ¥çš„ **50 å€**ï¼Œä¸æ˜¯æœ€ä¼˜è§£ã€‚

---

### 2. `S3PCA_20dimension.ipynb`
- åˆ‡åˆ†æ–¹å¼ï¼š
  - å— a + å±€éƒ¨ PCA é™ç»´è‡³ 20 ç»´ï¼ˆa1ï¼‰
  - å— b + å…¨å±€ PCA é™ç»´è‡³ 20 ç»´ï¼ˆb1ï¼‰
- æœ€ç»ˆ a1 å’Œ b1 å‡ä¸º 20 ç»´ç‰¹å¾ã€‚

---

### 3. `S3PCA_40dimension.ipynb`
- åˆ‡åˆ†æ–¹å¼ï¼š
  - å— a + å±€éƒ¨ PCA é™ç»´ 20 ç»´
  - å— b + å…¨å±€ PCA é™ç»´ 20 ç»´
- ç„¶ååˆå¹¶æˆ 40 ç»´ç‰¹å¾ã€‚

---

### 4. `S3PCA_40dimension_OPCArandom.ipynb`
- ä¸ `S3PCA_40dimension.ipynb` ç›¸åŒç»“æ„ï¼›
- åŒºåˆ«åœ¨äºï¼š**ä½¿ç”¨éšæœºé€‰å–çš„æ ·æœ¬**è¿›è¡Œ PCA é™ç»´ï¼ˆæ¨¡æ‹Ÿæ›´ä¸ç¡®å®šçš„åœºæ™¯ï¼‰ã€‚

---

### 5. `S3PCA_fulldimension.ipynb`
- **ä¸è¿›è¡Œé™ç»´**ï¼Œä¿ç•™åŸå§‹ç»´åº¦çš„å±€éƒ¨å’Œå…¨å±€ç‰¹å¾ï¼›
- ç”¨äºå¯¹æ¯”é™ç»´ä¸å¦å¯¹åˆ†ç±»æ€§èƒ½çš„å½±å“ã€‚

---

### 6. `S3PCA_nocat.ipynb`
- ä¸æ‹¼æ¥å±€éƒ¨ä¸å…¨å±€ï¼Œä»…ä½¿ç”¨å®ƒä»¬**ç‹¬ç«‹è®­ç»ƒ**å¹¶è¯„ä¼°ï¼›
- ç›®çš„æ˜¯éªŒè¯å•ä¸€ç‰¹å¾æ¥æºçš„æ•ˆæœã€‚

---
=======
# **Contrastive Learning-Based Hyperspectral Image Classification**  
ğŸš€ **A novel contrastive learning framework for hyperspectral image classification, leveraging superpixel-based local PCA and global PCA features.**  

## **ğŸ“– Overview**  
Hyperspectral image (HSI) classification is a challenging task due to the high-dimensional spectral information and limited labeled data. This project introduces a **contrastive learning-based framework** that enhances **spectral-spatial feature learning** by incorporating **superpixel segmentation and PCA transformation**.  

By constructing **positive sample pairs** from both **local (SuperPCA) and global (GlobalPCA) spectral features**, the model effectively learns **discriminative representations** for HSI classification.  

---

## **ğŸ“Œ Methodology**  
The proposed framework follows these key steps:  

### **1ï¸âƒ£ PCA Dimensionality Reduction**  
- The raw hyperspectral data is **transformed into 40 principal components** using **Principal Component Analysis (PCA)** to reduce computational complexity while preserving essential spectral information.  

### **2ï¸âƒ£ Superpixel Segmentation**  
- **Simple Linear Iterative Clustering (SLIC)** is used to segment the hyperspectral image into superpixels, capturing structural and local spatial information.  

### **3ï¸âƒ£ Feature Extraction (Local & Global PCA)**  
- **SuperPCA**: PCA is applied **within each superpixel** to extract localized spectral-spatial features.  
- **GlobalPCA**: PCA is computed **across the entire training region**, generating global spectral features.  

### **4ï¸âƒ£ Contrastive Learning - Cube Construction**  
To create effective contrastive learning pairs, **two feature cubes (Cube A & Cube B) are constructed**:  
- **Cube A** = **Random 20 PCA channels** + **SuperPCA (local)**  
- **Cube B** = **Remaining 20 PCA channels** + **GlobalPCA (global)**  

These cubes serve as **positive pairs**, ensuring that they represent the **same spatial region** but with **different feature perspectives**.  

### **5ï¸âƒ£ Contrastive Learning Training**  
- **InfoNCE loss** is applied to **maximize the similarity between Cube A & Cube B** while **minimizing their similarity with negative samples**.  
- The model is trained in a **self-supervised manner**, reducing dependence on labeled data.  

---


